,Title,PDF URL,Author,DOI,Published Date,Summary,Journal Ref,Primary Category,Category,Entry ID
0,"Cutting $γ$-Liouville quantum gravity by Schramm-Loewner evolution for $κ\not\in \{γ^2, 16/γ^2\}$",http://arxiv.org/pdf/2310.11455v1,"[arxiv.Result.Author('Morris Ang'), arxiv.Result.Author('Ewain Gwynne')]",,2023-10-17 17:59:54+00:00,"There are many deep and useful theorems relating Schramm-Loewner evolution
(SLE$_\kappa$) and Liouville quantum gravity ($\gamma$-LQG) in the case when
the parameters satisfy $\kappa \in \{\gamma^2, 16/\gamma^2\}$. Roughly
speaking, these theorems say that the SLE$_\kappa$ curve cuts the $\gamma$-LQG
surface into two or more independent $\gamma$-LQG surfaces. We extend these
theorems to the case when $\kappa \not\in \{\gamma^2, 16/\gamma^2\}$. Roughly
speaking we show that if we have an appropriate variant of SLE$_\kappa$ and an
independent $\gamma$-LQG disk, then the SLE curve cuts the LQG disk into two or
more $\gamma$-LQG surfaces which are conditionally independent given the values
along the SLE curve of a certain collection of auxiliary imaginary geometry
fields, viewed modulo conformal coordinate change. These fields are sampled
independently from the SLE and the LQG and have the property that that the sum
of the central charges associated with the SLE$_\kappa$ curve, the $\gamma$-LQG
surface, and the auxiliary fields is 26. This condition on the central charge
is natural from the perspective of bosonic string theory. We also prove
analogous statements when the SLE curve is replaced by, e.g., an LQG metric
ball or a Brownian motion path. Statements of this type were conjectured by
Sheffield and are continuum analogs of certain Markov properties of random
planar maps decorated by two or more statistical physics models. We include a
substantial list of open problems.",,math.PR,"['math.PR', 'math-ph', 'math.MP']",http://arxiv.org/abs/2310.11455v1
1,VeRA: Vector-based Random Matrix Adaptation,http://arxiv.org/pdf/2310.11454v1,"[arxiv.Result.Author('Dawid Jan Kopiczko'), arxiv.Result.Author('Tijmen Blankevoort'), arxiv.Result.Author('Yuki Markus Asano')]",,2023-10-17 17:59:46+00:00,"Low-rank adapation (LoRA) is a popular method that reduces the number of
trainable parameters when finetuning large language models, but still faces
acute storage challenges when scaling to even larger models or deploying
numerous per-user or per-task adapted models. In this work, we present
Vector-based Random Matrix Adaptation (VeRA), which reduces the number of
trainable parameters by 10x compared to LoRA, yet maintains the same
performance. It achieves this by using a single pair of low-rank matrices
shared across all layers and learning small scaling vectors instead. We
demonstrate its effectiveness on the GLUE and E2E benchmarks, and show its
application in instruction-following with just 1.4M parameters using the Llama2
7B model.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11454v1
2,BitNet: Scaling 1-bit Transformers for Large Language Models,http://arxiv.org/pdf/2310.11453v1,"[arxiv.Result.Author('Hongyu Wang'), arxiv.Result.Author('Shuming Ma'), arxiv.Result.Author('Li Dong'), arxiv.Result.Author('Shaohan Huang'), arxiv.Result.Author('Huaijie Wang'), arxiv.Result.Author('Lingxiao Ma'), arxiv.Result.Author('Fan Yang'), arxiv.Result.Author('Ruiping Wang'), arxiv.Result.Author('Yi Wu'), arxiv.Result.Author('Furu Wei')]",,2023-10-17 17:59:15+00:00,"The increasing size of large language models has posed challenges for
deployment and raised concerns about environmental impact due to high energy
consumption. In this work, we introduce BitNet, a scalable and stable 1-bit
Transformer architecture designed for large language models. Specifically, we
introduce BitLinear as a drop-in replacement of the nn.Linear layer in order to
train 1-bit weights from scratch. Experimental results on language modeling
show that BitNet achieves competitive performance while substantially reducing
memory footprint and energy consumption, compared to state-of-the-art 8-bit
quantization methods and FP16 Transformer baselines. Furthermore, BitNet
exhibits a scaling law akin to full-precision Transformers, suggesting its
potential for effective scaling to even larger language models while
maintaining efficiency and performance benefits.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11453v1
3,Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from a Parametric Perspective,http://arxiv.org/pdf/2310.11451v1,"[arxiv.Result.Author('Ming Zhong'), arxiv.Result.Author('Chenxin An'), arxiv.Result.Author('Weizhu Chen'), arxiv.Result.Author('Jiawei Han'), arxiv.Result.Author('Pengcheng He')]",,2023-10-17 17:58:34+00:00,"Large Language Models (LLMs) inherently encode a wealth of knowledge within
their parameters through pre-training on extensive corpora. While prior
research has delved into operations on these parameters to manipulate the
underlying implicit knowledge (encompassing detection, editing, and merging),
there remains an ambiguous understanding regarding their transferability across
models with varying scales. In this paper, we seek to empirically investigate
knowledge transfer from larger to smaller models through a parametric
perspective. To achieve this, we employ sensitivity-based techniques to extract
and align knowledge-specific parameters between different LLMs. Moreover, the
LoRA module is used as the intermediary mechanism for injecting the extracted
knowledge into smaller models. Evaluations across four benchmarks validate the
efficacy of our proposed method. Our findings highlight the critical factors
contributing to the process of parametric knowledge transfer, underscoring the
transferability of model parameters across LLMs of different scales. We release
code and data at \url{https://github.com/maszhongming/ParaKnowTransfer}.",,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']",http://arxiv.org/abs/2310.11451v1
4,4K4D: Real-Time 4D View Synthesis at 4K Resolution,http://arxiv.org/pdf/2310.11448v1,"[arxiv.Result.Author('Zhen Xu'), arxiv.Result.Author('Sida Peng'), arxiv.Result.Author('Haotong Lin'), arxiv.Result.Author('Guangzhao He'), arxiv.Result.Author('Jiaming Sun'), arxiv.Result.Author('Yujun Shen'), arxiv.Result.Author('Hujun Bao'), arxiv.Result.Author('Xiaowei Zhou')]",,2023-10-17 17:57:38+00:00,"This paper targets high-fidelity and real-time view synthesis of dynamic 3D
scenes at 4K resolution. Recently, some methods on dynamic view synthesis have
shown impressive rendering quality. However, their speed is still limited when
rendering high-resolution images. To overcome this problem, we propose 4K4D, a
4D point cloud representation that supports hardware rasterization and enables
unprecedented rendering speed. Our representation is built on a 4D feature grid
so that the points are naturally regularized and can be robustly optimized. In
addition, we design a novel hybrid appearance model that significantly boosts
the rendering quality while preserving efficiency. Moreover, we develop a
differentiable depth peeling algorithm to effectively learn the proposed model
from RGB videos. Experiments show that our representation can be rendered at
over 400 FPS on the DNA-Rendering dataset at 1080p resolution and 80 FPS on the
ENeRF-Outdoor dataset at 4K resolution using an RTX 4090 GPU, which is 30x
faster than previous methods and achieves the state-of-the-art rendering
quality. We will release the code for reproducibility.",,cs.CV,['cs.CV'],http://arxiv.org/abs/2310.11448v1
5,Functional Invariants to Watermark Large Transformers,http://arxiv.org/pdf/2310.11446v1,"[arxiv.Result.Author('Fernandez Pierre'), arxiv.Result.Author('Couairon Guillaume'), arxiv.Result.Author('Furon Teddy'), arxiv.Result.Author('Douze Matthijs')]",,2023-10-17 17:56:18+00:00,"The rapid growth of transformer-based models increases the concerns about
their integrity and ownership insurance. Watermarking addresses this issue by
embedding a unique identifier into the model, while preserving its performance.
However, most existing approaches require to optimize the weights to imprint
the watermark signal, which is not suitable at scale due to the computational
cost. This paper explores watermarks with virtually no computational cost,
applicable to a non-blind white-box setting (assuming access to both the
original and watermarked networks). They generate functionally equivalent
copies by leveraging the models' invariance, via operations like dimension
permutations or scaling/unscaling. This enables to watermark models without any
change in their outputs and remains stealthy. Experiments demonstrate the
effectiveness of the approach and its robustness against various model
transformations (fine-tuning, quantization, pruning), making it a practical
solution to protect the integrity of large models.",,cs.CR,"['cs.CR', 'cs.AI', 'cs.CL']",http://arxiv.org/abs/2310.11446v1
6,"Trusted Provenance of Automated, Collaborative and Adaptive Data Processing Pipelines",http://arxiv.org/pdf/2310.11442v1,"[arxiv.Result.Author('Ludwig Stage'), arxiv.Result.Author('Dimka Karastoyanova')]",,2023-10-17 17:52:27+00:00,"To benefit from the abundance of data and the insights it brings data
processing pipelines are being used in many areas of research and development
in both industry and academia. One approach to automating data processing
pipelines is the workflow technology, as it also supports collaborative,
trial-and-error experimentation with the pipeline architecture in different
application domains. In addition to the necessary flexibility that such
pipelines need to possess, in collaborative settings cross-organisational
interactions are plagued by lack of trust. While capturing provenance
information related to the pipeline execution and the processed data is a first
step towards enabling trusted collaborations, the current solutions do not
allow for provenance of the change in the processing pipelines, where the
subject of change can be made on any aspect of the workflow implementing the
pipeline and on the data used while the pipeline is being executed. Therefore
in this work we provide a solution architecture and a proof of concept
implementation of a service, called Provenance Holder, which enable provenance
of collaborative, adaptive data processing pipelines in a trusted manner. We
also contribute a definition of a set of properties of such a service and
identify future research directions.",,cs.CR,['cs.CR'],http://arxiv.org/abs/2310.11442v1
7,Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V,http://arxiv.org/pdf/2310.11441v1,"[arxiv.Result.Author('Jianwei Yang'), arxiv.Result.Author('Hao Zhang'), arxiv.Result.Author('Feng Li'), arxiv.Result.Author('Xueyan Zou'), arxiv.Result.Author('Chunyuan Li'), arxiv.Result.Author('Jianfeng Gao')]",,2023-10-17 17:51:31+00:00,"We present Set-of-Mark (SoM), a new visual prompting method, to unleash the
visual grounding abilities of large multimodal models (LMMs), such as GPT-4V.
As illustrated in Fig. 1 (right), we employ off-the-shelf interactive
segmentation models, such as SAM, to partition an image into regions at
different levels of granularity, and overlay these regions with a set of marks
e.g., alphanumerics, masks, boxes. Using the marked image as input, GPT-4V can
answer the questions that require visual grounding. We perform a comprehensive
empirical study to validate the effectiveness of SoM on a wide range of
fine-grained vision and multimodal tasks. For example, our experiments show
that GPT-4V with SoM outperforms the state-of-the-art fully-finetuned referring
segmentation model on RefCOCOg in a zero-shot setting.",,cs.CV,"['cs.CV', 'cs.AI', 'cs.CL', 'cs.HC']",http://arxiv.org/abs/2310.11441v1
8,EvalCrafter: Benchmarking and Evaluating Large Video Generation Models,http://arxiv.org/pdf/2310.11440v1,"[arxiv.Result.Author('Yaofang Liu'), arxiv.Result.Author('Xiaodong Cun'), arxiv.Result.Author('Xuebo Liu'), arxiv.Result.Author('Xintao Wang'), arxiv.Result.Author('Yong Zhang'), arxiv.Result.Author('Haoxin Chen'), arxiv.Result.Author('Yang Liu'), arxiv.Result.Author('Tieyong Zeng'), arxiv.Result.Author('Raymond Chan'), arxiv.Result.Author('Ying Shan')]",,2023-10-17 17:50:46+00:00,"The vision and language generative models have been overgrown in recent
years. For video generation, various open-sourced models and public-available
services are released for generating high-visual quality videos. However, these
methods often use a few academic metrics, for example, FVD or IS, to evaluate
the performance. We argue that it is hard to judge the large conditional
generative models from the simple metrics since these models are often trained
on very large datasets with multi-aspect abilities. Thus, we propose a new
framework and pipeline to exhaustively evaluate the performance of the
generated videos. To achieve this, we first conduct a new prompt list for
text-to-video generation by analyzing the real-world prompt list with the help
of the large language model. Then, we evaluate the state-of-the-art video
generative models on our carefully designed benchmarks, in terms of visual
qualities, content qualities, motion qualities, and text-caption alignment with
around 18 objective metrics. To obtain the final leaderboard of the models, we
also fit a series of coefficients to align the objective metrics to the users'
opinions. Based on the proposed opinion alignment method, our final score shows
a higher correlation than simply averaging the metrics, showing the
effectiveness of the proposed evaluation method.",,cs.CV,['cs.CV'],http://arxiv.org/abs/2310.11440v1
9,An empirical connection between line-emitting regions and X-rays heating the accretion disc in BH-LMXB MAXI J1820$+$070,http://arxiv.org/pdf/2310.11438v1,"[arxiv.Result.Author('B. E. Tetarenko'), arxiv.Result.Author('A. W. Shaw'), arxiv.Result.Author('P. A. Charles')]",,2023-10-17 17:50:00+00:00,"The recurring transient outbursts in low-mass X-ray binaries (LMXBs) provide
ideal laboratories to study the accretion process. Unlike their supermassive
relatives, LMXBs are far too small and distant to be imaged directly.
Fortunately, phase-resolved spectroscopy can provide an alternative diagnostic
to study their highly complex, time-dependent accretion discs. The primary
spectral signature of LMXBs are strong, disc-formed emission lines detected at
optical wavelengths. The shape, profile, and appearance/disappearance of these
lines change throughout a binary orbit, and thus, can be used to trace how
matter in these discs behaves and evolves over time. By combining a
\textit{Swift} multi-wavelength monitoring campaign, phase-resolved
spectroscopy from the Gran Telescopio Canarias (GTC) and Liverpool Telescope,
and modern astrotomography techniques, we find a clear empirical connection
between the line emitting regions and physical properties of the X-rays heating
the disc in the black hole LMXB MAXI J1820+070 during its 2018 outburst. In
this paper, we show how these empirical correlations can be used as an
effective observational tool for understanding the geometry and structure of a
LMXB accretion disc and present further evidence for an irradiation-driven
warped accretion disc present in this system.",,astro-ph.HE,['astro-ph.HE'],http://arxiv.org/abs/2310.11438v1
10,Identifying Interpretable Visual Features in Artificial and Biological Neural Systems,http://arxiv.org/pdf/2310.11431v1,"[arxiv.Result.Author('David Klindt'), arxiv.Result.Author('Sophia Sanborn'), arxiv.Result.Author('Francisco Acosta'), arxiv.Result.Author('Frédéric Poitevin'), arxiv.Result.Author('Nina Miolane')]",,2023-10-17 17:41:28+00:00,"Single neurons in neural networks are often ``interpretable'' in that they
represent individual, intuitively meaningful features. However, many neurons
exhibit $\textit{mixed selectivity}$, i.e., they represent multiple unrelated
features. A recent hypothesis proposes that features in deep networks may be
represented in $\textit{superposition}$, i.e., on non-orthogonal axes by
multiple neurons, since the number of possible interpretable features in
natural data is generally larger than the number of neurons in a given network.
Accordingly, we should be able to find meaningful directions in activation
space that are not aligned with individual neurons. Here, we propose (1) an
automated method for quantifying visual interpretability that is validated
against a large database of human psychophysics judgments of neuron
interpretability, and (2) an approach for finding meaningful directions in
network activation space. We leverage these methods to discover directions in
convolutional neural networks that are more intuitively meaningful than
individual neurons, as we confirm and investigate in a series of analyses.
Moreover, we apply the same method to two recent datasets of visual neural
responses in the brain and find that our conclusions largely transfer to real
neural data, suggesting that superposition might be deployed by the brain. This
also provides a link with disentanglement and raises fundamental questions
about robust, efficient and factorized representations in both artificial and
biological neural systems.",,stat.ML,"['stat.ML', 'cs.LG']",http://arxiv.org/abs/2310.11431v1
11,An Empirical Study of Translation Hypothesis Ensembling with Large Language Models,http://arxiv.org/pdf/2310.11430v1,"[arxiv.Result.Author('António Farinhas'), arxiv.Result.Author('José G. C. de Souza'), arxiv.Result.Author('André F. T. Martins')]",,2023-10-17 17:40:21+00:00,"Large language models (LLMs) are becoming a one-fits-many solution, but they
sometimes hallucinate or produce unreliable output. In this paper, we
investigate how hypothesis ensembling can improve the quality of the generated
text for the specific problem of LLM-based machine translation. We experiment
with several techniques for ensembling hypotheses produced by LLMs such as
ChatGPT, LLaMA, and Alpaca. We provide a comprehensive study along multiple
dimensions, including the method to generate hypotheses (multiple prompts,
temperature-based sampling, and beam search) and the strategy to produce the
final translation (instruction-based, quality-based reranking, and minimum
Bayes risk (MBR) decoding). Our results show that MBR decoding is a very
effective method, that translation quality can be improved using a small number
of samples, and that instruction tuning has a strong impact on the relation
between the diversity of the hypotheses and the sampling temperature.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11430v1
12,Butterfly Effects of SGD Noise: Error Amplification in Behavior Cloning and Autoregression,http://arxiv.org/pdf/2310.11428v1,"[arxiv.Result.Author('Adam Block'), arxiv.Result.Author('Dylan J. Foster'), arxiv.Result.Author('Akshay Krishnamurthy'), arxiv.Result.Author('Max Simchowitz'), arxiv.Result.Author('Cyril Zhang')]",,2023-10-17 17:39:40+00:00,"This work studies training instabilities of behavior cloning with deep neural
networks. We observe that minibatch SGD updates to the policy network during
training result in sharp oscillations in long-horizon rewards, despite
negligibly affecting the behavior cloning loss. We empirically disentangle the
statistical and computational causes of these oscillations, and find them to
stem from the chaotic propagation of minibatch SGD noise through unstable
closed-loop dynamics. While SGD noise is benign in the single-step action
prediction objective, it results in catastrophic error accumulation over long
horizons, an effect we term gradient variance amplification (GVA). We show that
many standard mitigation techniques do not alleviate GVA, but find an
exponential moving average (EMA) of iterates to be surprisingly effective at
doing so. We illustrate the generality of this phenomenon by showing the
existence of GVA and its amelioration by EMA in both continuous control and
autoregressive language generation. Finally, we provide theoretical vignettes
that highlight the benefits of EMA in alleviating GVA and shed light on the
extent to which classical convex models can help in understanding the benefits
of iterate averaging in deep learning.",,cs.LG,"['cs.LG', 'math.OC', 'stat.ML']",http://arxiv.org/abs/2310.11428v1
13,Predicting polymerization reactions via transfer learning using chemical language models,http://arxiv.org/pdf/2310.11423v1,"[arxiv.Result.Author('Brenda S. Ferrari'), arxiv.Result.Author('Matteo Manica'), arxiv.Result.Author('Ronaldo Giro'), arxiv.Result.Author('Teodoro Laino'), arxiv.Result.Author('Mathias B. Steiner')]",,2023-10-17 17:31:52+00:00,"Polymers are candidate materials for a wide range of sustainability
applications such as carbon capture and energy storage. However, computational
polymer discovery lacks automated analysis of reaction pathways and stability
assessment through retro-synthesis. Here, we report the first extension of
transformer-based language models to polymerization reactions for both forward
and retrosynthesis tasks. To that end, we have curated a polymerization dataset
for vinyl polymers covering reactions and retrosynthesis for representative
homo-polymers and co-polymers. Overall, we obtain a forward model Top-4
accuracy of 80% and a backward model Top-4 accuracy of 60%. We further analyze
the model performance with representative polymerization and retro-synthesis
examples and evaluate its prediction quality from a materials science
perspective.",,physics.chem-ph,"['physics.chem-ph', 'cond-mat.mtrl-sci']",http://arxiv.org/abs/2310.11423v1
14,Characters of the unitriangular group and the Mackey method,http://arxiv.org/pdf/2310.11421v1,"[arxiv.Result.Author('Mikhail Ignatev'), arxiv.Result.Author('Mikhail Venchakov')]",,2023-10-17 17:29:44+00:00,"Let $U$ be the unitriangular group over a finite field. We consider an
interesting class of irreducible complex characters of $U$, so-called
characters of depth 2. This is a next natural step after characters of maximal
and submaximal dimension, whose description is already known. We explicitly
describe the support of a character of depth 2 by a system of defining
algebraic equations. After that, we calculate the value of such a character on
an element from the support. The main technical tool used in the proofs is the
Mackey little group method for semidirect products.",,math.RT,"['math.RT', 'math.GR', '20C15, 17B08, 20D15']",http://arxiv.org/abs/2310.11421v1
15,Loss features in ultracold $^{162}$Dy gases: two- versus three-body processes,http://arxiv.org/pdf/2310.11418v1,"[arxiv.Result.Author('Maxime Lecomte'), arxiv.Result.Author('Alexandre Journeaux'), arxiv.Result.Author('Loan Renaud'), arxiv.Result.Author('Jean Dalibard'), arxiv.Result.Author('Raphael Lopes')]",,2023-10-17 17:26:49+00:00,"Dipolar gases like erbium and dysprosium have a dense spectrum of resonant
loss features associated with their strong anisotropic interaction potential.
These resonances display various behaviours with density and temperature,
implying diverse microscopic properties. Here, we quantitatively investigate
the low-field ($B < 6\,\text{G}$) loss features in ultracold thermal samples of
$^{162}$Dy, revealing two- and three-body dominated loss processes. We
investigate their temperature dependence and detect a feature compatible with a
$d$-wave Fano-Feshbach resonance, which has not been observed before. We also
analyse the expansion of the dipolar Bose-Einstein condensate as a function of
the magnetic field and interpret the changes in size close to the resonances
with a variation in the scattering length.",,cond-mat.quant-gas,['cond-mat.quant-gas'],http://arxiv.org/abs/2310.11418v1
16,Stellar mass-metallicity relation throughout the large-scale of the Universe: CAVITY mother sample,http://arxiv.org/pdf/2310.11412v1,"[arxiv.Result.Author('Jesús Domínguez-Gómez'), arxiv.Result.Author('Isabel Pérez'), arxiv.Result.Author('Tomás Ruiz-Lara'), arxiv.Result.Author('Reynier F. Peletier'), arxiv.Result.Author('Patricia Sánchez-Blázquez'), arxiv.Result.Author('Ute Lisenfeld'), arxiv.Result.Author('Bahar Bidaran'), arxiv.Result.Author('Jesús Falcón-Barroso'), arxiv.Result.Author('Manuel Alcázar-Laynez'), arxiv.Result.Author('María Argudo-Fernández'), arxiv.Result.Author('Guillermo Blázquez-Calero'), arxiv.Result.Author('Hélène Courtois'), arxiv.Result.Author('Salvador Duarte Puertas'), arxiv.Result.Author('Daniel Espada'), arxiv.Result.Author('Estrella Florido'), arxiv.Result.Author('Rubén García-Benito'), arxiv.Result.Author('Andoni Jiménez'), arxiv.Result.Author('Kathryn Kreckel'), arxiv.Result.Author('Mónica Relaño'), arxiv.Result.Author('Laura Sánchez-Menguiano'), arxiv.Result.Author('Thijs van der Hulst'), arxiv.Result.Author('Rien van de Weygaert'), arxiv.Result.Author('Simon Verley'), arxiv.Result.Author('Almudena Zurita')]",,2023-10-17 17:20:43+00:00,"Void galaxies are essential to understand the physical processes that drive
galaxy evolution as they are less affected by external factors than galaxies in
denser environments, i.e. filaments, walls, and clusters. The stellar
metallicity of a galaxy traces the accumulated fossil record of star formation
through its entire life. Comparing the stellar metallicity of galaxies in
various environments, including voids, filaments, walls, and clusters, can
provide valuable insights into how the large-scale environment impacts galaxy
chemical evolution. We present the first comparison of the total stellar mass
vs. central stellar metallicity relation between galaxies in voids, filaments,
walls, and clusters with different star formation history (SFH) types,
morphologies, and colours, for stellar masses between 10^8.0 to 10^11.5 solar
masses and redshift 0.01 < z < 0.05. We aim to better understand how the
large-scale structure affects galaxy evolution by studying the stellar
mass-metallicity relation of thousands of galaxies, which allows us to make a
statistically sound comparison between galaxies in voids, filaments, walls, and
clusters. We apply non-parametric full spectral fitting techniques (pPXF and
STECKMAP) to 10807 spectra from the SDSS-DR7 (987 in voids, 6463 in filaments
and walls, and 3357 in clusters) and derive their central mass-weighted average
stellar metallicity. We find that galaxies in voids have on average slightly
lower stellar metallicities than galaxies in filaments and walls (by 0.1 dex),
and much lower than galaxies in clusters (by 0.4 dex). These differences are
more significant for low-mass (10^9.25) than for high-mass galaxies, for
long-timescale SFH (LT-SFH, extended along time) galaxies than for
short-timescale SFHs (ST-SFH, concentrated at early times) galaxies, for spiral
than for elliptical galaxies, and for blue than for red galaxies.",,astro-ph.GA,"['astro-ph.GA', 'astro-ph.CO']",http://arxiv.org/abs/2310.11412v1
17,High kinetic inductance NbTiN films for quantum limited travelling wave parametric amplifiers,http://arxiv.org/pdf/2310.11410v1,"[arxiv.Result.Author('Felix Ahrens'), arxiv.Result.Author('Matteo Borghesi'), arxiv.Result.Author('Paolo Falferi'), arxiv.Result.Author('Luca Fasolo'), arxiv.Result.Author('Marco Faverzani'), arxiv.Result.Author('Elena Ferri'), arxiv.Result.Author('Andrea Giachero'), arxiv.Result.Author('Danilo Labranca'), arxiv.Result.Author('Federica Mantegazzini'), arxiv.Result.Author('Benno Margesin'), arxiv.Result.Author('Renato Mezzena'), arxiv.Result.Author('Roberto Moretti'), arxiv.Result.Author('Angelo Nucciotti'), arxiv.Result.Author('Luca Origo'), arxiv.Result.Author('Andrea Vinante'), arxiv.Result.Author('Mario Zannoni')]",,2023-10-17 17:18:05+00:00,"A wide-bandwidth and low-noise amplification chain in the microwave regime is
crucial for the efficient read-out of quantum systems based on superconducting
detectors, such as Microwave Kinetic Inductance Detectors (MKIDs), Transition
Edge Sensors (TESs), Magnetic Microcalorimeters (MMCs), and RF cavities, as
well as qubits. Kinetic Inductance Travelling Wave Parametric Amplifiers
(KI-TWPAs) operated in a three-wave mixing fashion have demonstrated
exceptional dynamic range and low-noise performance, approaching the quantum
limit. These amplifiers can be fabricated using a single layer of a high
kinetic inductance film as weakly dispersive artificial transmission lines,
with the ability to control the phase-matched bandwidth through dispersion
engineering. In this study, we present the optimisation of the rf
sputter-deposition process of NbTiN films using a Nb80%T20 target, with the
goal of achieving precise control over film characteristics, resulting in high
kinetic inductance while maintaining a high transition temperature. The
parameter landscape related to the different sputtering conditions, such as
pressure, power, and nitrogen flow, has been explored and the film thickness
has been used as a fine-tuning parameter to adjust the properties of the final
NbTiN films used for the fabrication of KI-TWPAs. As a final result, we have
obtained a NbTiN film with a kinetic inductance of 8.5 pH/sq which we have
exploited to fabricate KI-TWPA prototype devices, showing promising
amplification performance.",,physics.app-ph,"['physics.app-ph', 'quant-ph']",http://arxiv.org/abs/2310.11410v1
18,Evaluating LLMs for Privilege-Escalation Scenarios,http://arxiv.org/pdf/2310.11409v1,"[arxiv.Result.Author('Andreas Happe'), arxiv.Result.Author('Aaron Kaplan'), arxiv.Result.Author('Jürgen Cito')]",,2023-10-17 17:15:41+00:00,"Penetration testing, an essential component of cybersecurity, allows
organizations to proactively identify and remediate vulnerabilities in their
systems, thus bolstering their defense mechanisms against potential
cyberattacks. One recent advancement in the realm of penetration testing is the
utilization of Language Models (LLMs). We explore the intersection of LLMs and
penetration testing to gain insight into their capabilities and challenges in
the context of privilige escalation. We create an automated Linux
privilege-escalation benchmark utilizing local virtual machines. We introduce
an LLM-guided privilege-escalation tool designed for evaluating different LLMs
and prompt strategies against our benchmark. We analyze the impact of different
prompt designs, the benefits of in-context learning, and the advantages of
offering high-level guidance to LLMs. We discuss challenging areas for LLMs,
including maintaining focus during testing, coping with errors, and finally
comparing them with both stochastic parrots as well as with human hackers.",,cs.CR,"['cs.CR', 'cs.AI']",http://arxiv.org/abs/2310.11409v1
19,Group-blind optimal transport to group parity and its constrained variants,http://arxiv.org/pdf/2310.11407v1,"[arxiv.Result.Author('Quan Zhou'), arxiv.Result.Author('Jakub Marecek')]",,2023-10-17 17:14:07+00:00,"Fairness holds a pivotal role in the realm of machine learning, particularly
when it comes to addressing groups categorised by sensitive attributes, e.g.,
gender, race. Prevailing algorithms in fair learning predominantly hinge on
accessibility or estimations of these sensitive attributes, at least in the
training process. We design a single group-blind projection map that aligns the
feature distributions of both groups in the source data, achieving
(demographic) group parity, without requiring values of the protected attribute
for individual samples in the computation of the map, as well as its use.
Instead, our approach utilises the feature distributions of the privileged and
unprivileged groups in a boarder population and the essential assumption that
the source data are unbiased representation of the population. We present
numerical results on synthetic data and real data.",,cs.LG,"['cs.LG', 'math.OC']",http://arxiv.org/abs/2310.11407v1
20,Enhancing Group Fairness in Online Settings Using Oblique Decision Forests,http://arxiv.org/pdf/2310.11401v1,"[arxiv.Result.Author('Somnath Basu Roy Chowdhury'), arxiv.Result.Author('Nicholas Monath'), arxiv.Result.Author('Ahmad Beirami'), arxiv.Result.Author('Rahul Kidambi'), arxiv.Result.Author('Avinava Dubey'), arxiv.Result.Author('Amr Ahmed'), arxiv.Result.Author('Snigdha Chaturvedi')]",,2023-10-17 17:10:56+00:00,"Fairness, especially group fairness, is an important consideration in the
context of machine learning systems. The most commonly adopted group
fairness-enhancing techniques are in-processing methods that rely on a mixture
of a fairness objective (e.g., demographic parity) and a task-specific
objective (e.g., cross-entropy) during the training process. However, when data
arrives in an online fashion -- one instance at a time -- optimizing such
fairness objectives poses several challenges. In particular, group fairness
objectives are defined using expectations of predictions across different
demographic groups. In the online setting, where the algorithm has access to a
single instance at a time, estimating the group fairness objective requires
additional storage and significantly more computation (e.g., forward/backward
passes) than the task-specific objective at every time step. In this paper, we
propose Aranyani, an ensemble of oblique decision trees, to make fair decisions
in online settings. The hierarchical tree structure of Aranyani enables
parameter isolation and allows us to efficiently compute the fairness gradients
using aggregate statistics of previous decisions, eliminating the need for
additional storage and forward/backward passes. We also present an efficient
framework to train Aranyani and theoretically analyze several of its
properties. We conduct empirical evaluations on 5 publicly available benchmarks
(including vision and language datasets) to show that Aranyani achieves a
better accuracy-fairness trade-off compared to baseline approaches.",,cs.LG,['cs.LG'],http://arxiv.org/abs/2310.11401v1
21,Neural Attention: Enhancing QKV Calculation in Self-Attention Mechanism with Neural Networks,http://arxiv.org/pdf/2310.11398v1,[arxiv.Result.Author('Muhan Zhang')],,2023-10-17 17:06:26+00:00,"In the realm of deep learning, the self-attention mechanism has substantiated
its pivotal role across a myriad of tasks, encompassing natural language
processing and computer vision. Despite achieving success across diverse
applications, the traditional self-attention mechanism primarily leverages
linear transformations for the computation of query, key, and value (QKV),
which may not invariably be the optimal choice under specific circumstances.
This paper probes into a novel methodology for QKV computation-implementing a
specially-designed neural network structure for the calculation. Utilizing a
modified Marian model, we conducted experiments on the IWSLT 2017
German-English translation task dataset and juxtaposed our method with the
conventional approach. The experimental results unveil a significant
enhancement in BLEU scores with our method. Furthermore, our approach also
manifested superiority when training the Roberta model with the Wikitext-103
dataset, reflecting a notable reduction in model perplexity compared to its
original counterpart. These experimental outcomes not only validate the
efficacy of our method but also reveal the immense potential in optimizing the
self-attention mechanism through neural network-based QKV computation, paving
the way for future research and practical applications. The source code and
implementation details for our proposed method can be accessed at
https://github.com/ocislyjrti/NeuralAttention.",,cs.CL,"['cs.CL', 'cs.AI']",http://arxiv.org/abs/2310.11398v1
22,"Last One Standing: A Comparative Analysis of Security and Privacy of Soft Prompt Tuning, LoRA, and In-Context Learning",http://arxiv.org/pdf/2310.11397v1,"[arxiv.Result.Author('Rui Wen'), arxiv.Result.Author('Tianhao Wang'), arxiv.Result.Author('Michael Backes'), arxiv.Result.Author('Yang Zhang'), arxiv.Result.Author('Ahmed Salem')]",,2023-10-17 17:03:00+00:00,"Large Language Models (LLMs) are powerful tools for natural language
processing, enabling novel applications and user experiences. However, to
achieve optimal performance, LLMs often require adaptation with private data,
which poses privacy and security challenges. Several techniques have been
proposed to adapt LLMs with private data, such as Low-Rank Adaptation (LoRA),
Soft Prompt Tuning (SPT), and In-Context Learning (ICL), but their comparative
privacy and security properties have not been systematically investigated. In
this work, we fill this gap by evaluating the robustness of LoRA, SPT, and ICL
against three types of well-established attacks: membership inference, which
exposes data leakage (privacy); backdoor, which injects malicious behavior
(security); and model stealing, which can violate intellectual property
(privacy and security). Our results show that there is no silver bullet for
privacy and security in LLM adaptation and each technique has different
strengths and weaknesses.",,cs.CR,"['cs.CR', 'cs.LG']",http://arxiv.org/abs/2310.11397v1
23,Quantum Financial Modeling on NISQ Hardware: Random Walks using Approximate Quantum Counting,http://arxiv.org/pdf/2310.11394v1,[arxiv.Result.Author('Dominic Widdows')],,2023-10-17 16:54:31+00:00,"Quantum computers are expected to contribute more efficient and accurate ways
of modeling economic processes. Quantum hardware is currently available at a
relatively small scale, but effective algorithms are limited by the number of
logic gates that can be used, before noise from gate inaccuracies tends to
dominate results. Some theoretical algorithms that have been proposed and
studied for years do not perform well yet on quantum hardware in practice. This
encourages the development of suitable alternative algorithms that play similar
roles in limited contexts.
  This paper implements this strategy in the case of quantum counting, which is
used as a component for keeping track of position in a quantum walk, which is
used as a model for simulating asset prices over time. We introduce quantum
approximate counting circuits that use far fewer 2-qubit entangling gates than
traditional quantum counting that relies on binary positional encoding. The
robustness of these circuits to noise is demonstrated.
  While this paper is mainly about robust simplified quantum circuit designs,
we compare some aspects of the results with price change distributions from
stock indices, and compare the behavior of circuits with and without
mid-measurement to trends in the housing market.",,quant-ph,"['quant-ph', 'cs.CE']",http://arxiv.org/abs/2310.11394v1
24,Towards Automatic Satellite Images Captions Generation Using Large Language Models,http://arxiv.org/pdf/2310.11392v1,"[arxiv.Result.Author('Yingxu He'), arxiv.Result.Author('Qiqi Sun')]",,2023-10-17 16:45:47+00:00,"Automatic image captioning is a promising technique for conveying visual
information using natural language. It can benefit various tasks in satellite
remote sensing, such as environmental monitoring, resource management, disaster
management, etc. However, one of the main challenges in this domain is the lack
of large-scale image-caption datasets, as they require a lot of human expertise
and effort to create. Recent research on large language models (LLMs) has
demonstrated their impressive performance in natural language understanding and
generation tasks. Nonetheless, most of them cannot handle images (GPT-3.5,
Falcon, Claude, etc.), while conventional captioning models pre-trained on
general ground-view images often fail to produce detailed and accurate captions
for aerial images (BLIP, GIT, CM3, CM3Leon, etc.). To address this problem, we
propose a novel approach: Automatic Remote Sensing Image Captioning (ARSIC) to
automatically collect captions for remote sensing images by guiding LLMs to
describe their object annotations. We also present a benchmark model that
adapts the pre-trained generative image2text model (GIT) to generate
high-quality captions for remote-sensing images. Our evaluation demonstrates
the effectiveness of our approach for collecting captions for remote sensing
images.",,cs.CV,"['cs.CV', 'cs.AI']",http://arxiv.org/abs/2310.11392v1
25,VaR\ and CVaR Estimation in a Markov Cost Process: Lower and Upper Bounds,http://arxiv.org/pdf/2310.11389v1,"[arxiv.Result.Author('Sanjay Bhat'), arxiv.Result.Author('Prashanth L. A.'), arxiv.Result.Author('Gugan Thoppe')]",,2023-10-17 16:35:39+00:00,"We tackle the problem of estimating the Value-at-Risk (VaR) and the
Conditional Value-at-Risk (CVaR) of the infinite-horizon discounted cost within
a Markov cost process. First, we derive a minimax lower bound of
$\Omega(1/\sqrt{n})$ that holds both in an expected and in a probabilistic
sense. Then, using a finite-horizon truncation scheme, we derive an upper bound
for the error in CVaR estimation, which matches our lower bound up to constant
factors. Finally, we discuss an extension of our estimation scheme that covers
more general risk measures satisfying a certain continuity criterion, e.g.,
spectral risk measures, utility-based shortfall risk. To the best of our
knowledge, our work is the first to provide lower and upper bounds on the
estimation error for any risk measure within Markovian settings. We remark that
our lower bounds also extend to the infinite-horizon discounted costs' mean.
Even in that case, our result $\Omega(1/\sqrt{n}) $ improves upon the existing
result $\Omega(1/n)$[13].",,cs.LG,"['cs.LG', 'stat.ML']",http://arxiv.org/abs/2310.11389v1
26,Towards Operationalizing Social Bonding in Human-Robot Dyads,http://arxiv.org/pdf/2310.11386v1,[arxiv.Result.Author('Imran Khan')],,2023-10-17 16:35:03+00:00,"With momentum increasing in the use of social robots as long-term assistive
and collaborative partners, humans developing social bonds with these
artificial agents appears to be inevitable. In human-human dyads, social
bonding plays a powerful role in regulating behaviours, emotions, and even
health. If this is to extend to human-robot dyads, the phenomenology of such
relationships (including their emergence and stability) must be better
understood. In this paper, we discuss potential approaches towards
operationalizing the phenomenon of social bonding between human-robot dyads. We
will discuss a number of biobehavioural proxies of social bonding, moving away
from existing approaches that use subjective, psychological measures, and
instead grounding our approach in some of the evolutionary, neurobiological and
physiological correlates of social bond formation in natural systems: (a)
reductions in physiological stress (the ''social buffering'' phenomenon), (b)
narrowing of spatial proximity between dyads, and (c) inter-dyad behavioural
synchrony. We provide relevant evolutionary support for each proposed
component, with suggestions and considerations for how they can be recorded in
(real-time) human-robot interaction scenarios. With this, we aim to inspire
more robust operationalisation of ''social bonding'' between human and
artificial (robotic) agents.",,cs.RO,"['cs.RO', 'cs.HC']",http://arxiv.org/abs/2310.11386v1
27,A voxel-level approach to brain age prediction: A method to assess regional brain aging,http://arxiv.org/pdf/2310.11385v1,"[arxiv.Result.Author('Neha Gianchandani'), arxiv.Result.Author('Mahsa Dibaji'), arxiv.Result.Author('Johanna Ospel'), arxiv.Result.Author('Fernando Vega'), arxiv.Result.Author('Mariana Bento'), arxiv.Result.Author('M. Ethan MacDonald'), arxiv.Result.Author('Roberto Souza')]",,2023-10-17 16:32:38+00:00,"Brain aging is a regional phenomenon, a facet that remains relatively
under-explored within the realm of brain age prediction research using machine
learning methods. Voxel-level predictions can provide localized brain age
estimates that can provide granular insights into the regional aging processes.
This is essential to understand the differences in aging trajectories in
healthy versus diseased subjects. In this work, a deep learning-based multitask
model is proposed for voxel-level brain age prediction from T1-weighted
magnetic resonance images. The proposed model outperforms the models existing
in the literature and yields valuable clinical insights when applied to both
healthy and diseased populations. Regional analysis is performed on the
voxel-level brain age predictions to understand aging trajectories of known
anatomical regions in the brain and show that there exist disparities in
regional aging trajectories of healthy subjects compared to ones with
underlying neurological disorders such as Dementia and more specifically,
Alzheimer's disease. Our code is available at
https://github.com/nehagianchandani/Voxel-level-brain-age-prediction.",,cs.CV,['cs.CV'],http://arxiv.org/abs/2310.11385v1
28,Condensate droplet roaming on nanostructured superhydrophobic surfaces,http://arxiv.org/pdf/2310.11382v1,"[arxiv.Result.Author('Cheuk Wing Edmond Lam'), arxiv.Result.Author('Kartik Regulagadda'), arxiv.Result.Author('Matteo Donati'), arxiv.Result.Author('Abinash Tripathy'), arxiv.Result.Author('Gopal Chandra Pal'), arxiv.Result.Author('Chander Shekhar Sharma'), arxiv.Result.Author('Athanasios Milionis'), arxiv.Result.Author('Dimos Poulikakos')]",,2023-10-17 16:30:57+00:00,"Jumping of coalescing condensate droplets from superhydrophobic surfaces is
an interesting phenomenon which yields marked heat transfer enhancement over
the more explored gravity-driven droplet removal mode in surface condensation,
a phase change process of central interest to applications ranging from energy
to water harvesting. However, when condensate microdroplets coalesce, they can
also spontaneously propel themselves omnidirectionally on the surface
independent of gravity and grow by feeding from droplets they sweep along the
way. Here we observe and explain the physics behind this phenomenon of roaming
of coalescing condensate microdroplets on solely nanostructured
superhydrophobic surfaces, where the microdroplets are orders of magnitude
larger than the underlaying surface nanotexture. We quantify and show that it
is the inherent asymmetries in droplet adhesion during condensation, arising
from the stochastic nature of nucleation within the nanostructures, that
generates the tangential momentum driving the roaming motion. Subsequent
dewetting during this conversion initiates a vivid roaming and successive
coalescence process, preventing condensate flooding of the surface, and
enhancing surface renewal. Finally, we show that the more efficient conversion
process of roaming from excess surface energy to kinetic energy results in
significantly improved heat transfer efficiency over condensate droplet
jumping, the mechanism currently understood as maximum.",,physics.flu-dyn,['physics.flu-dyn'],http://arxiv.org/abs/2310.11382v1
29,Chiral Bell-state transfer via dissipative Liouvillian dynamics,http://arxiv.org/pdf/2310.11381v1,"[arxiv.Result.Author('Shishir Khandelwal'), arxiv.Result.Author('Weijian Chen'), arxiv.Result.Author('Kater W. Murch'), arxiv.Result.Author('Géraldine Haack')]",,2023-10-17 16:24:41+00:00,"Chiral state transfer along closed loops in the vicinity of an exceptional
point is one of the many counter-intuitive observations in non-Hermitian
physics. The application of this property beyond proof-of-principle,
specifically in quantum physics, is an open question. In this work, we
demonstrate chiral state conversion between singlet and triplet Bell states
through fully-quantum Liouvillian dynamics. Crucially, we demonstrate that this
property can be used for the chiral production of Bell states from separable
states with a high fidelity and for a large range of parameters. Additionally,
we show that the removal of quantum jumps from the dynamics through
postselection can result in near-perfect Bell states from initially separable
states. Our work paves the way to a novel type of quantum control and a
potential application of non-Hermitian physics in quantum information
processing.",,quant-ph,"['quant-ph', 'cond-mat.mes-hall']",http://arxiv.org/abs/2310.11381v1
30,Robust Wake-Up Word Detection by Two-stage Multi-resolution Ensembles,http://arxiv.org/pdf/2310.11379v1,"[arxiv.Result.Author('Fernando López'), arxiv.Result.Author('Jordi Luque'), arxiv.Result.Author('Carlos Segura'), arxiv.Result.Author('Pablo Gómez')]",,2023-10-17 16:22:18+00:00,"Voice-based interfaces rely on a wake-up word mechanism to initiate
communication with devices. However, achieving a robust, energy-efficient, and
fast detection remains a challenge. This paper addresses these real production
needs by enhancing data with temporal alignments and using detection based on
two phases with multi-resolution. It employs two models: a lightweight
on-device model for real-time processing of the audio stream and a verification
model on the server-side, which is an ensemble of heterogeneous architectures
that refine detection. This scheme allows the optimization of two operating
points. To protect privacy, audio features are sent to the cloud instead of raw
audio. The study investigated different parametric configurations for feature
extraction to select one for on-device detection and another for the
verification model. Furthermore, thirteen different audio classifiers were
compared in terms of performance and inference time. The proposed ensemble
outperforms our stronger classifier in every noise condition.",,cs.SD,"['cs.SD', 'cs.CL', 'eess.AS']",http://arxiv.org/abs/2310.11379v1
31,DialogueLLM: Context and Emotion Knowledge-Tuned LLaMA Models for Emotion Recognition in Conversations,http://arxiv.org/pdf/2310.11374v1,"[arxiv.Result.Author('Yazhou Zhang'), arxiv.Result.Author('Mengyao Wang'), arxiv.Result.Author('Prayag Tiwari'), arxiv.Result.Author('Qiuchi Li'), arxiv.Result.Author('Benyou Wang'), arxiv.Result.Author('Jing Qin')]",,2023-10-17 16:15:34+00:00,"Large language models (LLMs) and their variants have shown extraordinary
efficacy across numerous downstream natural language processing (NLP) tasks,
which has presented a new vision for the development of NLP. Despite their
remarkable performance in natural language generating (NLG), LLMs lack a
distinct focus on the emotion understanding domain. As a result, using LLMs for
emotion recognition may lead to suboptimal and inadequate precision. Another
limitation of LLMs is that they are typical trained without leveraging
multi-modal information. To overcome these limitations, we propose DialogueLLM,
a context and emotion knowledge tuned LLM that is obtained by fine-tuning LLaMA
models with 13,638 multi-modal (i.e., texts and videos) emotional dialogues.
The visual information is considered as the supplementary knowledge to
construct high-quality instructions. We offer a comprehensive evaluation of our
proposed model on three benchmarking emotion recognition in conversations (ERC)
datasets and compare the results against the SOTA baselines and other SOTA
LLMs. Additionally, DialogueLLM-7B can be easily trained using LoRA on a 40GB
A100 GPU in 5 hours, facilitating reproducibility for other researchers.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11374v1
32,A Two-Layer Blockchain Sharding Protocol Leveraging Safety and Liveness for Enhanced Performance,http://arxiv.org/pdf/2310.11373v1,"[arxiv.Result.Author('Yibin Xu'), arxiv.Result.Author('Jingyi Zheng'), arxiv.Result.Author('Boris Düdder'), arxiv.Result.Author('Tijs Slaats'), arxiv.Result.Author('Yongluan Zhou')]",,2023-10-17 16:15:28+00:00,"Sharding is essential for improving blockchain scalability. Existing
protocols overlook diverse adversarial attacks, limiting transaction
throughput. This paper presents Reticulum, a groundbreaking sharding protocol
addressing this issue, boosting blockchain scalability.
  Reticulum employs a two-phase approach, adapting transaction throughput based
on runtime adversarial attacks. It comprises ""control"" and ""process"" shards in
two layers. Process shards contain at least one trustworthy node, while control
shards have a majority of trusted nodes. In the first phase, transactions are
written to blocks and voted on by nodes in process shards. Unanimously accepted
blocks are confirmed. In the second phase, blocks without unanimous acceptance
are voted on by control shards. Blocks are accepted if the majority votes in
favor, eliminating first-phase opponents and silent voters. Reticulum uses
unanimous voting in the first phase, involving fewer nodes, enabling more
parallel process shards. Control shards finalize decisions and resolve
disputes.
  Experiments confirm Reticulum's innovative design, providing high transaction
throughput and robustness against various network attacks, outperforming
existing sharding protocols for blockchain networks.",Network and Distributed System Security (NDSS) Symposium 2024,cs.CR,"['cs.CR', 'cs.DC']",http://arxiv.org/abs/2310.11373v1
33,VECHR: A Dataset for Explainable and Robust Classification of Vulnerability Type in the European Court of Human Rights,http://arxiv.org/pdf/2310.11368v1,"[arxiv.Result.Author('Shanshan Xu'), arxiv.Result.Author('Leon Staufer'), arxiv.Result.Author('Santosh T. Y. S. S'), arxiv.Result.Author('Oana Ichim'), arxiv.Result.Author('Corina Heri'), arxiv.Result.Author('Matthias Grabmair')]",,2023-10-17 16:05:52+00:00,"Recognizing vulnerability is crucial for understanding and implementing
targeted support to empower individuals in need. This is especially important
at the European Court of Human Rights (ECtHR), where the court adapts
Convention standards to meet actual individual needs and thus ensures effective
human rights protection. However, the concept of vulnerability remains elusive
at the ECtHR and no prior NLP research has dealt with it. To enable future
research in this area, we present VECHR, a novel expert-annotated multi-label
dataset comprising of vulnerability type classification and explanation
rationale. We benchmark the performance of state-of-the-art models on VECHR
from both prediction and explainability perspectives. Our results demonstrate
the challenging nature of the task with lower prediction performance and
limited agreement between models and experts. Further, we analyze the
robustness of these models in dealing with out-of-domain (OOD) data and observe
overall limited performance. Our dataset poses unique challenges offering
significant room for improvement regarding performance, explainability, and
robustness.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11368v1
34,High-Fidelity Noise Reduction with Differentiable Signal Processing,http://arxiv.org/pdf/2310.11364v1,"[arxiv.Result.Author('Christian J. Steinmetz'), arxiv.Result.Author('Thomas Walther'), arxiv.Result.Author('Joshua D. Reiss')]",,2023-10-17 16:02:07+00:00,"Noise reduction techniques based on deep learning have demonstrated
impressive performance in enhancing the overall quality of recorded speech.
While these approaches are highly performant, their application in audio
engineering can be limited due to a number of factors. These include operation
only on speech without support for music, lack of real-time capability, lack of
interpretable control parameters, operation at lower sample rates, and a
tendency to introduce artifacts. On the other hand, signal processing-based
noise reduction algorithms offer fine-grained control and operation on a broad
range of content, however, they often require manual operation to achieve the
best results. To address the limitations of both approaches, in this work we
introduce a method that leverages a signal processing-based denoiser that when
combined with a neural network controller, enables fully automatic and
high-fidelity noise reduction on both speech and music signals. We evaluate our
proposed method with objective metrics and a perceptual listening test. Our
evaluation reveals that speech enhancement models can be extended to music,
however training the model to remove only stationary noise is critical.
Furthermore, our proposed approach achieves performance on par with the deep
learning models, while being significantly more efficient and introducing fewer
artifacts in some cases. Listening examples are available online at
https://tape.it/research/denoiser .",,cs.SD,"['cs.SD', 'eess.AS']",http://arxiv.org/abs/2310.11364v1
35,Disentangling the Linguistic Competence of Privacy-Preserving BERT,http://arxiv.org/pdf/2310.11363v1,"[arxiv.Result.Author('Stefan Arnold'), arxiv.Result.Author('Nils Kemmerzell'), arxiv.Result.Author('Annika Schreiner')]",,2023-10-17 16:00:26+00:00,"Differential Privacy (DP) has been tailored to address the unique challenges
of text-to-text privatization. However, text-to-text privatization is known for
degrading the performance of language models when trained on perturbed text.
Employing a series of interpretation techniques on the internal representations
extracted from BERT trained on perturbed pre-text, we intend to disentangle at
the linguistic level the distortion induced by differential privacy.
Experimental results from a representational similarity analysis indicate that
the overall similarity of internal representations is substantially reduced.
Using probing tasks to unpack this dissimilarity, we find evidence that
text-to-text privatization affects the linguistic competence across several
formalisms, encoding localized properties of words while falling short at
encoding the contextual relationships between spans of words.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11363v1
36,Enhancing Neural Machine Translation with Semantic Units,http://arxiv.org/pdf/2310.11360v1,"[arxiv.Result.Author('Langlin Huang'), arxiv.Result.Author('Shuhao Gu'), arxiv.Result.Author('Zhuocheng Zhang'), arxiv.Result.Author('Yang Feng')]",,2023-10-17 15:55:31+00:00,"Conventional neural machine translation (NMT) models typically use subwords
and words as the basic units for model input and comprehension. However,
complete words and phrases composed of several tokens are often the fundamental
units for expressing semantics, referred to as semantic units. To address this
issue, we propose a method Semantic Units for Machine Translation (SU4MT) which
models the integral meanings of semantic units within a sentence, and then
leverages them to provide a new perspective for understanding the sentence.
Specifically, we first propose Word Pair Encoding (WPE), a phrase extraction
method to help identify the boundaries of semantic units. Next, we design an
Attentive Semantic Fusion (ASF) layer to integrate the semantics of multiple
subwords into a single vector: the semantic unit representation. Lastly, the
semantic-unit-level sentence representation is concatenated to the token-level
one, and they are combined as the input of encoder. Experimental results
demonstrate that our method effectively models and leverages
semantic-unit-level information and outperforms the strong baselines. The code
is available at https://github.com/ictnlp/SU4MT.",,cs.CL,"['cs.CL', 'I.2.7']",http://arxiv.org/abs/2310.11360v1
37,Scaling theory of maximally efficient quantum-dynamical scrambling,http://arxiv.org/pdf/2310.11355v1,"[arxiv.Result.Author('Tara Kalsi'), arxiv.Result.Author('Alessandro Romito'), arxiv.Result.Author('Henning Schomerus')]",,2023-10-17 15:41:50+00:00,"A key conjecture about the evolution of complex quantum systems towards an
ergodic steady state, known as scrambling, is that this process acquires
universal features when it is most efficient. We develop a single-parameter
scaling theory for this scenario, which embodies exact self-similarity of the
spectral correlations along the complete scrambling dynamics. We establish that
the scaling predictions are matched by a privileged stochastic process, and
serve as bounds for other dynamical scrambling scenarios, allowing one to
quantify inefficient or incomplete scrambling on all timescales.",,quant-ph,"['quant-ph', 'cond-mat.stat-mech']",http://arxiv.org/abs/2310.11355v1
38,Learning by Teaching: Key Challenges and Design Implications,http://arxiv.org/pdf/2310.11354v1,"[arxiv.Result.Author('Amy Debbané'), arxiv.Result.Author('Ken Jen Lee'), arxiv.Result.Author('Jarvis Tse'), arxiv.Result.Author('Edith Law')]",10.1145/3579501,2023-10-17 15:40:43+00:00,"Benefits of learning by teaching (LbT) have been highlighted by previous
studies from a pedagogical lens, as well as through computer-supported systems.
However, the challenges that university students face in technology-mediated
LbT$\unicode{x2013}$whether it be teaching oneself, teaching a peer, or
teaching an agent$\unicode{x2013}$are not well understood. Furthermore, there
is a gap in knowledge on the challenges that students encounter throughout the
process of teaching (content selection, preparation, teaching, receiving and
giving feedback, and reflection) despite its importance to the design of LbT
platforms. Thus, we conducted a study with 24 university students where they
taught content they had not fully grasped, without guidance, and participated
in a semi-structured interview. Results demonstrate that participants
encountered the following challenges: psychological barriers relating to self
and others, and lack of know-how. Furthermore, we illuminate design
implications required to overcome these challenges and benefit from LbT without
requiring prior training in pedagogy.","Proc. ACM Hum.-Comput. Interact. 7, CSCW1, Article 68 (April
  2023), 34 pages",cs.HC,"['cs.HC', 'K.3.1; H.5.3']",http://arxiv.org/abs/2310.11354v1
39,Hybrid quantum-classical graph neural networks for tumor classification in digital pathology,http://arxiv.org/pdf/2310.11353v1,"[arxiv.Result.Author('Anupama Ray'), arxiv.Result.Author('Dhiraj Madan'), arxiv.Result.Author('Srushti Patil'), arxiv.Result.Author('Maria Anna Rapsomaniki'), arxiv.Result.Author('Pushpak Pati')]",,2023-10-17 15:40:26+00:00,"Advances in classical machine learning and single-cell technologies have
paved the way to understand interactions between disease cells and tumor
microenvironments to accelerate therapeutic discovery. However, challenges in
these machine learning methods and NP-hard problems in spatial Biology create
an opportunity for quantum computing algorithms. We create a hybrid
quantum-classical graph neural network (GNN) that combines GNN with a
Variational Quantum Classifier (VQC) for classifying binary sub-tasks in breast
cancer subtyping. We explore two variants of the same, the first with fixed
pretrained GNN parameters and the second with end-to-end training of GNN+VQC.
The results demonstrate that the hybrid quantum neural network (QNN) is at par
with the state-of-the-art classical graph neural networks (GNN) in terms of
weighted precision, recall and F1-score. We also show that by means of
amplitude encoding, we can compress information in logarithmic number of qubits
and attain better performance than using classical compression (which leads to
information loss while keeping the number of qubits required constant in both
regimes). Finally, we show that end-to-end training enables to improve over
fixed GNN parameters and also slightly improves over vanilla GNN with same
number of dimensions.",,quant-ph,"['quant-ph', 'eess.IV']",http://arxiv.org/abs/2310.11353v1
40,Large Deviations in the Symmetric Simple Exclusion Process with Slow Boundaries: A Hydrodynamic Approach,http://arxiv.org/pdf/2310.11350v1,"[arxiv.Result.Author('Soumyabrata Saha'), arxiv.Result.Author('Tridib Sadhu')]",,2023-10-17 15:39:25+00:00,"We revisit the one-dimensional model of the symmetric simple exclusion
process slowly coupled with two unequal reservoirs at the boundaries. In its
non-equilibrium stationary state, the large deviations functions of density and
current have been recently derived using exact microscopic analysis by Derrida
et al. in J. Stat. Phys. 182, 15 (2021). We present an independent derivation
using the hydrodynamic approach of the macroscopic fluctuation theory (MFT).
The slow coupling introduces additional boundary terms in the MFT-action which
modifies the spatial boundary conditions for the associated variational
problem. For the density large deviations, we explicitly solve the
corresponding Euler-Lagrange equation using a simple local transformation of
the optimal fields. For the current large deviations, our solution is obtained
using the additivity principle. In addition to recovering the expression of the
large deviation functions, our solution describes the most probable path for
these rare fluctuations.",,cond-mat.stat-mech,"['cond-mat.stat-mech', 'math-ph', 'math.MP']",http://arxiv.org/abs/2310.11350v1
41,Towards Generalizable Multi-Camera 3D Object Detection via Perspective Debiasing,http://arxiv.org/pdf/2310.11346v1,"[arxiv.Result.Author('Hao Lu'), arxiv.Result.Author('Yunpeng Zhang'), arxiv.Result.Author('Qing Lian'), arxiv.Result.Author('Dalong Du'), arxiv.Result.Author('Yingcong Chen')]",,2023-10-17 15:31:28+00:00,"Detecting objects in 3D space using multiple cameras, known as Multi-Camera
3D Object Detection (MC3D-Det), has gained prominence with the advent of
bird's-eye view (BEV) approaches. However, these methods often struggle when
faced with unfamiliar testing environments due to the lack of diverse training
data encompassing various viewpoints and environments. To address this, we
propose a novel method that aligns 3D detection with 2D camera plane results,
ensuring consistent and accurate detections. Our framework, anchored in
perspective debiasing, helps the learning of features resilient to domain
shifts. In our approach, we render diverse view maps from BEV features and
rectify the perspective bias of these maps, leveraging implicit foreground
volumes to bridge the camera and BEV planes. This two-step process promotes the
learning of perspective- and context-independent features, crucial for accurate
object detection across varying viewpoints, camera parameters and environment
conditions. Notably, our model-agnostic approach preserves the original network
structure without incurring additional inference costs, facilitating seamless
integration across various models and simplifying deployment. Furthermore, we
also show our approach achieves satisfactory results in real data when trained
only with virtual datasets, eliminating the need for real scene annotations.
Experimental results on both Domain Generalization (DG) and Unsupervised Domain
Adaptation (UDA) clearly demonstrate its effectiveness. Our code will be
released.",,cs.CV,['cs.CV'],http://arxiv.org/abs/2310.11346v1
42,The effect of stemming and lemmatization on Portuguese fake news text classification,http://arxiv.org/pdf/2310.11344v1,"[arxiv.Result.Author('Lucca de Freitas Santos'), arxiv.Result.Author('Murilo Varges da Silva')]",,2023-10-17 15:26:40+00:00,"With the popularization of the internet, smartphones and social media,
information is being spread quickly and easily way, which implies bigger
traffic of information in the world, but there is a problem that is harming
society with the dissemination of fake news. With a bigger flow of information,
some people are trying to disseminate deceptive information and fake news. The
automatic detection of fake news is a challenging task because to obtain a good
result is necessary to deal with linguistics problems, especially when we are
dealing with languages that not have been comprehensively studied yet, besides
that, some techniques can help to reach a good result when we are dealing with
text data, although, the motivation of detecting this deceptive information it
is in the fact that the people need to know which information is true and
trustful and which one is not. In this work, we present the effect the
pre-processing methods such as lemmatization and stemming have on fake news
classification, for that we designed some classifier models applying different
pre-processing techniques. The results show that the pre-processing step is
important to obtain betters results, the stemming and lemmatization techniques
are interesting methods and need to be more studied to develop techniques
focused on the Portuguese language so we can reach better results.",,cs.CL,"['cs.CL', 'cs.AI']",http://arxiv.org/abs/2310.11344v1
43,Dark matter scattering off ${}^4$He in chiral effective field theory,http://arxiv.org/pdf/2310.11343v1,"[arxiv.Result.Author('J. de Vries'), arxiv.Result.Author('C. Köber'), arxiv.Result.Author('A. Nogga'), arxiv.Result.Author('S. Shain')]",,2023-10-17 15:25:44+00:00,"We study dark matter scattering off ${}^4$He and other light nuclei using
chiral effective field theory. We consider scalar DM interactions and include
both one- and two-nucleon scattering processes. The DM interactions and nuclear
wave functions are obtained from chiral effective field theory and we work up
to fourth order in the chiral expansion for the latter to investigate the
chiral convergence. The results for the scattering rates can be used to
determine the sensitivity of planned experiments to detect relatively light
dark matter particles using ${}^4$He. We find that next-to-leading-order scalar
currents are smaller than expected from power counting for scattering off
${}^4$He confirming earlier work. However, the results for two-nucleon
corrections exhibit a linear regulator dependence indicating potential problems
in the applied power counting. We observe a linear correlation between the, in
principle not observable, D-wave probability of various light nuclei and the
scalar two-nucleon matrix elements, again pointing towards potentially missing
contributions.",,hep-ph,"['hep-ph', 'nucl-th']",http://arxiv.org/abs/2310.11343v1
44,Contextualized Machine Learning,http://arxiv.org/pdf/2310.11340v1,"[arxiv.Result.Author('Benjamin Lengerich'), arxiv.Result.Author('Caleb N. Ellington'), arxiv.Result.Author('Andrea Rubbi'), arxiv.Result.Author('Manolis Kellis'), arxiv.Result.Author('Eric P. Xing')]",,2023-10-17 15:23:00+00:00,"We examine Contextualized Machine Learning (ML), a paradigm for learning
heterogeneous and context-dependent effects. Contextualized ML estimates
heterogeneous functions by applying deep learning to the meta-relationship
between contextual information and context-specific parametric models. This is
a form of varying-coefficient modeling that unifies existing frameworks
including cluster analysis and cohort modeling by introducing two reusable
concepts: a context encoder which translates sample context into model
parameters, and sample-specific model which operates on sample predictors. We
review the process of developing contextualized models, nonparametric inference
from contextualized models, and identifiability conditions of contextualized
models. Finally, we present the open-source PyTorch package ContextualizedML.",,stat.ML,"['stat.ML', 'cs.LG']",http://arxiv.org/abs/2310.11340v1
45,Branching process representation for Burgers-like nonlinear partial differential equations,http://arxiv.org/pdf/2310.11338v1,"[arxiv.Result.Author('Jochem Hoogendijk'), arxiv.Result.Author('Ivan Kryven')]",,2023-10-17 15:19:04+00:00,"We show that a large class of first-order conservation PDEs can be
probabilistically represented using multi-type branching processes. The
representation holds when the initial conditions are linear combinations of
negative exponentials. This class contains Burgers' equation in 1D, which may
develop a gradient blow-up in finite time, as well as other equations with more
general nonlinearities. We also show how the time of gradient blow up can be
identified by studying criticality conditions of the corresponding branching
processes.",,math.AP,"['math.AP', 'math.PR', '35F20 (Primary) 35F25, 35Q35, 35Q82, 60J80, 60J85 (Secondary)']",http://arxiv.org/abs/2310.11338v1
46,Agent-Specific Effects,http://arxiv.org/pdf/2310.11334v1,"[arxiv.Result.Author('Stelios Triantafyllou'), arxiv.Result.Author('Aleksa Sukovic'), arxiv.Result.Author('Debmalya Mandal'), arxiv.Result.Author('Goran Radanovic')]",,2023-10-17 15:12:56+00:00,"Establishing causal relationships between actions and outcomes is fundamental
for accountable multi-agent decision-making. However, interpreting and
quantifying agents' contributions to such relationships pose significant
challenges. These challenges are particularly prominent in the context of
multi-agent sequential decision-making, where the causal effect of an agent's
action on the outcome depends on how the other agents respond to that action.
In this paper, our objective is to present a systematic approach for
attributing the causal effects of agents' actions to the influence they exert
on other agents. Focusing on multi-agent Markov decision processes, we
introduce agent-specific effects (ASE), a novel causal quantity that measures
the effect of an agent's action on the outcome that propagates through other
agents. We then turn to the counterfactual counterpart of ASE (cf-ASE), provide
a sufficient set of conditions for identifying cf-ASE, and propose a practical
sampling-based algorithm for estimating it. Finally, we experimentally evaluate
the utility of cf-ASE through a simulation-based testbed, which includes a
sepsis management environment.",,cs.AI,['cs.AI'],http://arxiv.org/abs/2310.11334v1
47,Key Point-based Orientation Estimation of Strawberries for Robotic Fruit Picking,http://arxiv.org/pdf/2310.11333v1,"[arxiv.Result.Author('Justin Le Louëdec'), arxiv.Result.Author('Grzegorz Cielniak')]",10.1007/978-3-031-44137-0_13,2023-10-17 15:12:11+00:00,"Selective robotic harvesting is a promising technological solution to address
labour shortages which are affecting modern agriculture in many parts of the
world. For an accurate and efficient picking process, a robotic harvester
requires the precise location and orientation of the fruit to effectively plan
the trajectory of the end effector. The current methods for estimating fruit
orientation employ either complete 3D information which typically requires
registration from multiple views or rely on fully-supervised learning
techniques, which require difficult-to-obtain manual annotation of the
reference orientation. In this paper, we introduce a novel key-point-based
fruit orientation estimation method allowing for the prediction of 3D
orientation from 2D images directly. The proposed technique can work without
full 3D orientation annotations but can also exploit such information for
improved accuracy. We evaluate our work on two separate datasets of strawberry
images obtained from real-world data collection scenarios. Our proposed method
achieves state-of-the-art performance with an average error as low as
$8^{\circ}$, improving predictions by $\sim30\%$ compared to previous work
presented in~\cite{wagner2021efficient}. Furthermore, our method is suited for
real-time robotic applications with fast inference times of $\sim30$ms.","Computer Vision Systems. ICVS 2023. Lecture Notes in Computer
  Science, vol 14253",cs.CV,"['cs.CV', 'cs.AI']",http://arxiv.org/abs/2310.11333v1
48,Discovering High-Quality Process Models Despite Data Scarcity,http://arxiv.org/pdf/2310.11332v1,"[arxiv.Result.Author('Jan Niklas Adams'), arxiv.Result.Author('Jari Peeperkorn'), arxiv.Result.Author('Tobias Brockhoff'), arxiv.Result.Author('Isabelle Terrier'), arxiv.Result.Author('Heiko Göhner'), arxiv.Result.Author('Merih Seran Uysal'), arxiv.Result.Author('Seppe vanden Broucke'), arxiv.Result.Author('Jochen De Weerdt'), arxiv.Result.Author('Wil M. P. van der Aalst')]",,2023-10-17 15:12:05+00:00,"Process discovery algorithms learn process models from executed activity
sequences, describing concurrency, causality, and conflict. Concurrent
activities require observing multiple permutations, increasing data
requirements, especially for processes with concurrent subprocesses such as
hierarchical, composite, or distributed processes. While process discovery
algorithms traditionally use sequences of activities as input, recently
introduced object-centric process discovery algorithms can use graphs of
activities as input, encoding partial orders between activities. As such, they
contain the concurrency information of many sequences in a single graph. In
this paper, we address the research question of reducing process discovery data
requirements when using object-centric event logs for process discovery. We
classify different real-life processes according to the control-flow complexity
within and between subprocesses and introduce an evaluation framework to assess
process discovery algorithm quality of traditional and object-centric process
discovery based on the sample size. We complement this with a large-scale
production process case study. Our results show reduced data requirements,
enabling the discovery of large, concurrent processes such as manufacturing
with little data, previously infeasible with traditional process discovery. Our
findings suggest that object-centric process mining could revolutionize process
discovery in various sectors, including manufacturing and supply chains.",,cs.DB,['cs.DB'],http://arxiv.org/abs/2310.11332v1
49,Modulation Transfer Spectroscopy of the D1 Transition of Potassium: Theory and Experiment,http://arxiv.org/pdf/2310.11327v1,"[arxiv.Result.Author('Andrew D. Innes'), arxiv.Result.Author('Prosenjit Majumder'), arxiv.Result.Author('Heung-Ryoul Noh'), arxiv.Result.Author('Simon. L. Cornish')]",,2023-10-17 15:05:40+00:00,"We report on a study of modulation transfer spectroscopy of the
$4\textrm{S}_{1/2}\rightarrow 4\textrm{P}_{1/2}$ (D\textsubscript{1})
transition of naturally abundant potassium in a room-temperature vapour cell.
This transition is critical for laser cooling and optical pumping of potassium
and our study is therefore motivated by the need for robust laser frequency
stabilisation. Despite the absence of a closed transition, the small
ground-state hyperfine splitting in potassium results in strong crossover
features in the D\textsubscript{1} modulation transfer spectrum. To emphasise
this we compare the D\textsubscript{1} and D\textsubscript{2} spectra of
potassium with those of rubidium. Further, we compare our experimental results
with a detailed theoretical simulation, examining different pump-probe
polarization configurations to identify the optimal signals for laser frequency
stabilisation. We find good agreement between the experiment and the theory,
especially for the $\textrm{lin} \parallel \textrm{lin}$ polarization
configuration.",,physics.atom-ph,['physics.atom-ph'],http://arxiv.org/abs/2310.11327v1
50,Integrated Sensing and Channel Estimation by Exploiting Dual Timescales for Delay-Doppler Alignment Modulation,http://arxiv.org/pdf/2310.11326v1,"[arxiv.Result.Author('Zhiqiang Xiao'), arxiv.Result.Author('Yong Zeng'), arxiv.Result.Author('Fuxi Wen'), arxiv.Result.Author('Zaichen Zhang'), arxiv.Result.Author('Derrick Wing Kwan Ng')]",,2023-10-17 15:04:40+00:00,"For integrated sensing and communication (ISAC) systems, the channel
information essential for communication and sensing tasks fluctuates across
different timescales. Specifically, wireless sensing primarily focuses on
acquiring path state information (PSI) (e.g., delay, angle, and Doppler) of
individual multi-path components to sense the environment, which usually
evolves much more slowly than the composite channel state information (CSI)
required for communications. Typically, the CSI is approximately unchanged
during the channel coherence time, which characterizes the statistical
properties of wireless communication channels. However, this concept is less
appropriate for describing that for wireless sensing. To this end, in this
paper, we introduce a new timescale to study the variation of the PSI from a
channel geometric perspective, termed path invariant time, during which the PSI
largely remains constant. Our analysis indicates that the path invariant time
considerably exceeds the channel coherence time. Thus, capitalizing on these
dual timescales of the wireless channel, in this paper, we propose a novel ISAC
framework exploiting the recently proposed delay-Doppler alignment modulation
(DDAM) technique. Different from most existing studies on DDAM that assume the
availability of perfect PSI, in this work, we propose a novel algorithm, termed
as adaptive simultaneously orthogonal matching pursuit with support refinement
(ASOMP-SR), for joint environment sensing and PSI estimation. We also analyze
the performance of DDAM with imperfectly sensed PSI.Simulation results unveil
that the proposed DDAM-based ISAC can achieve superior spectral efficiency and
a reduced peak-to-average power ratio (PAPR) compared to standard orthogonal
frequency division multiplexing (OFDM).",,cs.IT,"['cs.IT', 'eess.SP', 'math.IT']",http://arxiv.org/abs/2310.11326v1
51,Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting,http://arxiv.org/pdf/2310.11324v1,"[arxiv.Result.Author('Melanie Sclar'), arxiv.Result.Author('Yejin Choi'), arxiv.Result.Author('Yulia Tsvetkov'), arxiv.Result.Author('Alane Suhr')]",,2023-10-17 15:03:30+00:00,"As large language models (LLMs) are adopted as a fundamental component of
language technologies, it is crucial to accurately characterize their
performance. Because choices in prompt design can strongly influence model
behavior, this design process is critical in effectively using any modern
pre-trained generative language model. In this work, we focus on LLM
sensitivity to a quintessential class of meaning-preserving design choices:
prompt formatting. We find that several widely used open-source LLMs are
extremely sensitive to subtle changes in prompt formatting in few-shot
settings, with performance differences of up to 76 accuracy points when
evaluated using LLaMA-2-13B. Sensitivity remains even when increasing model
size, the number of few-shot examples, or performing instruction tuning. Our
analysis suggests that work evaluating LLMs with prompting-based methods would
benefit from reporting a range of performance across plausible prompt formats,
instead of the currently-standard practice of reporting performance on a single
format. We also show that format performance only weakly correlates between
models, which puts into question the methodological validity of comparing
models with an arbitrarily chosen, fixed prompt format. To facilitate
systematic analysis we propose FormatSpread, an algorithm that rapidly
evaluates a sampled set of plausible prompt formats for a given task, and
reports the interval of expected performance without accessing model weights.
Furthermore, we present a suite of analyses that characterize the nature of
this sensitivity, including exploring the influence of particular atomic
perturbations and the internal representation of particular formats.",,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']",http://arxiv.org/abs/2310.11324v1
52,Towards Generic Semi-Supervised Framework for Volumetric Medical Image Segmentation,http://arxiv.org/pdf/2310.11320v1,"[arxiv.Result.Author('Haonan Wang'), arxiv.Result.Author('Xiaomeng Li')]",,2023-10-17 14:58:18+00:00,"Volume-wise labeling in 3D medical images is a time-consuming task that
requires expertise. As a result, there is growing interest in using
semi-supervised learning (SSL) techniques to train models with limited labeled
data. However, the challenges and practical applications extend beyond SSL to
settings such as unsupervised domain adaptation (UDA) and semi-supervised
domain generalization (SemiDG). This work aims to develop a generic SSL
framework that can handle all three settings. We identify two main obstacles to
achieving this goal in the existing SSL framework: 1) the weakness of capturing
distribution-invariant features; and 2) the tendency for unlabeled data to be
overwhelmed by labeled data, leading to over-fitting to the labeled data during
training. To address these issues, we propose an Aggregating & Decoupling
framework. The aggregating part consists of a Diffusion encoder that constructs
a common knowledge set by extracting distribution-invariant features from
aggregated information from multiple distributions/domains. The decoupling part
consists of three decoders that decouple the training process with labeled and
unlabeled data, thus avoiding over-fitting to labeled data, specific domains
and classes. We evaluate our proposed framework on four benchmark datasets for
SSL, Class-imbalanced SSL, UDA and SemiDG. The results showcase notable
improvements compared to state-of-the-art methods across all four settings,
indicating the potential of our framework to tackle more challenging SSL
scenarios. Code and models are available at:
https://github.com/xmed-lab/GenericSSL.",,eess.IV,"['eess.IV', 'cs.CV']",http://arxiv.org/abs/2310.11320v1
53,Utilising a Large Language Model to Annotate Subject Metadata: A Case Study in an Australian National Research Data Catalogue,http://arxiv.org/pdf/2310.11318v1,"[arxiv.Result.Author('Shiwei Zhang'), arxiv.Result.Author('Mingfang Wu'), arxiv.Result.Author('Xiuzhen Zhang')]",,2023-10-17 14:52:33+00:00,"In support of open and reproducible research, there has been a rapidly
increasing number of datasets made available for research. As the availability
of datasets increases, it becomes more important to have quality metadata for
discovering and reusing them. Yet, it is a common issue that datasets often
lack quality metadata due to limited resources for data curation. Meanwhile,
technologies such as artificial intelligence and large language models (LLMs)
are progressing rapidly. Recently, systems based on these technologies, such as
ChatGPT, have demonstrated promising capabilities for certain data curation
tasks. This paper proposes to leverage LLMs for cost-effective annotation of
subject metadata through the LLM-based in-context learning. Our method employs
GPT-3.5 with prompts designed for annotating subject metadata, demonstrating
promising performance in automatic metadata annotation. However, models based
on in-context learning cannot acquire discipline-specific rules, resulting in
lower performance in several categories. This limitation arises from the
limited contextual information available for subject inference. To the best of
our knowledge, we are introducing, for the first time, an in-context learning
method that harnesses large language models for automated subject metadata
annotation.",,cs.CL,"['cs.CL', 'cs.AI']",http://arxiv.org/abs/2310.11318v1
54,QADYNAMICS: Training Dynamics-Driven Synthetic QA Diagnostic for Zero-Shot Commonsense Question Answering,http://arxiv.org/pdf/2310.11303v1,"[arxiv.Result.Author('Haochen Shi'), arxiv.Result.Author('Weiqi Wang'), arxiv.Result.Author('Tianqing Fang'), arxiv.Result.Author('Baixuan Xu'), arxiv.Result.Author('Wenxuan Ding'), arxiv.Result.Author('Xin Liu'), arxiv.Result.Author('Yangqiu Song')]",,2023-10-17 14:27:34+00:00,"Zero-shot commonsense Question-Answering (QA) requires models to reason about
general situations beyond specific benchmarks. State-of-the-art approaches
fine-tune language models on QA pairs constructed from CommonSense Knowledge
Bases (CSKBs) to equip the models with more commonsense knowledge in a QA
context. However, current QA synthesis protocols may introduce noise from the
CSKBs and generate ungrammatical questions and false negative options, which
impede the model's ability to generalize. To address these issues, we propose
QADYNAMICS, a training dynamics-driven framework for QA diagnostics and
refinement. Our approach analyzes the training dynamics of each QA pair at both
the question level and option level, discarding machine-detectable artifacts by
removing uninformative QA pairs and mislabeled or false-negative options.
Extensive experiments demonstrate the effectiveness of our approach, which
outperforms all baselines while using only 33% of the synthetic data, even
including LLMs such as ChatGPT. Moreover, expert evaluations confirm that our
framework significantly improves the quality of QA synthesis. Our codes and
model checkpoints are available at
https://github.com/HKUST-KnowComp/QaDynamics.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11303v1
55,Source Code Comprehension: A Contemporary Definition and Conceptual Model for Empirical Investigation,http://arxiv.org/pdf/2310.11301v1,[arxiv.Result.Author('Marvin Wyrich')],,2023-10-17 14:23:46+00:00,"Be it in debugging, testing, code review or, more recently, pair programming
with AI assistance: in all these activities, software engineers need to
understand source code. Accordingly, plenty of research is taking place in the
field to find out, for example, what makes code easy to understand and which
tools can best support developers in their comprehension process. And while any
code comprehension researcher certainly has a rough idea of what they mean when
they mention a developer having a good understanding of a piece of code, to
date, the research community has not managed to define source code
comprehension as a concept. Instead, in primary research on code comprehension,
an implicit definition by task prevails, i.e., code comprehension is what the
experimental tasks measure. This approach has two negative consequences. First,
it makes it difficult to conduct secondary research. Currently, each code
comprehension primary study uses different comprehension tasks and measures,
and thus it is not clear whether different studies intend to measure the same
construct. Second, authors of a primary study run into the difficulty of
justifying their design decisions without a definition of what they attempt to
measure. An operationalization of an insufficiently described construct occurs,
which poses a threat to construct validity.
  The task of defining code comprehension considering the theory of the past
fifty years is not an easy one. Nor is it a task that every author of a primary
study must accomplish on their own. Therefore, this paper constitutes a
reference work that defines source code comprehension and presents a conceptual
framework in which researchers can anchor their empirical code comprehension
research.",,cs.SE,['cs.SE'],http://arxiv.org/abs/2310.11301v1
56,"A high fidelity Milky Way simulation with Kraken, Gaia-Enceladus, and Sequoia analogues: clues to their accretion histories",http://arxiv.org/pdf/2310.11300v1,"[arxiv.Result.Author('Guacimara García-Bethencourt'), arxiv.Result.Author('Chris B. Brook'), arxiv.Result.Author('Robert J. J. Grand'), arxiv.Result.Author('Daisuke Kawata')]",10.1093/mnras/stad2832,2023-10-17 14:21:56+00:00,"Within a simulated Milky Way-like galaxy, we identify and analyse analogues
of the Gaia-Enceladus (GE), Kraken and Sequoia mergers that each matches
remarkably well observational results, including in velocity and chemical
abundance space, and their distributions in the $j_{z}$-Energy plane. The
Kraken analogue is the earliest merger and has the highest total mass ratio.
Consistent with previous studies, it is chemically indistinguishable from old
in-situ stars at the time of its accretion. The GE and Sequoia analogue events
accrete at similar times in our simulation, both along filaments but from
opposite sides of the main galaxy. The mean stellar ages of the GE and Sequoia
analogues are both similar and, from our simulation results, we see that they
can be separate entities and still naturally reproduce the observed properties
of their stellar remnants at the present day, including the significant
retrograde velocities of the Sequoia analogue remnant stars and the difference
in the tracks of the two galaxies through chemical abundance space. Our results
provide supporting information about the properties of these three merger
events, and show for the first time that they can all be reproduced with a
fully cosmological simulation, providing a possible self consistent
evolutionary pathway for the Milky Way's formation.","Monthly Notices of the Royal Astronomical Society, Volume 526,
  Issue 1, November 2023, Pages 1190-1197",astro-ph.GA,['astro-ph.GA'],http://arxiv.org/abs/2310.11300v1
57,Automatic Coronary Artery Plaque Quantification and CAD-RADS Prediction using Mesh Priors,http://arxiv.org/pdf/2310.11297v1,"[arxiv.Result.Author('Rudolf L. M. van Herten'), arxiv.Result.Author('Nils Hampe'), arxiv.Result.Author('Richard A. P. Takx'), arxiv.Result.Author('Klaas Jan Franssen'), arxiv.Result.Author('Yining Wang'), arxiv.Result.Author('Dominika Suchá'), arxiv.Result.Author('José P. Henriques'), arxiv.Result.Author('Tim Leiner'), arxiv.Result.Author('R. Nils Planken'), arxiv.Result.Author('Ivana Išgum')]",,2023-10-17 14:19:56+00:00,"Coronary artery disease (CAD) remains the leading cause of death worldwide.
Patients with suspected CAD undergo coronary CT angiography (CCTA) to evaluate
the risk of cardiovascular events and determine the treatment. Clinical
analysis of coronary arteries in CCTA comprises the identification of
atherosclerotic plaque, as well as the grading of any coronary artery stenosis
typically obtained through the CAD-Reporting and Data System (CAD-RADS). This
requires analysis of the coronary lumen and plaque. While voxel-wise
segmentation is a commonly used approach in various segmentation tasks, it does
not guarantee topologically plausible shapes. To address this, in this work, we
propose to directly infer surface meshes for coronary artery lumen and plaque
based on a centerline prior and use it in the downstream task of CAD-RADS
scoring. The method is developed and evaluated using a total of 2407 CCTA
scans. Our method achieved lesion-wise volume intraclass correlation
coefficients of 0.98, 0.79, and 0.85 for calcified, non-calcified, and total
plaque volume respectively. Patient-level CAD-RADS categorization was evaluated
on a representative hold-out test set of 300 scans, for which the achieved
linearly weighted kappa ($\kappa$) was 0.75. CAD-RADS categorization on the set
of 658 scans from another hospital and scanner led to a $\kappa$ of 0.71. The
results demonstrate that direct inference of coronary artery meshes for lumen
and plaque is feasible, and allows for the automated prediction of routinely
performed CAD-RADS categorization.",,eess.IV,['eess.IV'],http://arxiv.org/abs/2310.11297v1
58,CorrTalk: Correlation Between Hierarchical Speech and Facial Activity Variances for 3D Animation,http://arxiv.org/pdf/2310.11295v1,"[arxiv.Result.Author('Zhaojie Chu'), arxiv.Result.Author('Kailing Guo'), arxiv.Result.Author('Xiaofen Xing'), arxiv.Result.Author('Yilin Lan'), arxiv.Result.Author('Bolun Cai'), arxiv.Result.Author('Xiangmin Xu')]",,2023-10-17 14:16:42+00:00,"Speech-driven 3D facial animation is a challenging cross-modal task that has
attracted growing research interest. During speaking activities, the mouth
displays strong motions, while the other facial regions typically demonstrate
comparatively weak activity levels. Existing approaches often simplify the
process by directly mapping single-level speech features to the entire facial
animation, which overlook the differences in facial activity intensity leading
to overly smoothed facial movements. In this study, we propose a novel
framework, CorrTalk, which effectively establishes the temporal correlation
between hierarchical speech features and facial activities of different
intensities across distinct regions. A novel facial activity intensity metric
is defined to distinguish between strong and weak facial activity, obtained by
computing the short-time Fourier transform of facial vertex displacements.
Based on the variances in facial activity, we propose a dual-branch decoding
framework to synchronously synthesize strong and weak facial activity, which
guarantees wider intensity facial animation synthesis. Furthermore, a weighted
hierarchical feature encoder is proposed to establish temporal correlation
between hierarchical speech features and facial activity at different
intensities, which ensures lip-sync and plausible facial expressions. Extensive
qualitatively and quantitatively experiments as well as a user study indicate
that our CorrTalk outperforms existing state-of-the-art methods. The source
code and supplementary video are publicly available at:
https://zjchu.github.io/projects/CorrTalk/",,cs.CV,"['cs.CV', 'cs.CG']",http://arxiv.org/abs/2310.11295v1
59,Fair Reward Distribution in Federated Byzantine Agreement Systems,http://arxiv.org/pdf/2310.11294v1,"[arxiv.Result.Author('Charmaine Ndolo'), arxiv.Result.Author('Martin Florian'), arxiv.Result.Author('Florian Tschorsch')]",,2023-10-17 14:16:28+00:00,"Federated Byzantine Agreement Systems (FBASs) offer a solution to consensus
in permissionless systems by adapting the well-studied Byzantine agreement
model to permissionless consensus. Unlike its counterparts in the context of
permissionless consensus, the FBAS system model does not offer validating nodes
protocol-level incentives although they are entrusted with safeguarding and
ensuring the functionality of the system. Multiple studies have reported on the
small number of active validators in these systems leading to some concerns
about their resilience. To this end, this paper studies how rewards can be
distributed in FBASs and presents a fair reward distribution function for
FBASs. The challenge is that, on the one hand, consensus in an FBAS is found
jointly between all nodes and, on the other hand, nodes do not all contribute
equally to this process. We draw on game-theoretic methods to quantify these
contributions bearing the overall health of the FBAS in mind and present a fair
reward distribution function which we evaluate based on a set of identified
properties.",,cs.NI,"['cs.NI', 'cs.GT']",http://arxiv.org/abs/2310.11294v1
60,An Automatic Learning Rate Schedule Algorithm for Achieving Faster Convergence and Steeper Descent,http://arxiv.org/pdf/2310.11291v1,"[arxiv.Result.Author('Zhao Song'), arxiv.Result.Author('Chiwun Yang')]",,2023-10-17 14:15:57+00:00,"The delta-bar-delta algorithm is recognized as a learning rate adaptation
technique that enhances the convergence speed of the training process in
optimization by dynamically scheduling the learning rate based on the
difference between the current and previous weight updates. While this
algorithm has demonstrated strong competitiveness in full data optimization
when compared to other state-of-the-art algorithms like Adam and SGD, it may
encounter convergence issues in mini-batch optimization scenarios due to the
presence of noisy gradients.
  In this study, we thoroughly investigate the convergence behavior of the
delta-bar-delta algorithm in real-world neural network optimization. To address
any potential convergence challenges, we propose a novel approach called RDBD
(Regrettable Delta-Bar-Delta). Our approach allows for prompt correction of
biased learning rate adjustments and ensures the convergence of the
optimization process. Furthermore, we demonstrate that RDBD can be seamlessly
integrated with any optimization algorithm and significantly improve the
convergence speed.
  By conducting extensive experiments and evaluations, we validate the
effectiveness and efficiency of our proposed RDBD approach. The results
showcase its capability to overcome convergence issues in mini-batch
optimization and its potential to enhance the convergence speed of various
optimization algorithms. This research contributes to the advancement of
optimization techniques in neural network training, providing practitioners
with a reliable automatic learning rate scheduler for achieving faster
convergence and improved optimization outcomes.",,cs.LG,['cs.LG'],http://arxiv.org/abs/2310.11291v1
61,Search for non-resonant Higgs boson pair production in the $2b + 2\ell + E_\mathrm{T}^\mathrm{miss}$ final state in $pp$ collisions at $\sqrt{s} = 13\mathrm{TeV}$ with the ATLAS detector,http://arxiv.org/pdf/2310.11286v1,[arxiv.Result.Author('ATLAS Collaboration')],,2023-10-17 14:08:39+00:00,"A search for non-resonant Higgs boson pair ($HH$) production is presented, in
which one of the Higgs bosons decays to a b-quark pair ($b\bar b$) and the
other decays to $WW^*$, $ZZ^*$, or $\tau^+\tau^-$, with in each case a final
state with $\ell^+\ell^- +$ neutrinos ($\ell = e, \mu$). The analysis targets
separately the gluon-gluon fusion and vector boson fusion production modes.
Data recorded by the ATLAS detector in proton-proton collisions at a
centre-of-mass energy of 13 TeV at the Large Hadron Collider, corresponding to
an integrated luminosity of $140\mathrm{fb}^{-1}$, are used in this analysis.
Events are selected to have exactly two $b$-tagged jets and two leptons with
opposite electric charge and missing transverse momentum in the final state.
These events are classified using multivariate analysis algorithms to separate
the $HH$ events from other Standard Model processes. No evidence of the signal
is found. The observed (expected) upper limit on the cross-section for
non-resonant Higgs boson pair production is determined to be 9.7 (16.2) times
the Standard Model prediction at 95% confidence level. The Higgs boson
self-interaction coupling parameter $\kappa_\lambda$ and the quadrilinear
coupling parameter $\kappa_{2V}$ are each separately constrained by this
analysis to be within the ranges ${[-6.2, 13.3]}$ and ${[-0.17, 2.4]}$,
respectively, at 95% confidence level, when all other parameters are fixed.",,hep-ex,['hep-ex'],http://arxiv.org/abs/2310.11286v1
62,"ChapGTP, ILLC's Attempt at Raising a BabyLM: Improving Data Efficiency by Automatic Task Formation",http://arxiv.org/pdf/2310.11282v1,"[arxiv.Result.Author('Jaap Jumelet'), arxiv.Result.Author('Michael Hanna'), arxiv.Result.Author('Marianne de Heer Kloots'), arxiv.Result.Author('Anna Langedijk'), arxiv.Result.Author('Charlotte Pouw'), arxiv.Result.Author('Oskar van der Wal')]",,2023-10-17 14:06:06+00:00,"We present the submission of the ILLC at the University of Amsterdam to the
BabyLM challenge (Warstadt et al., 2023), in the strict-small track. Our final
model, ChapGTP, is a masked language model that was trained for 200 epochs,
aided by a novel data augmentation technique called Automatic Task Formation.
We discuss in detail the performance of this model on the three evaluation
suites: BLiMP, (Super)GLUE, and MSGS. Furthermore, we present a wide range of
methods that were ultimately not included in the model, but may serve as
inspiration for training LMs in low-resource settings.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11282v1
63,Proof of a conjecture of Kudla and Rallis on quotients of degenerate principal series,http://arxiv.org/pdf/2310.11280v1,[arxiv.Result.Author('Johannes Droschl')],,2023-10-17 14:03:31+00:00,"In this paper we prove a conjecture of Kudla and Rallis. Let $\chi$ be a
unitary character, $s\in \mathbb{C}$ and $W$ a symplectic vector space over a
non-archimedean field with symmetry group $G(W)$. Denote by $I(\chi,s)$ the
degenerate principal series representation of $G(W\oplus W)$. Pulling back
$I(\chi,s)$ along the natural embedding $G(W)\times G(W)\hookrightarrow
G(W\oplus W)$ gives a representation $I_{W,W}(\chi,s)$ of $G(W)\times G(W)$.
Let $\pi,\pi'$ be irreducible smooth complex representations of $G(W)$. We then
prove \[\dim _\mathbb{C}\mathrm{Hom}_{G(W)\times
G(W)}(I_{W,W}(\chi,s),\pi\otimes \pi')\le 1\] with equality if and only if
$\pi^\lor\cong \pi'$. We also give analogous statements for $W$ orthogonal or
unitary. This gives in particular a new proof of the conservation relation of
the local Theta correspondence for symplectic-orthogonal and unitary dual
pairs.",,math.RT,"['math.RT', '22E46, 22E50']",http://arxiv.org/abs/2310.11280v1
64,Video Super-Resolution Using a Grouped Residual in Residual Network,http://arxiv.org/pdf/2310.11276v1,"[arxiv.Result.Author('MohammadHossein Ashoori'), arxiv.Result.Author('Arash Amini')]",,2023-10-17 13:55:43+00:00,"Super-resolution (SR) is the technique of increasing the nominal resolution
of image / video content accompanied with quality improvement. Video
super-resolution (VSR) can be considered as the generalization of single image
super-resolution (SISR). This generalization should be such that more detail is
created in the output using adjacent input frames. In this paper, we propose a
grouped residual in residual network (GRRN) for VSR. By adjusting the
hyperparameters of the proposed structure, we train three networks with
different numbers of parameters and compare their quantitative and qualitative
results with the existing methods. Although based on some quantitative
criteria, GRRN does not provide better results than the existing methods, in
terms of the quality of the output image it has acceptable performance.",,eess.IV,"['eess.IV', 'cs.CV']",http://arxiv.org/abs/2310.11276v1
65,xMEN: A Modular Toolkit for Cross-Lingual Medical Entity Normalization,http://arxiv.org/pdf/2310.11275v1,"[arxiv.Result.Author('Florian Borchert'), arxiv.Result.Author('Ignacio Llorca'), arxiv.Result.Author('Roland Roller'), arxiv.Result.Author('Bert Arnrich'), arxiv.Result.Author('Matthieu-P. Schapranow')]",,2023-10-17 13:53:57+00:00,"Objective: To improve performance of medical entity normalization across many
languages, especially when fewer language resources are available compared to
English.
  Materials and Methods: We introduce xMEN, a modular system for cross-lingual
medical entity normalization, which performs well in both low- and
high-resource scenarios. When synonyms in the target language are scarce for a
given terminology, we leverage English aliases via cross-lingual candidate
generation. For candidate ranking, we incorporate a trainable cross-encoder
model if annotations for the target task are available. We also evaluate
cross-encoders trained in a weakly supervised manner based on
machine-translated datasets from a high resource domain. Our system is publicly
available as an extensible Python toolkit.
  Results: xMEN improves the state-of-the-art performance across a wide range
of multilingual benchmark datasets. Weakly supervised cross-encoders are
effective when no training data is available for the target task. Through the
compatibility of xMEN with the BigBIO framework, it can be easily used with
existing and prospective datasets.
  Discussion: Our experiments show the importance of balancing the output of
general-purpose candidate generators with subsequent trainable re-rankers,
which we achieve through a rank regularization term in the loss function of the
cross-encoder. However, error analysis reveals that multi-word expressions and
other complex entities are still challenging.
  Conclusion: xMEN exhibits strong performance for medical entity normalization
in multiple languages, even when no labeled data and few terminology aliases
for the target language are available. Its configuration system and evaluation
modules enable reproducible benchmarks. Models and code are available online at
the following URL: https://github.com/hpi-dhc/xmen",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11275v1
66,Optical chiral sorting forces and their manifestation in evanescent waves and nanofibres,http://arxiv.org/pdf/2310.11272v1,"[arxiv.Result.Author('Sebastian Golat'), arxiv.Result.Author('Jack J. Kingsley-Smith'), arxiv.Result.Author('Iago Diez'), arxiv.Result.Author('Josep Martinez-Romeu'), arxiv.Result.Author('Alejandro Martínez'), arxiv.Result.Author('Francisco J. Rodríguez-Fortuño')]",,2023-10-17 13:45:44+00:00,"Optical fields can exert forces of chiral nature on molecules and
nanoparticles, which would prove extremely valuable in the separation of
enantiomers with pharmaceutical applications, yet it is inherently complex, and
the varied frameworks used in the literature further complicate the theoretical
understanding. This paper unifies existing approaches used to describe dipolar
optical forces and introduces a new symmetry-based `force basis' consisting of
twelve vector fields, each weighted by particle-specific coefficients, for a
streamlined description of force patterns. The approach is rigorously applied
to evanescent waves and dielectric nanofibres, yielding concise analytical
expressions for optical forces. Through this, we identify optimal strategies
for enantiomer separation, offering invaluable guidance for future experiments.",,physics.optics,['physics.optics'],http://arxiv.org/abs/2310.11272v1
67,Thermodynamic cost of finite-time stochastic resetting,http://arxiv.org/pdf/2310.11267v1,"[arxiv.Result.Author('Kristian Stølevik Olsen'), arxiv.Result.Author('Deepak Gupta'), arxiv.Result.Author('Francesco Mori'), arxiv.Result.Author('Supriya Krishnamurthy')]",,2023-10-17 13:40:36+00:00,"Recent experiments have implemented resetting by means of an external trap,
whereby a system relaxes to the minimum of the trap and is reset in a finite
time. In this work, we set up and analyze the thermodynamics of such a
protocol. We present a general framework, even valid for non-Poissonian
resetting, that captures the thermodynamic work required to maintain a
resetting process up to a given observation time, and exactly calculate the
moment generating function of this work. Our framework is valid for a wide
range of systems, the only assumption being of relaxation to equilibrium in the
resetting trap. Examples and extensions are considered, including the validity
of fluctuation theorems. In the case of Brownian motion, we investigate optimal
resetting schemes that minimize work and its fluctuations, the mean work for
arbitrary switching protocols and comparisons to earlier-studied resetting
schemes. Numerical simulations are performed to validate our findings.",,cond-mat.stat-mech,"['cond-mat.stat-mech', 'cond-mat.soft']",http://arxiv.org/abs/2310.11267v1
68,Emulating Human Cognitive Processes for Expert-Level Medical Question-Answering with Large Language Models,http://arxiv.org/pdf/2310.11266v1,"[arxiv.Result.Author('Khushboo Verma'), arxiv.Result.Author('Marina Moore'), arxiv.Result.Author('Stephanie Wottrich'), arxiv.Result.Author('Karla Robles López'), arxiv.Result.Author('Nishant Aggarwal'), arxiv.Result.Author('Zeel Bhatt'), arxiv.Result.Author('Aagamjit Singh'), arxiv.Result.Author('Bradford Unroe'), arxiv.Result.Author('Salah Basheer'), arxiv.Result.Author('Nitish Sachdeva'), arxiv.Result.Author('Prinka Arora'), arxiv.Result.Author('Harmanjeet Kaur'), arxiv.Result.Author('Tanupreet Kaur'), arxiv.Result.Author('Tevon Hood'), arxiv.Result.Author('Anahi Marquez'), arxiv.Result.Author('Tushar Varshney'), arxiv.Result.Author('Nanfu Deng'), arxiv.Result.Author('Azaan Ramani'), arxiv.Result.Author('Pawanraj Ishwara'), arxiv.Result.Author('Maimoona Saeed'), arxiv.Result.Author('Tatiana López Velarde Peña'), arxiv.Result.Author('Bryan Barksdale'), arxiv.Result.Author('Sushovan Guha'), arxiv.Result.Author('Satwant Kumar')]",,2023-10-17 13:39:26+00:00,"In response to the pressing need for advanced clinical problem-solving tools
in healthcare, we introduce BooksMed, a novel framework based on a Large
Language Model (LLM). BooksMed uniquely emulates human cognitive processes to
deliver evidence-based and reliable responses, utilizing the GRADE (Grading of
Recommendations, Assessment, Development, and Evaluations) framework to
effectively quantify evidence strength. For clinical decision-making to be
appropriately assessed, an evaluation metric that is clinically aligned and
validated is required. As a solution, we present ExpertMedQA, a multispecialty
clinical benchmark comprised of open-ended, expert-level clinical questions,
and validated by a diverse group of medical professionals. By demanding an
in-depth understanding and critical appraisal of up-to-date clinical
literature, ExpertMedQA rigorously evaluates LLM performance. BooksMed
outperforms existing state-of-the-art models Med-PaLM 2, Almanac, and ChatGPT
in a variety of medical scenarios. Therefore, a framework that mimics human
cognitive stages could be a useful tool for providing reliable and
evidence-based responses to clinical inquiries.",,cs.CL,"['cs.CL', 'cs.AI', 'cs.NE']",http://arxiv.org/abs/2310.11266v1
69,Image Compression using only Attention based Neural Networks,http://arxiv.org/pdf/2310.11265v1,"[arxiv.Result.Author('Natacha Luka'), arxiv.Result.Author('Romain Negrel'), arxiv.Result.Author('David Picard')]",,2023-10-17 13:38:38+00:00,"In recent research, Learned Image Compression has gained prominence for its
capacity to outperform traditional handcrafted pipelines, especially at low
bit-rates. While existing methods incorporate convolutional priors with
occasional attention blocks to address long-range dependencies, recent advances
in computer vision advocate for a transformative shift towards fully
transformer-based architectures grounded in the attention mechanism. This paper
investigates the feasibility of image compression exclusively using attention
layers within our novel model, QPressFormer. We introduce the concept of
learned image queries to aggregate patch information via cross-attention,
followed by quantization and coding techniques. Through extensive evaluations,
our work demonstrates competitive performance achieved by convolution-free
architectures across the popular Kodak, DIV2K, and CLIC datasets.",,eess.IV,"['eess.IV', 'cs.CV']",http://arxiv.org/abs/2310.11265v1
70,Direct measurement of spin-flip rates in single-electron tunneling,http://arxiv.org/pdf/2310.11259v1,"[arxiv.Result.Author('Olfa Dani'), arxiv.Result.Author('Robert Hussein'), arxiv.Result.Author('Johannes C. Bayer'), arxiv.Result.Author('Klaus Pierz'), arxiv.Result.Author('Sigmund Kohler'), arxiv.Result.Author('Rolf J. Haug')]",,2023-10-17 13:28:34+00:00,"Spin-flips are one of the limiting factors for spin-based information
processing. We demonstrate a transport approach for determining the spin-flip
rates of a self-assembled InAs double quantum dot. In such devices, different
Land\'e factors lead to an inhomogeneous Zeeman splitting, so that the two spin
channels can never be at resonance simultaneously, leading to a spin blockade
at low temperatures. This blockade is analyzed in terms of spin flips for
different temperatures and magnetic fields. Our results are in good agreement
with a quantum master equation that combines the dot-lead couplings with an
ohmic spin-boson model for the dissipative spin dynamics.",,cond-mat.mes-hall,['cond-mat.mes-hall'],http://arxiv.org/abs/2310.11259v1
71,Utilizing Weak Supervision To Generate Indonesian Conservation Dataset,http://arxiv.org/pdf/2310.11258v1,"[arxiv.Result.Author('Mega Fransiska'), arxiv.Result.Author('Diah Pitaloka'), arxiv.Result.Author('Saripudin'), arxiv.Result.Author('Satrio Putra'), arxiv.Result.Author('Lintang Sutawika')]",,2023-10-17 13:23:18+00:00,"Weak supervision has emerged as a promising approach for rapid and
large-scale dataset creation in response to the increasing demand for
accelerated NLP development. By leveraging labeling functions, weak supervision
allows practitioners to generate datasets quickly by creating learned label
models that produce soft-labeled datasets. This paper aims to show how such an
approach can be utilized to build an Indonesian NLP dataset from conservation
news text. We construct two types of datasets: multi-class classification and
sentiment classification. We then provide baseline experiments using various
pretrained language models. These baseline results demonstrate test
performances of 59.79% accuracy and 55.72% F1-score for sentiment
classification, 66.87% F1-score-macro, 71.5% F1-score-micro, and 83.67% ROC-AUC
for multi-class classification. Additionally, we release the datasets and
labeling functions used in this work for further research and exploration.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11258v1
72,Revealing the Unwritten: Visual Investigation of Beam Search Trees to Address Language Model Prompting Challenges,http://arxiv.org/pdf/2310.11252v1,"[arxiv.Result.Author('Thilo Spinner'), arxiv.Result.Author('Rebecca Kehlbeck'), arxiv.Result.Author('Rita Sevastjanova'), arxiv.Result.Author('Tobias Stähle'), arxiv.Result.Author('Daniel A. Keim'), arxiv.Result.Author('Oliver Deussen'), arxiv.Result.Author('Andreas Spitz'), arxiv.Result.Author('Mennatallah El-Assady')]",,2023-10-17 13:20:16+00:00,"The growing popularity of generative language models has amplified interest
in interactive methods to guide model outputs. Prompt refinement is considered
one of the most effective means to influence output among these methods. We
identify several challenges associated with prompting large language models,
categorized into data- and model-specific, linguistic, and socio-linguistic
challenges. A comprehensive examination of model outputs, including runner-up
candidates and their corresponding probabilities, is needed to address these
issues. The beam search tree, the prevalent algorithm to sample model outputs,
can inherently supply this information. Consequently, we introduce an
interactive visual method for investigating the beam search tree, facilitating
analysis of the decisions made by the model during generation. We
quantitatively show the value of exposing the beam search tree and present five
detailed analysis scenarios addressing the identified challenges. Our
methodology validates existing results and offers additional insights.",,cs.CL,"['cs.CL', 'cs.AI', 'cs.HC', 'H.5.2; I.2.7']",http://arxiv.org/abs/2310.11252v1
73,Leveraging Large Language Model for Automatic Evolving of Industrial Data-Centric R&D Cycle,http://arxiv.org/pdf/2310.11249v1,"[arxiv.Result.Author('Xu Yang'), arxiv.Result.Author('Xiao Yang'), arxiv.Result.Author('Weiqing Liu'), arxiv.Result.Author('Jinhui Li'), arxiv.Result.Author('Peng Yu'), arxiv.Result.Author('Zeqi Ye'), arxiv.Result.Author('Jiang Bian')]",,2023-10-17 13:18:02+00:00,"In the wake of relentless digital transformation, data-driven solutions are
emerging as powerful tools to address multifarious industrial tasks such as
forecasting, anomaly detection, planning, and even complex decision-making.
Although data-centric R&D has been pivotal in harnessing these solutions, it
often comes with significant costs in terms of human, computational, and time
resources. This paper delves into the potential of large language models (LLMs)
to expedite the evolution cycle of data-centric R&D. Assessing the foundational
elements of data-centric R&D, including heterogeneous task-related data,
multi-facet domain knowledge, and diverse computing-functional tools, we
explore how well LLMs can understand domain-specific requirements, generate
professional ideas, utilize domain-specific tools to conduct experiments,
interpret results, and incorporate knowledge from past endeavors to tackle new
challenges. We take quantitative investment research as a typical example of
industrial data-centric R&D scenario and verified our proposed framework upon
our full-stack open-sourced quantitative research platform Qlib and obtained
promising results which shed light on our vision of automatic evolving of
industrial data-centric R&D cycle.",,cs.AI,"['cs.AI', 'q-fin.GN']",http://arxiv.org/abs/2310.11249v1
74,CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code Completion,http://arxiv.org/pdf/2310.11248v1,"[arxiv.Result.Author('Yangruibo Ding'), arxiv.Result.Author('Zijian Wang'), arxiv.Result.Author('Wasi Uddin Ahmad'), arxiv.Result.Author('Hantian Ding'), arxiv.Result.Author('Ming Tan'), arxiv.Result.Author('Nihal Jain'), arxiv.Result.Author('Murali Krishna Ramanathan'), arxiv.Result.Author('Ramesh Nallapati'), arxiv.Result.Author('Parminder Bhatia'), arxiv.Result.Author('Dan Roth'), arxiv.Result.Author('Bing Xiang')]",,2023-10-17 13:18:01+00:00,"Code completion models have made significant progress in recent years, yet
current popular evaluation datasets, such as HumanEval and MBPP, predominantly
focus on code completion tasks within a single file. This over-simplified
setting falls short of representing the real-world software development
scenario where repositories span multiple files with numerous cross-file
dependencies, and accessing and understanding cross-file context is often
required to complete the code correctly.
  To fill in this gap, we propose CrossCodeEval, a diverse and multilingual
code completion benchmark that necessitates an in-depth cross-file contextual
understanding to complete the code accurately. CrossCodeEval is built on a
diverse set of real-world, open-sourced, permissively-licensed repositories in
four popular programming languages: Python, Java, TypeScript, and C#. To create
examples that strictly require cross-file context for accurate completion, we
propose a straightforward yet efficient static-analysis-based approach to
pinpoint the use of cross-file context within the current file.
  Extensive experiments on state-of-the-art code language models like CodeGen
and StarCoder demonstrate that CrossCodeEval is extremely challenging when the
relevant cross-file context is absent, and we see clear improvements when
adding these context into the prompt. However, despite such improvements, the
pinnacle of performance remains notably unattained even with the
highest-performing model, indicating that CrossCodeEval is also capable of
assessing model's capability in leveraging extensive context to make better
code completion. Finally, we benchmarked various methods in retrieving
cross-file context, and show that CrossCodeEval can also be used to measure the
capability of code retrievers.",,cs.LG,"['cs.LG', 'cs.CL', 'cs.SE']",http://arxiv.org/abs/2310.11248v1
75,Mismatch Negativity: is it time for deconstruction?,http://arxiv.org/pdf/2310.11247v1,"[arxiv.Result.Author('Francoise Lecaignard'), arxiv.Result.Author('Jeremie Mattout')]",,2023-10-17 13:15:42+00:00,"Addressed in over 7000 papers, the mismatch negativity (MMN) is an automatic
brain response to unexpectation that has profoundly shaped perception research.
An important turn has been its computational interpretation as a prediction
error. This learning-based account is grounded in Bayesian theory and offers
testable hypotheses for addressing efficiently the context-sensitivity of
sensory processing. We emphasize that this theoretical turn requires a
methodological one. Specifically, we advocate dynamical modeling over
averaged-based approaches providing the MMN. We show that dynamic analysis
addresses the interpretation of subtle fluctuations in brain activity, a
necessary step to understand how perception adapts to change.",,q-bio.NC,['q-bio.NC'],http://arxiv.org/abs/2310.11247v1
76,Entity Matching using Large Language Models,http://arxiv.org/pdf/2310.11244v1,"[arxiv.Result.Author('Ralph Peeters'), arxiv.Result.Author('Christian Bizer')]",,2023-10-17 13:12:32+00:00,"Entity Matching is the task of deciding whether two entity descriptions refer
to the same real-world entity. Entity Matching is a central step in most data
integration pipelines and an enabler for many e-commerce applications which
require to match products offers from different vendors. State-of-the-art
entity matching methods often rely on pre-trained language models (PLMs) such
as BERT or RoBERTa. Two major drawbacks of these models for entity matching are
that (i) the models require significant amounts of task-specific training data
and (ii) the fine-tuned models are not robust concerning out-of-distribution
entities. In this paper, we investigate using large language models (LLMs) for
entity matching as a less domain-specific training data reliant and more robust
alternative to PLM-based matchers. Our study covers hosted LLMs, such as GPT3.5
and GPT4, as well as open source LLMs based on Llama2 which can be run locally.
We evaluate these models in a zero-shot scenario as well as a scenario where
task-specific training data is available. We compare different prompt designs
as well as the prompt sensitivity of the models in the zero-shot scenario. We
investigate (i) the selection of in-context demonstrations, (ii) the generation
of matching rules, as well as (iii) fine-tuning GPT3.5 in the second scenario
using the same pool of training data across the different approaches. Our
experiments show that GPT4 without any task-specific training data outperforms
fine-tuned PLMs (RoBERTa and Ditto) on three out of five benchmark datasets
reaching F1 scores around 90%. The experiments with in-context learning and
rule generation show that all models beside of GPT4 benefit from these
techniques (on average 5.9% and 2.2% F1), while GPT4 does not need such
additional guidance in most cases...",,cs.CL,"['cs.CL', 'cs.LG']",http://arxiv.org/abs/2310.11244v1
77,A Novel Mixed-Integer Linear Programming Formulation for Continuous-Time Inventory Routing,http://arxiv.org/pdf/2310.11240v1,"[arxiv.Result.Author('Akang Wang'), arxiv.Result.Author('Xiandong Li'), arxiv.Result.Author('Jeffrey E. Arbogast'), arxiv.Result.Author('Zachary Wilson'), arxiv.Result.Author('Chrysanthos E. Gounaris')]",,2023-10-17 13:08:36+00:00,"Inventory management, vehicle routing, and delivery scheduling decisions are
simultaneously considered in the context of the inventory routing problem. This
paper focuses on the continuous-time version of this problem where, unlike its
more traditional discrete-time counterpart, the distributor is required to
guarantee that inventory levels are maintained within the desired intervals at
any moment of the planning horizon. In this work, we develop a compact
mixed-integer linear programming formulation to model the continuous-time
inventory routing problem. We further discuss means to expedite its solution
process, including the adaptation of well-known rounded capacity inequalities
to tighten the formulation in the context of a branch-and-cut algorithm.
Through extensive computational studies on a suite of 90 benchmark instances
from the literature, we show that our branch-and-cut algorithm outperforms the
state-of-the-art approach. We also consider a new set of 63 instances adapted
from a real-life dataset and show our algorithm's practical value in solving
instances with up to 20 customers to guaranteed optimality.",,math.OC,['math.OC'],http://arxiv.org/abs/2310.11240v1
78,Watermarking LLMs with Weight Quantization,http://arxiv.org/pdf/2310.11237v1,"[arxiv.Result.Author('Linyang Li'), arxiv.Result.Author('Botian Jiang'), arxiv.Result.Author('Pengyu Wang'), arxiv.Result.Author('Ke Ren'), arxiv.Result.Author('Hang Yan'), arxiv.Result.Author('Xipeng Qiu')]",,2023-10-17 13:06:59+00:00,"Abuse of large language models reveals high risks as large language models
are being deployed at an astonishing speed. It is important to protect the
model weights to avoid malicious usage that violates licenses of open-source
large language models. This paper proposes a novel watermarking strategy that
plants watermarks in the quantization process of large language models without
pre-defined triggers during inference. The watermark works when the model is
used in the fp32 mode and remains hidden when the model is quantized to int8,
in this way, the users can only inference the model without further supervised
fine-tuning of the model. We successfully plant the watermark into open-source
large language model weights including GPT-Neo and LLaMA. We hope our proposed
method can provide a potential direction for protecting model weights in the
era of large language model applications.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11237v1
79,Chevalley--Monk formulas for bow varieties,http://arxiv.org/pdf/2310.11235v1,[arxiv.Result.Author('Till Wehrhan')],,2023-10-17 13:06:56+00:00,"We prove a formula for the multiplication of equivariant first Chern classes
of tautological bundles of type A bow varieties with respect to the stable
envelope basis. This formula naturally generalizes the classical
Chevalley--Monk formula and can be formulated in terms of creating crossings of
skein type diagrams that label the stable envelope basis.",,math.AG,"['math.AG', 'math.RT']",http://arxiv.org/abs/2310.11235v1
80,Imaging of nonlinear materials via the Monotonicity Principle,http://arxiv.org/pdf/2310.11234v1,"[arxiv.Result.Author('Vincenzo Mottola'), arxiv.Result.Author('Antonio Corbo Esposito'), arxiv.Result.Author('Gianpaolo Piscitelli'), arxiv.Result.Author('Antonello Tamburrino')]",,2023-10-17 13:06:24+00:00,"The topic of inverse problems, related to Maxwell's equations, in the
presence of nonlinear materials is quite new in literature. The lack of
contributions in this area can be ascribed to the significant challenges that
such problems pose. Retrieving the spatial behaviour of some unknown physical
property, starting from boundary measurements, is a nonlinear and highly
ill-posed problem even in the presence of linear materials. And the complexity
exponentially grows when the focus is on nonlinear material properties.
Recently, the Monotonicity Principle has been extended to nonlinear materials
under very general assumptions. Starting from the theoretical background given
by this extension, we develop a first real-time inversion method for the
inverse obstacle problem in the presence of nonlinear materials. The
Monotonicity Principle is the foundation of a class of non-iterative algorithms
for tomography of linear materials. It has been successfully applied to various
problems, governed by different PDEs. In the linear case, MP based inversion
methods ensure excellent performances and compatibility with real-time
applications. We focus on problems governed by elliptical PDEs and, as an
example of application, we treat the Magnetostatic Permeability Tomography
problem, in which the aim is to retrieve the spatial behaviour of magnetic
permeability through boundary measurements in DC operations. In this paper, we
provide some preliminary results giving the foundation of our method and
extended numerical examples.",,math.NA,"['math.NA', 'cs.NA', 'eess.SP']",http://arxiv.org/abs/2310.11234v1
81,Zipformer: A faster and better encoder for automatic speech recognition,http://arxiv.org/pdf/2310.11230v1,"[arxiv.Result.Author('Zengwei Yao'), arxiv.Result.Author('Liyong Guo'), arxiv.Result.Author('Xiaoyu Yang'), arxiv.Result.Author('Wei Kang'), arxiv.Result.Author('Fangjun Kuang'), arxiv.Result.Author('Yifan Yang'), arxiv.Result.Author('Zengrui Jin'), arxiv.Result.Author('Long Lin'), arxiv.Result.Author('Daniel Povey')]",,2023-10-17 13:01:10+00:00,"The Conformer has become the most popular encoder model for automatic speech
recognition (ASR). It adds convolution modules to a transformer to learn both
local and global dependencies. In this work we describe a faster, more
memory-efficient, and better-performing transformer, called Zipformer. Modeling
changes include: 1) a U-Net-like encoder structure where middle stacks operate
at lower frame rates; 2) reorganized block structure with more modules, within
which we re-use attention weights for efficiency; 3) a modified form of
LayerNorm called BiasNorm allows us to retain some length information; 4) new
activation functions SwooshR and SwooshL work better than Swish. We also
propose a new optimizer, called ScaledAdam, which scales the update by each
tensor's current scale to keep the relative change about the same, and also
explictly learns the parameter scale. It achieves faster convergence and better
performance than Adam. Extensive experiments on LibriSpeech, Aishell-1, and
WenetSpeech datasets demonstrate the effectiveness of our proposed Zipformer
over other state-of-the-art ASR models. Our code is publicly available at
https://github.com/k2-fsa/icefall.",,eess.AS,"['eess.AS', 'cs.LG']",http://arxiv.org/abs/2310.11230v1
82,On the nature of polariton transport in a Fabry-Perot Cavity,http://arxiv.org/pdf/2310.11228v1,"[arxiv.Result.Author('Zeyu Zhou'), arxiv.Result.Author('Hsing-Ta Chen'), arxiv.Result.Author('Maxim Sukharev'), arxiv.Result.Author('Joseph E. Subotnik'), arxiv.Result.Author('Abraham Nitzan')]",,2023-10-17 12:58:52+00:00,"Fabry-Perot microcavities can strongly enhance interactions between light and
molecules, leading to the formation of hybrid light-matter states known as
polaritons. Polaritons possess much smaller effective masses and much larger
group velocities when the molecules are resonant with cavity modes that have
finite (non-zero) in-plane wavevectors, giving rise to the possibilities of
long-range and ultrafast ballistic transport. In this paper, we present results
of numerical simulations of the ultrafast ballistic transport phenomenon in
real space and time during and after initialization with a short, spatially
localized pulse. We find that the transport of the molecular excitons as
induced by the external light field is synchronized with the evolution of the
enhanced and localized electromagnetic field inside the cavity. Moreover, the
synchronized transport rate is in good agreement with the group velocities
predicted from a calculated dispersion relation across a wide range of
frequencies. These simulations provide an intuitive tool for understanding the
collective motion of light and excitons and helps to better understand how
experimental observations of polaritons should be interpreted.",,physics.chem-ph,"['physics.chem-ph', 'physics.optics']",http://arxiv.org/abs/2310.11228v1
83,RealBehavior: A Framework for Faithfully Characterizing Foundation Models' Human-like Behavior Mechanisms,http://arxiv.org/pdf/2310.11227v1,"[arxiv.Result.Author('Enyu Zhou'), arxiv.Result.Author('Rui Zheng'), arxiv.Result.Author('Zhiheng Xi'), arxiv.Result.Author('Songyang Gao'), arxiv.Result.Author('Xiaoran Fan'), arxiv.Result.Author('Zichu Fei'), arxiv.Result.Author('Jingting Ye'), arxiv.Result.Author('Tao Gui'), arxiv.Result.Author('Qi Zhang'), arxiv.Result.Author('Xuanjing Huang')]",,2023-10-17 12:58:17+00:00,"Reports of human-like behaviors in foundation models are growing, with
psychological theories providing enduring tools to investigate these behaviors.
However, current research tends to directly apply these human-oriented tools
without verifying the faithfulness of their outcomes. In this paper, we
introduce a framework, RealBehavior, which is designed to characterize the
humanoid behaviors of models faithfully. Beyond simply measuring behaviors, our
framework assesses the faithfulness of results based on reproducibility,
internal and external consistency, and generalizability. Our findings suggest
that a simple application of psychological tools cannot faithfully characterize
all human-like behaviors. Moreover, we discuss the impacts of aligning models
with human and social values, arguing for the necessity of diversifying
alignment objectives to prevent the creation of models with restricted
characteristics.",,cs.CL,"['cs.CL', 'cs.AI']",http://arxiv.org/abs/2310.11227v1
84,KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using Large Language Models,http://arxiv.org/pdf/2310.11220v1,"[arxiv.Result.Author('Jiho Kim'), arxiv.Result.Author('Yeonsu Kwon'), arxiv.Result.Author('Yohan Jo'), arxiv.Result.Author('Edward Choi')]",,2023-10-17 12:51:35+00:00,"While large language models (LLMs) have made considerable advancements in
understanding and generating unstructured text, their application in structured
data remains underexplored. Particularly, using LLMs for complex reasoning
tasks on knowledge graphs (KGs) remains largely untouched. To address this, we
propose KG-GPT, a multi-purpose framework leveraging LLMs for tasks employing
KGs. KG-GPT comprises three steps: Sentence Segmentation, Graph Retrieval, and
Inference, each aimed at partitioning sentences, retrieving relevant graph
components, and deriving logical conclusions, respectively. We evaluate KG-GPT
using KG-based fact verification and KGQA benchmarks, with the model showing
competitive and robust performance, even outperforming several fully-supervised
models. Our work, therefore, marks a significant step in unifying structured
and unstructured data processing within the realm of LLMs.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11220v1
85,Innovative Methods for Non-Destructive Inspection of Handwritten Documents,http://arxiv.org/pdf/2310.11217v1,"[arxiv.Result.Author('Eleonora Breci'), arxiv.Result.Author('Luca Guarnera'), arxiv.Result.Author('Sebastiano Battiato')]",,2023-10-17 12:45:04+00:00,"Handwritten document analysis is an area of forensic science, with the goal
of establishing authorship of documents through examination of inherent
characteristics. Law enforcement agencies use standard protocols based on
manual processing of handwritten documents. This method is time-consuming, is
often subjective in its evaluation, and is not replicable. To overcome these
limitations, in this paper we present a framework capable of extracting and
analyzing intrinsic measures of manuscript documents related to text line
heights, space between words, and character sizes using image processing and
deep learning techniques. The final feature vector for each document involved
consists of the mean and standard deviation for every type of measure
collected. By quantifying the Euclidean distance between the feature vectors of
the documents to be compared, authorship can be discerned. We also proposed a
new and challenging dataset consisting of 362 handwritten manuscripts written
on paper and digital devices by 124 different people. Our study pioneered the
comparison between traditionally handwritten documents and those produced with
digital tools (e.g., tablets). Experimental results demonstrate the ability of
our method to objectively determine authorship in different writing media,
outperforming the state of the art.",,cs.CV,['cs.CV'],http://arxiv.org/abs/2310.11217v1
86,Can Large Language Models Explain Themselves? A Study of LLM-Generated Self-Explanations,http://arxiv.org/pdf/2310.11207v1,"[arxiv.Result.Author('Shiyuan Huang'), arxiv.Result.Author('Siddarth Mamidanna'), arxiv.Result.Author('Shreedhar Jangam'), arxiv.Result.Author('Yilun Zhou'), arxiv.Result.Author('Leilani H. Gilpin')]",,2023-10-17 12:34:32+00:00,"Large language models (LLMs) such as ChatGPT have demonstrated superior
performance on a variety of natural language processing (NLP) tasks including
sentiment analysis, mathematical reasoning and summarization. Furthermore,
since these models are instruction-tuned on human conversations to produce
""helpful"" responses, they can and often will produce explanations along with
the response, which we call self-explanations. For example, when analyzing the
sentiment of a movie review, the model may output not only the positivity of
the sentiment, but also an explanation (e.g., by listing the sentiment-laden
words such as ""fantastic"" and ""memorable"" in the review). How good are these
automatically generated self-explanations? In this paper, we investigate this
question on the task of sentiment analysis and for feature attribution
explanation, one of the most commonly studied settings in the interpretability
literature (for pre-ChatGPT models). Specifically, we study different ways to
elicit the self-explanations, evaluate their faithfulness on a set of
evaluation metrics, and compare them to traditional explanation methods such as
occlusion or LIME saliency maps. Through an extensive set of experiments, we
find that ChatGPT's self-explanations perform on par with traditional ones, but
are quite different from them according to various agreement metrics, meanwhile
being much cheaper to produce (as they are generated along with the
prediction). In addition, we identified several interesting characteristics of
them, which prompt us to rethink many current model interpretability practices
in the era of ChatGPT(-like) LLMs.",,cs.CL,"['cs.CL', 'cs.LG']",http://arxiv.org/abs/2310.11207v1
87,Improving Video Deepfake Detection: A DCT-Based Approach with Patch-Level Analysis,http://arxiv.org/pdf/2310.11204v1,"[arxiv.Result.Author('Luca Guarnera'), arxiv.Result.Author('Salvatore Manganello'), arxiv.Result.Author('Sebastiano Battiato')]",,2023-10-17 12:30:46+00:00,"The term deepfake refers to all those multimedia contents that were
synthetically altered or created from scratch through the use of generative
models. This phenomenon has become widespread due to the use of increasingly
accurate and efficient architectures capable of rendering manipulated content
indistinguishable from real content. In order to fight the illicit use of this
powerful technology, it has become necessary to develop algorithms able to
distinguish synthetic content from real ones. In this study, a new algorithm
for the detection of deepfakes in digital videos is presented, focusing on the
main goal of creating a fast and explainable method from a forensic
perspective. To achieve this goal, the I-frames were extracted in order to
provide faster computation and analysis than approaches described in
literature. In addition, to identify the most discriminating regions within
individual video frames, the entire frame, background, face, eyes, nose, mouth,
and face frame were analyzed separately. From the Discrete Cosine Transform
(DCT), the Beta components were extracted from the AC coefficients and used as
input to standard classifiers (e.g., k-NN, SVM, and others) in order to
identify those frequencies most discriminative for solving the task in
question. Experimental results obtained on the Faceforensics++ and Celeb-DF
(v2) datasets show that the eye and mouth regions are those most discriminative
and able to determine the nature of the video with greater reliability than the
analysis of the whole frame. The method proposed in this study is analytical,
fast and does not require much computational power.",,cs.CV,"['cs.CV', 'eess.IV']",http://arxiv.org/abs/2310.11204v1
88,Theory of pseudospin resonance for multiband superconductors,http://arxiv.org/pdf/2310.11195v1,[arxiv.Result.Author('Kristian Hauser Villegas')],,2023-10-17 12:18:15+00:00,"We formulate a generalized pseudospin formalism for multiband superconductors
in the presence of an external perturbing electromagnetic field. Our theory
naturally captures the effects of quantum band geometric quantities and is
valid even for flat-band superconductors. As an interesting consequence of our
theory, we show that there is an interband pairing fluctuations induced by the
external field and mediated by the quantum band geometry. Surprisingly, this
interband fluctuation is independent of the band gap, which can be understood
from the geometric nature of such novel fluctuations. We derive the generalized
equation of motion for the multiband pseudospin and the self-consistency
equation. We present a formal solution to the pseudospin equation of motion in
powers of the perturbing electromagnetic field. As a simple illustration of our
theory, we calculate the Leggett modes for the two band case.",,cond-mat.supr-con,['cond-mat.supr-con'],http://arxiv.org/abs/2310.11195v1
89,Thermally induced localization of dopants in a magnetic spin ladder,http://arxiv.org/pdf/2310.11193v1,[arxiv.Result.Author('K. Knakkergaard Nielsen')],,2023-10-17 12:15:00+00:00,"I unveil a novel variant of Anderson localization. This emergent phenomenon
pertains to the motion of a dopant in a thermal spin lattice, rendered
localized by thermal fluctuations. This is in stark contrast to the intrinsic
origin of localization for quenched disorder. The system of interest consists
of spin-$1/2$ particles organized in a two-leg ladder with nearest neighbor
Ising interactions $J$. The motion of a hole -- the dopant -- is initialized by
suddenly removing a spin from the thermal spin ensemble, which then moves along
the ladder via nearest neighbor hopping $t$. I find that the hole remains
\emph{localized} for all values of $J/t$ and for \emph{all} nonzero
temperatures. The origin is an effective disorder potential seen by the hole
and induced by thermal spin fluctuations. Its length scale is found to match
with the underlying spin-spin correlation length at low temperatures. For
ferromagnetic couplings ($J<0$), the associated localization length of the hole
increases with decreasing temperature and becomes proportional to the
correlation length at low temperatures, asymptotically delocalizing at low
temperatures. For antiferromagnetic couplings ($J>0$), there is a smooth
crossover between thermal localization at high temperatures to localization
driven by the antiferromagnetic order at low temperatures. At infinite
temperatures, the dynamics becomes independent of the sign of the spin
coupling, whereby the localization length is a universal function of $|J|/t$,
diverging as $(t/|J|)^{5/3}$ for $|J| \ll t$. Finally, I analyze a setup with
Rydberg-dressed atoms, which naturally realizes finite range Ising
interactions, accessible in current experimental setups. I show that the
discovered localization phenomenon can be probed on experimentally accessible
length- and timescales, providing a strong testing ground for my predictions.",,cond-mat.str-el,"['cond-mat.str-el', 'cond-mat.dis-nn', 'cond-mat.quant-gas']",http://arxiv.org/abs/2310.11193v1
90,Medical Text Simplification: Optimizing for Readability with Unlikelihood Training and Reranked Beam Search Decoding,http://arxiv.org/pdf/2310.11191v1,"[arxiv.Result.Author('Lorenzo Jaime Yu Flores'), arxiv.Result.Author('Heyuan Huang'), arxiv.Result.Author('Kejian Shi'), arxiv.Result.Author('Sophie Chheang'), arxiv.Result.Author('Arman Cohan')]",,2023-10-17 12:14:03+00:00,"Text simplification has emerged as an increasingly useful application of AI
for bridging the communication gap in specialized fields such as medicine,
where the lexicon is often dominated by technical jargon and complex
constructs. Despite notable progress, methods in medical simplification
sometimes result in the generated text having lower quality and diversity. In
this work, we explore ways to further improve the readability of text
simplification in the medical domain. We propose (1) a new unlikelihood loss
that encourages generation of simpler terms and (2) a reranked beam search
decoding method that optimizes for simplicity, which achieve better performance
on readability metrics on three datasets. This study's findings offer promising
avenues for improving text simplification in the medical field.",,cs.CL,"['cs.CL', 'cs.AI']",http://arxiv.org/abs/2310.11191v1
91,Jupiter-like planets might be common in a low-density environment,http://arxiv.org/pdf/2310.11190v1,"[arxiv.Result.Author('Raffaele Gratton'), arxiv.Result.Author('Dino Mesa'), arxiv.Result.Author('Mariangela Bonavita'), arxiv.Result.Author('Alice Zurlo'), arxiv.Result.Author('Sebastian Marino'), arxiv.Result.Author('Pierre Kervella'), arxiv.Result.Author('Silvano Desidera'), arxiv.Result.Author(""Valentina D'Orazi""), arxiv.Result.Author('Elisabetta Rigliaco')]",10.1038/s41467-023-41665-0.,2023-10-17 12:09:36+00:00,"Radial velocity surveys suggest that the Solar System may be unusual and that
Jupiter-like planets have a frequency <20% around solar-type stars. However,
they may be much more common in one of the closest associations in the solar
neighbourhood. Young moving stellar groups are the best targets for direct
imaging of exoplanets and four massive Jupiter-like planets have been already
discovered in the nearby young beta Pic Moving Group (BPMG) via high-contrast
imaging, and four others were suggested via high precision astrometry by the
European Space Agency's Gaia satellite. Here we analyze 30 stars in BPMG and
show that 20 of them might potentially host a Jupiter-like planet as their
orbits would be stable. Considering incompleteness in observations, our results
suggest that Jupiter-like planets may be more common than previously found. The
next Gaia data release will likely confirm our prediction.",,astro-ph.EP,"['astro-ph.EP', 'astro-ph.GA', 'astro-ph.SR']",http://arxiv.org/abs/2310.11190v1
92,Databases for comparative syntactic research,http://arxiv.org/pdf/2310.11187v1,"[arxiv.Result.Author('Jessica K. Ivani'), arxiv.Result.Author('Balthasar Bickel')]",,2023-10-17 12:07:33+00:00,"Recent years have witnessed a steep increase in linguistic databases
capturing syntactic variation. We survey and describe 21 publicly available
morpho-syntactic databases, focusing on such properties as data structure, user
interface, documentation, formats, and overall user friendliness. We
demonstrate that all the surveyed databases can be fruitfully categorized along
two dimensions: units of description and the design principle. Units of
description refer to the type of the data the database represents (languages,
constructions, or expressions). The design principles capture the internal
logic of the database. We identify three primary design principles, which vary
in their descriptive power, granularity, and complexity: monocategorization,
multicategorization, and structural decomposition. We describe how these design
principles are implemented in concrete databases and discuss their advantages
and limitations. Finally, we outline essential desiderata for future modern
databases in linguistics.",,cs.DB,['cs.DB'],http://arxiv.org/abs/2310.11187v1
93,On the Effectiveness of Creating Conversational Agent Personalities Through Prompting,http://arxiv.org/pdf/2310.11182v1,"[arxiv.Result.Author('Heng Gu'), arxiv.Result.Author('Chadha Degachi'), arxiv.Result.Author('Uğur Genç'), arxiv.Result.Author('Senthil Chandrasegaran'), arxiv.Result.Author('Himanshu Verma')]",,2023-10-17 11:59:39+00:00,"In this work, we report on the effectiveness of our efforts to tailor the
personality and conversational style of a conversational agent based on GPT-3.5
and GPT-4 through prompts. We use three personality dimensions with two levels
each to create eight conversational agents archetypes. Ten conversations were
collected per chatbot, of ten exchanges each, generating 1600 exchanges across
GPT-3.5 and GPT-4. Using Linguistic Inquiry and Word Count (LIWC) analysis, we
compared the eight agents on language elements including clout, authenticity,
and emotion. Four language cues were significantly distinguishing in GPT-3.5,
while twelve were distinguishing in GPT-4. With thirteen out of a total
nineteen cues in LIWC appearing as significantly distinguishing, our results
suggest possible novel prompting approaches may be needed to better suit the
creation and evaluation of persistent conversational agent personalities or
language styles.",,cs.HC,['cs.HC'],http://arxiv.org/abs/2310.11182v1
94,A diffusive wetting model for water entry/exit based on the weakly-compressible SPH method,http://arxiv.org/pdf/2310.11179v1,"[arxiv.Result.Author('Shuoguo Zhang'), arxiv.Result.Author('Yu Fan'), arxiv.Result.Author('Chi Zhang'), arxiv.Result.Author('Nikolaus Adams'), arxiv.Result.Author('Xiangyu Hu')]",,2023-10-17 11:54:13+00:00,"This paper proposes a diffusive wetting model for the weakly-compressible
smoothed particle hydrodynamics (WCSPH) method to simulate individual water
entry/exit as well as the complete process from water entry to exit. The model
is composed of a physically consistent diffusive wetting equation to describe
the wetting evolution at the fluid-solid interface, a wetting-coupled
identification approach to determine the type of fluid particles by taking into
account the wetting degree of the contacted solid, and a numerical
regularization on the fluid particles at fully wetted fluid-solid interface.
The accuracy, efficiency, and versatility of the present model are validated
through qualitative and quantitative comparisons with experiments, including
the 3-D water entry of a sphere, the 2-D water entry/exit of a cylinder, and
the complete process from water entry to exit of a 2-D cylinder.",,physics.flu-dyn,['physics.flu-dyn'],http://arxiv.org/abs/2310.11179v1
95,FocDepthFormer: Transformer with LSTM for Depth Estimation from Focus,http://arxiv.org/pdf/2310.11178v1,"[arxiv.Result.Author('Xueyang Kang'), arxiv.Result.Author('Fengze Han'), arxiv.Result.Author('Abdur Fayjie'), arxiv.Result.Author('Dong Gong')]",,2023-10-17 11:53:32+00:00,"Depth estimation from focal stacks is a fundamental computer vision problem
that aims to infer depth from focus/defocus cues in the image stacks. Most
existing methods tackle this problem by applying convolutional neural networks
(CNNs) with 2D or 3D convolutions over a set of fixed stack images to learn
features across images and stacks. Their performance is restricted due to the
local properties of the CNNs, and they are constrained to process a fixed
number of stacks consistent in train and inference, limiting the generalization
to the arbitrary length of stacks. To handle the above limitations, we develop
a novel Transformer-based network, FocDepthFormer, composed mainly of a
Transformer with an LSTM module and a CNN decoder. The self-attention in
Transformer enables learning more informative features via an implicit
non-local cross reference. The LSTM module is learned to integrate the
representations across the stack with arbitrary images. To directly capture the
low-level features of various degrees of focus/defocus, we propose to use
multi-scale convolutional kernels in an early-stage encoder. Benefiting from
the design with LSTM, our FocDepthFormer can be pre-trained with abundant
monocular RGB depth estimation data for visual pattern capturing, alleviating
the demand for the hard-to-collect focal stack data. Extensive experiments on
various focal stack benchmark datasets show that our model outperforms the
state-of-the-art models on multiple metrics.",,cs.CV,"['cs.CV', 'cs.AI', 'eess.IV', 'I.4.9; I.2.10']",http://arxiv.org/abs/2310.11178v1
96,Knowledge Extraction and Distillation from Large-Scale Image-Text Colonoscopy Records Leveraging Large Language and Vision Models,http://arxiv.org/pdf/2310.11173v1,"[arxiv.Result.Author('Shuo Wang'), arxiv.Result.Author('Yan Zhu'), arxiv.Result.Author('Xiaoyuan Luo'), arxiv.Result.Author('Zhiwei Yang'), arxiv.Result.Author('Yizhe Zhang'), arxiv.Result.Author('Peiyao Fu'), arxiv.Result.Author('Manning Wang'), arxiv.Result.Author('Zhijian Song'), arxiv.Result.Author('Quanlin Li'), arxiv.Result.Author('Pinghong Zhou'), arxiv.Result.Author('Yike Guo')]",,2023-10-17 11:41:38+00:00,"The development of artificial intelligence systems for colonoscopy analysis
often necessitates expert-annotated image datasets. However, limitations in
dataset size and diversity impede model performance and generalisation.
Image-text colonoscopy records from routine clinical practice, comprising
millions of images and text reports, serve as a valuable data source, though
annotating them is labour-intensive. Here we leverage recent advancements in
large language and vision models and propose EndoKED, a data mining paradigm
for deep knowledge extraction and distillation. EndoKED automates the
transformation of raw colonoscopy records into image datasets with pixel-level
annotation. We validate EndoKED using multi-centre datasets of raw colonoscopy
records (~1 million images), demonstrating its superior performance in training
polyp detection and segmentation models. Furthermore, the EndoKED pre-trained
vision backbone enables data-efficient and generalisable learning for optical
biopsy, achieving expert-level performance in both retrospective and
prospective validation.",,cs.CV,"['cs.CV', 'cs.AI']",http://arxiv.org/abs/2310.11173v1
97,ViSoBERT: A Pre-Trained Language Model for Vietnamese Social Media Text Processing,http://arxiv.org/pdf/2310.11166v1,"[arxiv.Result.Author('Quoc-Nam Nguyen'), arxiv.Result.Author('Thang Chau Phan'), arxiv.Result.Author('Duc-Vu Nguyen'), arxiv.Result.Author('Kiet Van Nguyen')]",,2023-10-17 11:34:50+00:00,"English and Chinese, known as resource-rich languages, have witnessed the
strong development of transformer-based language models for natural language
processing tasks. Although Vietnam has approximately 100M people speaking
Vietnamese, several pre-trained models, e.g., PhoBERT, ViBERT, and vELECTRA,
performed well on general Vietnamese NLP tasks, including POS tagging and named
entity recognition. These pre-trained language models are still limited to
Vietnamese social media tasks. In this paper, we present the first monolingual
pre-trained language model for Vietnamese social media texts, ViSoBERT, which
is pre-trained on a large-scale corpus of high-quality and diverse Vietnamese
social media texts using XLM-R architecture. Moreover, we explored our
pre-trained model on five important natural language downstream tasks on
Vietnamese social media texts: emotion recognition, hate speech detection,
sentiment analysis, spam reviews detection, and hate speech spans detection.
Our experiments demonstrate that ViSoBERT, with far fewer parameters, surpasses
the previous state-of-the-art models on multiple Vietnamese social media tasks.
Our ViSoBERT model is
available\footnote{\url{https://huggingface.co/uitnlp/visobert}} only for
research purposes.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11166v1
98,Serenade: A Model for Human-in-the-loop Automatic Chord Estimation,http://arxiv.org/pdf/2310.11165v1,"[arxiv.Result.Author('Hendrik Vincent Koops'), arxiv.Result.Author('Gianluca Micchi'), arxiv.Result.Author('Ilaria Manco'), arxiv.Result.Author('Elio Quinton')]",,2023-10-17 11:31:29+00:00,"Computational harmony analysis is important for MIR tasks such as automatic
segmentation, corpus analysis and automatic chord label estimation. However,
recent research into the ambiguous nature of musical harmony, causing limited
inter-rater agreement, has made apparent that there is a glass ceiling for
common metrics such as accuracy. Commonly, these issues are addressed either in
the training data itself by creating majority-rule annotations or during the
training phase by learning soft targets. We propose a novel alternative
approach in which a human and an autoregressive model together co-create a
harmonic annotation for an audio track. After automatically generating harmony
predictions, a human sparsely annotates parts with low model confidence and the
model then adjusts its predictions following human guidance. We evaluate our
model on a dataset of popular music and we show that, with this
human-in-the-loop approach, harmonic analysis performance improves over a
model-only approach. The human contribution is amplified by the second,
constrained prediction of the model.",,cs.SD,"['cs.SD', 'cs.LG', 'eess.AS']",http://arxiv.org/abs/2310.11165v1
99,Experimental Investigation of the Photochemical Production of Hydrocarbons in Warm Gas Giant Exoplanet Atmospheres,http://arxiv.org/pdf/2310.11164v1,"[arxiv.Result.Author('Benjamin Fleury'), arxiv.Result.Author('Yves Benilan'), arxiv.Result.Author('Olivia Venot'), arxiv.Result.Author('Bryana L. Henderson'), arxiv.Result.Author('Mark Swain'), arxiv.Result.Author('Murthy S. Gudipati')]",10.3847/1538-4357/acf71b,2023-10-17 11:29:05+00:00,"In warm (equilibrium temperature <1000 K) gas giant exoplanet atmospheres,
the observation of trace species in abundances deviating from thermochemical
equilibrium predictions could be used as an indicator of disequilibrium
chemical processes, such as photochemistry. To predict which compounds could be
used as such tracers, it is therefore essential to study how photochemical
processes affect their abundances. For this purpose, we investigated
experimentally the efficiency of the photochemical formation of hydrocarbons in
gas mixtures representative of warm gas giant atmospheres as a function of the
gas temperature at millibar pressures. We find that, compared to thermal
reactions alone, photochemistry efficiently promotes, under the studied
conditions, the formation of hydrocarbons, with the detection of acetylene,
ethane, and propane, as well as carbon monoxide. Therefore, our results confirm
the importance of photochemistry in exoplanet atmospheres as a disequilibrium
process. Ethane is the major hydrocarbon formed in our experiments, in apparent
contradiction with the prediction by thermophotochemical models that acetylene
should be the main hydrocarbon product. We also observe an evolution of the
hydrocarbon production efficiency as a function of the temperature, a behavior
not reproduced by a 0D thermophotochemical model. Additional studies are
necessary to definitively understand the origin of the differences between the
experimental and modeling results and to infer the importance of our results
for understanding hydrocarbon formation in warm gas giant exoplanet
atmospheres. Finally, our work demonstrates the importance of experimental
studies together with modeling studies to accurately interpret, understand, and
predict observations of exoplanet atmospheres.","The Astrophysical Journal, 956:134 (15pp), 2023 October 20",astro-ph.EP,['astro-ph.EP'],http://arxiv.org/abs/2310.11164v1
100,"IMTLab: An Open-Source Platform for Building, Evaluating, and Diagnosing Interactive Machine Translation Systems",http://arxiv.org/pdf/2310.11163v1,"[arxiv.Result.Author('Xu Huang'), arxiv.Result.Author('Zhirui Zhang'), arxiv.Result.Author('Ruize Gao'), arxiv.Result.Author('Yichao Du'), arxiv.Result.Author('Lemao Liu'), arxiv.Result.Author('Gouping Huang'), arxiv.Result.Author('Shuming Shi'), arxiv.Result.Author('Jiajun Chen'), arxiv.Result.Author('Shujian Huang')]",,2023-10-17 11:29:04+00:00,"We present IMTLab, an open-source end-to-end interactive machine translation
(IMT) system platform that enables researchers to quickly build IMT systems
with state-of-the-art models, perform an end-to-end evaluation, and diagnose
the weakness of systems. IMTLab treats the whole interactive translation
process as a task-oriented dialogue with a human-in-the-loop setting, in which
human interventions can be explicitly incorporated to produce high-quality,
error-free translations. To this end, a general communication interface is
designed to support the flexible IMT architectures and user policies. Based on
the proposed design, we construct a simulated and real interactive environment
to achieve end-to-end evaluation and leverage the framework to systematically
evaluate previous IMT systems. Our simulated and manual experiments show that
the prefix-constrained decoding approach still gains the lowest editing cost in
the end-to-end evaluation, while BiTIIMT achieves comparable editing cost with
a better interactive experience.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11163v1
101,Accurate prediction of international trade flows: Leveraging knowledge graphs and their embeddings,http://arxiv.org/pdf/2310.11161v1,"[arxiv.Result.Author('Diego Rincon-Yanez'), arxiv.Result.Author('Chahinez Ounoughi'), arxiv.Result.Author('Bassem Sellami'), arxiv.Result.Author('Tarmo Kalvet'), arxiv.Result.Author('Marek Tiits'), arxiv.Result.Author('Sabrina Senatore'), arxiv.Result.Author('Sadok Ben Yahia')]",,2023-10-17 11:28:30+00:00,"Knowledge representation (KR) is vital in designing symbolic notations to
represent real-world facts and facilitate automated decision-making tasks.
Knowledge graphs (KGs) have emerged so far as a popular form of KR, offering a
contextual and human-like representation of knowledge. In international
economics, KGs have proven valuable in capturing complex interactions between
commodities, companies, and countries. By putting the gravity model, which is a
common economic framework, into the process of building KGs, important factors
that affect trade relationships can be taken into account, making it possible
to predict international trade patterns. This paper proposes an approach that
leverages Knowledge Graph embeddings for modeling international trade, focusing
on link prediction using embeddings. Thus, valuable insights are offered to
policymakers, businesses, and economists, enabling them to anticipate the
effects of changes in the international trade system. Moreover, the integration
of traditional machine learning methods with KG embeddings, such as decision
trees and graph neural networks are also explored. The research findings
demonstrate the potential for improving prediction accuracy and provide
insights into embedding explainability in knowledge representation. The paper
also presents a comprehensive analysis of the influence of embedding methods on
other intelligent algorithms.",,cs.AI,"['cs.AI', 'cs.SC']",http://arxiv.org/abs/2310.11161v1
102,Leveraging Content-based Features from Multiple Acoustic Models for Singing Voice Conversion,http://arxiv.org/pdf/2310.11160v1,"[arxiv.Result.Author('Xueyao Zhang'), arxiv.Result.Author('Yicheng Gu'), arxiv.Result.Author('Haopeng Chen'), arxiv.Result.Author('Zihao Fang'), arxiv.Result.Author('Lexiao Zou'), arxiv.Result.Author('Liumeng Xue'), arxiv.Result.Author('Zhizheng Wu')]",,2023-10-17 11:26:28+00:00,"Singing voice conversion (SVC) is a technique to enable an arbitrary singer
to sing an arbitrary song. To achieve that, it is important to obtain
speaker-agnostic representations from source audio, which is a challenging
task. A common solution is to extract content-based features (e.g., PPGs) from
a pretrained acoustic model. However, the choices for acoustic models are vast
and varied. It is yet to be explored what characteristics of content features
from different acoustic models are, and whether integrating multiple content
features can help each other. Motivated by that, this study investigates three
distinct content features, sourcing from WeNet, Whisper, and ContentVec,
respectively. We explore their complementary roles in intelligibility, prosody,
and conversion similarity for SVC. By integrating the multiple content features
with a diffusion-based SVC model, our SVC system achieves superior conversion
performance on both objective and subjective evaluation in comparison to a
single source of content features. Our demo page and code can be available
https://www.zhangxueyao.com/data/MultipleContentsSVC/index.html.",,cs.SD,"['cs.SD', 'eess.AS']",http://arxiv.org/abs/2310.11160v1
103,Probing the Creativity of Large Language Models: Can models produce divergent semantic association?,http://arxiv.org/pdf/2310.11158v1,"[arxiv.Result.Author('Honghua Chen'), arxiv.Result.Author('Nai Ding')]",,2023-10-17 11:23:32+00:00,"Large language models possess remarkable capacity for processing language,
but it remains unclear whether these models can further generate creative
content. The present study aims to investigate the creative thinking of large
language models through a cognitive perspective. We utilize the divergent
association task (DAT), an objective measurement of creativity that asks models
to generate unrelated words and calculates the semantic distance between them.
We compare the results across different models and decoding strategies. Our
findings indicate that: (1) When using the greedy search strategy, GPT-4
outperforms 96% of humans, while GPT-3.5-turbo exceeds the average human level.
(2) Stochastic sampling and temperature scaling are effective to obtain higher
DAT scores for models except GPT-4, but face a trade-off between creativity and
stability. These results imply that advanced large language models have
divergent semantic associations, which is a fundamental process underlying
creativity.",,cs.CL,"['cs.CL', 'cs.LG']",http://arxiv.org/abs/2310.11158v1
104,Enhancement of cell membrane poration by the antimicrobial peptide Melp5,http://arxiv.org/pdf/2310.11156v1,"[arxiv.Result.Author('Qixuan Li'), arxiv.Result.Author('Xiaoshuang Zhong'), arxiv.Result.Author('Liang Sun'), arxiv.Result.Author('Liang Dai')]",,2023-10-17 11:23:06+00:00,"Melittin, a natural antimicrobial peptide comprising 26 amino acid residues,
can kill bacteria by inducing pores in cell membranes. Clinical applications of
melittin as an antibiotic require a thorough understanding of its poration
mechanism and mutations that enhance its antimicrobial activity. Previous
experiments showed Melp5, a variant of melittin with five mutations, exhibits a
higher poration ability. However, the mechanism of the enhanced poration
ability is not fully understood. Here, we investigated the mechanism by
comparing the poration of melittin and Melp5 using coarse-grained (CG) and
all-atom (AA) molecular dynamics (MD) simulations. We observe that Melp5 is
likely to form a pore with 5 peptides (pentameric), while melittin is likely to
form a pore with 4 peptides (tetrameric). Our atomistic MD simulations show
that the pentameric pore of Melp5 has a higher water permeability than the
tetrameric pore of melittin. We also analyze the stability of the pores of
melittin and Melp5 by calculating the interaction energies of the pores. In
particular, we investigate the effects of mutant residues on pore stability by
calculating electrostatic and LJ interactions. These results should provide
insights on the enhanced poration ability of Melp5 and push it toward
applications.",,physics.bio-ph,['physics.bio-ph'],http://arxiv.org/abs/2310.11156v1
105,Left- vs right-handed badminton slice shots: opposite shuttlecock spinning and Magnus effect,http://arxiv.org/pdf/2310.11155v1,[arxiv.Result.Author('Eric Collet')],,2023-10-17 11:21:47+00:00,"The chiral nature of a badminton shuttlecock is responsible for its
anti-clockwise spinning as it naturally propagates through the air. This
induces a dissymmetry between left-handed and right-handed players and the
resulting trajectories of the shuttlecock, which were captured in real
condition on the badminton court and in slow-motion at 3700 fps. The videos
clearly evidence this dissymmetry as slice shots performed by righties
accelerate the natural anti-clockwise spinning, while the one performed by
lefties induces a clockwise to anti-clockwise spinning, making trajectories of
shuttlecocks different. The slow-motion videos also caught a brief Magnus
effect, often neglected in badminton, lifting up the shuttlecock for both
lefties and righties and affecting the effectiveness of the slice shot.",,physics.pop-ph,['physics.pop-ph'],http://arxiv.org/abs/2310.11155v1
106,Causal discovery using dynamically requested knowledge,http://arxiv.org/pdf/2310.11154v1,"[arxiv.Result.Author('Neville K Kitson'), arxiv.Result.Author('Anthony C Constantinou')]",,2023-10-17 11:21:23+00:00,"Causal Bayesian Networks (CBNs) are an important tool for reasoning under
uncertainty in complex real-world systems. Determining the graphical structure
of a CBN remains a key challenge and is undertaken either by eliciting it from
humans, using machine learning to learn it from data, or using a combination of
these two approaches. In the latter case, human knowledge is generally provided
to the algorithm before it starts, but here we investigate a novel approach
where the structure learning algorithm itself dynamically identifies and
requests knowledge for relationships that the algorithm identifies as uncertain
during structure learning. We integrate this approach into the Tabu structure
learning algorithm and show that it offers considerable gains in structural
accuracy, which are generally larger than those offered by existing approaches
for integrating knowledge. We suggest that a variant which requests only arc
orientation information may be particularly useful where the practitioner has
little preexisting knowledge of the causal relationships. As well as offering
improved accuracy, the approach can use human expertise more effectively and
contributes to making the structure learning process more transparent.",,cs.AI,['cs.AI'],http://arxiv.org/abs/2310.11154v1
107,Unsupervised Pre-Training Using Masked Autoencoders for ECG Analysis,http://arxiv.org/pdf/2310.11153v1,"[arxiv.Result.Author('Guoxin Wang'), arxiv.Result.Author('Qingyuan Wang'), arxiv.Result.Author('Ganesh Neelakanta Iyer'), arxiv.Result.Author('Avishek Nag'), arxiv.Result.Author('Deepu John')]",,2023-10-17 11:19:51+00:00,"Unsupervised learning methods have become increasingly important in deep
learning due to their demonstrated large utilization of datasets and higher
accuracy in computer vision and natural language processing tasks. There is a
growing trend to extend unsupervised learning methods to other domains, which
helps to utilize a large amount of unlabelled data. This paper proposes an
unsupervised pre-training technique based on masked autoencoder (MAE) for
electrocardiogram (ECG) signals. In addition, we propose a task-specific
fine-tuning to form a complete framework for ECG analysis. The framework is
high-level, universal, and not individually adapted to specific model
architectures or tasks. Experiments are conducted using various model
architectures and large-scale datasets, resulting in an accuracy of 94.39% on
the MITDB dataset for ECG arrhythmia classification task. The result shows a
better performance for the classification of previously unseen data for the
proposed approach compared to fully supervised methods.",,cs.CV,"['cs.CV', 'eess.SP']",http://arxiv.org/abs/2310.11153v1
108,Complex Number Assignment in the Topology Method for Heartbeat Interval Estimation Using Millimeter-Wave Radar,http://arxiv.org/pdf/2310.11149v1,"[arxiv.Result.Author('Yuji Tanaka'), arxiv.Result.Author('Kimitaka Sumi'), arxiv.Result.Author('Itsuki Iwata'), arxiv.Result.Author('Takuya Sakamoto')]",,2023-10-17 11:06:12+00:00,"The topology method is an algorithm for accurate estimation of instantaneous
heartbeat intervals using millimeter-wave radar signals. In this model, feature
points are extracted from the skin displacement waveforms generated by
heartbeats and a complex number is assigned to each feature point. However,
these numbers have been assigned empirically and without solid justification.
This study used a simplified model of displacement waveforms to predict the
optimal choice of the complex number assignments to feature points
corresponding to inflection points, and the validity of these numbers was
confirmed using analysis of a publicly available dataset.",,eess.SP,['eess.SP'],http://arxiv.org/abs/2310.11149v1
109,The Quo Vadis of the Relationship between Language and Large Language Models,http://arxiv.org/pdf/2310.11146v1,"[arxiv.Result.Author('Evelina Leivada'), arxiv.Result.Author('Vittoria Dentella'), arxiv.Result.Author('Elliot Murphy')]",,2023-10-17 10:54:24+00:00,"In the field of Artificial (General) Intelligence (AI), the several recent
advancements in Natural language processing (NLP) activities relying on Large
Language Models (LLMs) have come to encourage the adoption of LLMs as
scientific models of language. While the terminology employed for the
characterization of LLMs favors their embracing as such, it is not clear that
they are in a place to offer insights into the target system they seek to
represent. After identifying the most important theoretical and empirical risks
brought about by the adoption of scientific models that lack transparency, we
discuss LLMs relating them to every scientific model's fundamental components:
the object, the medium, the meaning and the user. We conclude that, at their
current stage of development, LLMs hardly offer any explanations for language,
and then we provide an outlook for more informative future research directions
on this topic.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11146v1
110,Long-form Simultaneous Speech Translation: Thesis Proposal,http://arxiv.org/pdf/2310.11141v1,[arxiv.Result.Author('Peter Polák')],,2023-10-17 10:44:05+00:00,"Simultaneous speech translation (SST) aims to provide real-time translation
of spoken language, even before the speaker finishes their sentence.
Traditionally, SST has been addressed primarily by cascaded systems that
decompose the task into subtasks, including speech recognition, segmentation,
and machine translation. However, the advent of deep learning has sparked
significant interest in end-to-end (E2E) systems. Nevertheless, a major
limitation of most approaches to E2E SST reported in the current literature is
that they assume that the source speech is pre-segmented into sentences, which
is a significant obstacle for practical, real-world applications. This thesis
proposal addresses end-to-end simultaneous speech translation, particularly in
the long-form setting, i.e., without pre-segmentation. We present a survey of
the latest advancements in E2E SST, assess the primary obstacles in SST and its
relevance to long-form scenarios, and suggest approaches to tackle these
challenges.",,cs.CL,"['cs.CL', 'cs.AI', 'cs.SD', 'eess.AS']",http://arxiv.org/abs/2310.11141v1
111,Moving from ISAD(G) to a CIDOC CRM-based Linked Data Model in the Portuguese Archives,http://arxiv.org/pdf/2310.11140v1,"[arxiv.Result.Author('Inês Koch'), arxiv.Result.Author('Carla Teixeira Lopes'), arxiv.Result.Author('Cristina Ribeiro')]",10.1145/3605910,2023-10-17 10:43:08+00:00,"Archives are facing numerous challenges. On the one hand, archival assets are
evolving to encompass digitized documents and increasing quantities of
born-digital information in diverse formats. On the other hand, the audience is
changing along with how it wishes to access archival material. Moreover, the
interoperability requirements of cultural heritage repositories are growing. In
this context, the Portuguese Archives started an ambitious program aiming to
evolve its data model, migrate existing records, and build a new archival
management system appropriate to both archival tasks and public access. The
overall goal is to have a fine-grained and flexible description, more
machine-actionable than the current one. This work describes ArchOnto, a linked
open data model for archives, and rules for its automatic population from
existing records. ArchOnto adopts a semantic web approach and encompasses the
CIDOC Conceptual Reference Model and additional ontologies, envisioning
interoperability with datasets curated by multiple communities of practice.
Existing ISAD(G)-conforming descriptions are being migrated to the new model
using the direct mappings provided here. We used a sample of 25 records
associated with different description levels to validate the completeness and
conformity of ArchOnto to existing data. This work is in progress and is
original in several respects: (1) it is one of the first approaches to use
CIDOC CRM in the context of archives, identifying problems and questions that
emerged during the process and pinpointing possible solutions; (2) it addresses
the balance in the model between the migration of existing records and the
construction of new ones by archive professionals; and (3) it adopts an open
world view on linking archival data to global information sources.",,cs.DL,['cs.DL'],http://arxiv.org/abs/2310.11140v1
112,Theoretical study of the open-flavor tetraquark $T_{c\bar{s}}(2900)$ in the process $Λ_b\to K^0D^0Λ$,http://arxiv.org/pdf/2310.11139v1,"[arxiv.Result.Author('Wen-Tao Lyu'), arxiv.Result.Author('Yun-He Lyu'), arxiv.Result.Author('Man-Yu Duan'), arxiv.Result.Author('Guan-Ying Wang'), arxiv.Result.Author('Dian-Yong Chen'), arxiv.Result.Author('En Wang')]",,2023-10-17 10:40:54+00:00,"Recently, the LHCb Collaboration has measured the processes
$B^0\to\bar{D}^0D_s^+\pi^-$ and $B^+\to\bar{D}^0D_s^+\pi^+$, where the
$D_s^+\pi^-$ and $D_s^+\pi^+$ invariant mass distributions show the significant
signals of two new open-flavor tetraquark states $T_{c\bar{s}}(2900)^0$ and
$T_{c\bar{s}}(2900)^{++}$, as the two of the isospin triplet. In this work, we
have investigated the process $\Lambda_b\to K^0D^0\Lambda$ by taking into
account the intermediate nucleon resonance $N^*(1535)$ and the tetraquark state
$T_{c\bar{s}}(2900)^0$, which could be dynamically generated by the
interactions of the $D^*K^*/D^*_s\rho$ and the pseoduscalar mesons-octet
baryons, respectively. Our results show that a clear peak of the open-flavor
tetraquark $T_{c\bar{s}}(2900)$ may appear in the $K^0D^0$ invariant mass
distribution of the process $\Lambda_b\to K^0D^0\Lambda$, which could be tested
by future experiments.",,hep-ph,['hep-ph'],http://arxiv.org/abs/2310.11139v1
113,Moments of polynomial functionals in Levy-driven queues with secondary jumps,http://arxiv.org/pdf/2310.11137v1,"[arxiv.Result.Author('Peter W. Glynn'), arxiv.Result.Author('Royi Jacobovic'), arxiv.Result.Author('Michel Mandjes')]",,2023-10-17 10:39:32+00:00,"A long-standing open problem concerns the calculation of the moments of the
area beneath the M/G/1 workload graph during a busy period. While expressions
for the first two moments were known, no results for higher moments were
available. In this paper we develop a recursive algorithm by which all moments
can be expressed in terms of the model primitives. Our results extend to any
storage system fed by a superposition of a drifted Brownian motion and a
subordinator (nondecreasing Levy process) with a secondary jump input, yielding
the moments (including joint ones) of a general class of polynomial functionals
of the workload process. For the special case of the M/G/1 queue we identify
the joint transform of the area and the duration of the busy period.",,math.PR,"['math.PR', '60G51, 60K25']",http://arxiv.org/abs/2310.11137v1
114,Equational Anti-Unification over Absorption Theories,http://arxiv.org/pdf/2310.11136v1,"[arxiv.Result.Author('Mauricio Ayala-Rincon'), arxiv.Result.Author('David M. Cerna'), arxiv.Result.Author('Andres Felipe Gonzalez Barragan'), arxiv.Result.Author('Temur Kutsia')]",,2023-10-17 10:38:06+00:00,"Interest in anti-unification, the dual problem of unification, is on the rise
due to applications within the field of software analysis and related areas.
For example, anti-unification-based techniques have found uses within clone
detection and automatic program repair methods. While syntactic forms of
anti-unification are enough for many applications, some aspects of software
analysis methods are more appropriately modeled by reasoning modulo an
equational theory. Thus, extending existing anti-unification methods to deal
with important equational theories is the natural step forward. This paper
considers anti-unification modulo pure absorption theories, i.e., some
operators are associated with a special constant satisfying the axiom
$f(x,\varepsilon_f) \approx f(\varepsilon_f,x) \approx \varepsilon_f$. We
provide a sound and complete rule-based algorithm for such theories.
Furthermore, we show that anti-unification modulo absorption is infinitary.
Despite this, our algorithm terminates and produces a finitary algorithmic
representation of the minimal complete set of solutions. We also show that the
linear variant is finitary.",,cs.LO,"['cs.LO', 'cs.SE']",http://arxiv.org/abs/2310.11136v1
115,Synthesizing Invariants for Polynomial Programs by Semidefinite Programming,http://arxiv.org/pdf/2310.11133v1,"[arxiv.Result.Author('Hao Wu'), arxiv.Result.Author('Qiuye Wang'), arxiv.Result.Author('Bai Xue'), arxiv.Result.Author('Naijun Zhan'), arxiv.Result.Author('Lihong Zhi'), arxiv.Result.Author('Zhihong Yang')]",,2023-10-17 10:31:26+00:00,"Constraint-solving-based program invariant synthesis involves taking a
parametric template, encoding the invariant conditions, and attempting to solve
the constraints to obtain a valid assignment of parameters. The challenge lies
in that the resulting constraints are often non-convex and lack efficient
solvers. Consequently, existing works mostly rely on heuristic algorithms or
general-purpose solvers, leading to a trade-off between completeness and
efficiency.
  In this paper, we propose two novel approaches to synthesize invariants for
polynomial programs using semidefinite programming (SDP). For basic
semialgebraic templates, we apply techniques from robust optimization to
construct a hierarchy of SDP relaxations. These relaxations induce a series of
sub-level sets that under-approximate the set of valid parameter assignments.
Under a certain non-degenerate assumption, we present a weak completeness
result that the synthesized sets include almost all valid assignments.
Furthermore, we discuss several extensions to improve the efficiency and
expressiveness of the algorithm. We also identify a subclass of basic
semialgebraic templates, called masked templates, for which the non-degenerate
assumption is violated. Regarding masked templates, we present a
substitution-based method to strengthen the invariant conditions. The
strengthened constraints again admit a hierarchy of SDP approximations. Both of
our approaches have been implemented, and empirical results demonstrate that
they outperform the state-of-the-art methods.",,cs.PL,"['cs.PL', 'F.3.1; G.1.6']",http://arxiv.org/abs/2310.11133v1
116,Sensitivity-Aware Amortized Bayesian Inference,http://arxiv.org/pdf/2310.11122v1,"[arxiv.Result.Author('Lasse Elsemüller'), arxiv.Result.Author('Hans Olischläger'), arxiv.Result.Author('Marvin Schmitt'), arxiv.Result.Author('Paul-Christian Bürkner'), arxiv.Result.Author('Ullrich Köthe'), arxiv.Result.Author('Stefan T. Radev')]",,2023-10-17 10:14:10+00:00,"Bayesian inference is a powerful framework for making probabilistic
inferences and decisions under uncertainty. Fundamental choices in modern
Bayesian workflows concern the specification of the likelihood function and
prior distributions, the posterior approximator, and the data. Each choice can
significantly influence model-based inference and subsequent decisions, thereby
necessitating sensitivity analysis. In this work, we propose a multifaceted
approach to integrate sensitivity analyses into amortized Bayesian inference
(ABI, i.e., simulation-based inference with neural networks). First, we utilize
weight sharing to encode the structural similarities between alternative
likelihood and prior specifications in the training process with minimal
computational overhead. Second, we leverage the rapid inference of neural
networks to assess sensitivity to various data perturbations or pre-processing
procedures. In contrast to most other Bayesian approaches, both steps
circumvent the costly bottleneck of refitting the model(s) for each choice of
likelihood, prior, or dataset. Finally, we propose to use neural network
ensembles to evaluate variation in results induced by unreliable approximation
on unseen data. We demonstrate the effectiveness of our method in applied
modeling problems, ranging from the estimation of disease outbreak dynamics and
global warming thresholds to the comparison of human decision-making models.
Our experiments showcase how our approach enables practitioners to effectively
unveil hidden relationships between modeling choices and inferential
conclusions.",,stat.ML,"['stat.ML', 'cs.LG', 'stat.ME']",http://arxiv.org/abs/2310.11122v1
117,The influence of microwave pulse conditions on enantiomer-specific state transfer,http://arxiv.org/pdf/2310.11120v1,"[arxiv.Result.Author('JuHyeon Lee'), arxiv.Result.Author('Johannes Bischoff'), arxiv.Result.Author('A. O. Hernandez-Castillo'), arxiv.Result.Author('Elahe Abdiha'), arxiv.Result.Author('Boris G. Sartakov'), arxiv.Result.Author('Gerard Meijer'), arxiv.Result.Author('Sandra Eibenberger-Arias')]",,2023-10-17 10:12:23+00:00,"We report a combined experimental and theoretical study on the influence of
microwave pulse durations on enantiomer-specific state transfer. Two triads of
rotational states within a chiral molecule (1-indanol) are selected to address
the possible scenarios. In the triad connected to the absolute ground state,
the simplest triad that exists for all chiral molecules, the
enantiomer-specific state transfer process simplifies into a sequence of
two-level transitions. The second triad, including higher rotational states,
represents a more generic scenario that involves multiple Rabi frequencies for
each transition. Our study reveals that the conventional
$\frac{\pi}{2}-\pi-\frac{\pi}{2}$ pulse sequence is not the optimal choice,
except for the ideal case when in the simplest triad only the lowest level is
initially populated. We find that employing a shorter duration for the first
and last pulse of the sequence leads to significantly higher state-specific
enantiomeric enrichment, albeit at the expense of overall population in the
target state. Our experimental results are in very good agreement with theory,
substantiating the quantitative understanding of enantiomer-specific state
transfer.",,physics.chem-ph,"['physics.chem-ph', 'quant-ph']",http://arxiv.org/abs/2310.11120v1
118,Cross-Platform Social Dynamics: An Analysis of ChatGPT and COVID-19 Vaccine Conversations,http://arxiv.org/pdf/2310.11116v1,"[arxiv.Result.Author('Shayan Alipour'), arxiv.Result.Author('Alessandro Galeazzi'), arxiv.Result.Author('Emanuele Sangiorgio'), arxiv.Result.Author('Michele Avalle'), arxiv.Result.Author('Ljubisa Bojic'), arxiv.Result.Author('Matteo Cinelli'), arxiv.Result.Author('Walter Quattrociocchi')]",,2023-10-17 09:58:55+00:00,"The role of social media in information dissemination and agenda-setting has
significantly expanded in recent years. By offering real-time interactions,
online platforms have become invaluable tools for studying societal responses
to significant events as they unfold. However, online reactions to external
developments are influenced by various factors, including the nature of the
event and the online environment. This study examines the dynamics of public
discourse on digital platforms to shed light on this issue. We analyzed over 12
million posts and news articles related to two significant events: the release
of ChatGPT in 2022 and the global discussions about COVID-19 vaccines in 2021.
Data was collected from multiple platforms, including Twitter, Facebook,
Instagram, Reddit, YouTube, and GDELT. We employed topic modeling techniques to
uncover the distinct thematic emphases on each platform, which reflect their
specific features and target audiences. Additionally, sentiment analysis
revealed various public perceptions regarding the topics studied. Lastly, we
compared the evolution of engagement across platforms, unveiling unique
patterns for the same topic. Notably, discussions about COVID-19 vaccines
spread more rapidly due to the immediacy of the subject, while discussions
about ChatGPT, despite its technological importance, propagated more gradually.",,cs.CY,"['cs.CY', 'physics.soc-ph']",http://arxiv.org/abs/2310.11116v1
119,Heat kernel fluctuations and quantitative homogenization for the one-dimensional Bouchaud trap model,http://arxiv.org/pdf/2310.11115v1,"[arxiv.Result.Author('Sebastian Andres'), arxiv.Result.Author('David A. Croydon'), arxiv.Result.Author('Takashi Kumagai')]",,2023-10-17 09:58:03+00:00,"We present on-diagonal heat kernel estimates and quantitative homogenization
statements for the one-dimensional Bouchaud trap model. The heat kernel
estimates are obtained using standard techniques, with key inputs coming from a
careful analysis of the volume growth of the invariant measure of the process
under study. As for the quantitative homogenization results, these include both
quenched and annealed Berry-Esseen-type theorems, as well as a quantitative
quenched local limit theorem. Whilst the model we study here is a particularly
simple example of a random walk in a random environment, we believe the roadmap
we provide for establishing the latter result in particular will be useful for
deriving quantitative local limit theorems in other, more challenging,
settings.",,math.PR,"['math.PR', 'math.AP', '60K37, 60F17, 82C41, 82B43']",http://arxiv.org/abs/2310.11115v1
120,Revisiting Sentiment Analysis for Software Engineering in the Era of Large Language Models,http://arxiv.org/pdf/2310.11113v1,"[arxiv.Result.Author('Ting Zhang'), arxiv.Result.Author('Ivana Clairine Irsan'), arxiv.Result.Author('Ferdian Thung'), arxiv.Result.Author('David Lo')]",,2023-10-17 09:53:03+00:00,"Software development is an inherently collaborative process, where various
stakeholders frequently express their opinions and emotions across diverse
platforms. Recognizing the sentiments conveyed in these interactions is crucial
for the effective development and ongoing maintenance of software systems. For
instance, app developers can harness sentiment analysis of app users' reviews
to enhance the quality of their app. Over the years, many tools have been
proposed to aid in sentiment analysis, but accurately identifying the
sentiments expressed in software engineering datasets remains challenging.
  Recent advances have showcased the potential of fine-tuned pre-trained
language models in handling software engineering datasets, albeit they grapple
with the shortage of labeled data. With the emergence of large language models
(LLMs), it is pertinent to investigate how these models perform in the context
of sentiment analysis for software engineering. In this work, we undertake a
comprehensive empirical study using five established software engineering
datasets. We assess the performance of three open-source LLMs in both zero-shot
and few-shot scenarios. Additionally, we draw comparisons between fine-tuned
pre-trained smaller language models and LLMs employing prompts.
  Our experimental findings demonstrate that LLMs exhibit state-of-the-art
performance on datasets marked by limited training data and imbalanced
distributions. LLMs can also achieve excellent performance under a zero-shot
setting. However, when ample training data is available, or the dataset
exhibits a more balanced distribution, fine-tuned smaller language models can
still achieve superior results.",,cs.SE,['cs.SE'],http://arxiv.org/abs/2310.11113v1
121,Super resolution of histopathological frozen sections via deep learning preserving tissue structure,http://arxiv.org/pdf/2310.11112v1,"[arxiv.Result.Author('Elad Yoshai'), arxiv.Result.Author('Gil Goldinger'), arxiv.Result.Author('Miki Haifler'), arxiv.Result.Author('Natan T. Shaked')]",,2023-10-17 09:52:54+00:00,"Histopathology plays a pivotal role in medical diagnostics. In contrast to
preparing permanent sections for histopathology, a time-consuming process,
preparing frozen sections is significantly faster and can be performed during
surgery, where the sample scanning time should be optimized. Super-resolution
techniques allow imaging the sample in lower magnification and sparing scanning
time. In this paper, we present a new approach to super resolution for
histopathological frozen sections, with focus on achieving better distortion
measures, rather than pursuing photorealistic images that may compromise
critical diagnostic information. Our deep-learning architecture focuses on
learning the error between interpolated images and real images, thereby it
generates high-resolution images while preserving critical image details,
reducing the risk of diagnostic misinterpretation. This is done by leveraging
the loss functions in the frequency domain, assigning higher weights to the
reconstruction of complex, high-frequency components. In comparison to existing
methods, we obtained significant improvements in terms of Structural Similarity
Index (SSIM) and Peak Signal-to-Noise Ratio (PSNR), as well as indicated
details that lost in the low-resolution frozen-section images, affecting the
pathologist's clinical decisions. Our approach has a great potential in
providing more-rapid frozen-section imaging, with less scanning, while
preserving the high resolution in the imaged sample.",,eess.IV,"['eess.IV', 'cs.CV', 'cs.LG']",http://arxiv.org/abs/2310.11112v1
122,Minimally Informed Linear Discriminant Analysis: training an LDA model with unlabelled data,http://arxiv.org/pdf/2310.11110v1,"[arxiv.Result.Author('Nicolas Heintz'), arxiv.Result.Author('Tom Francart'), arxiv.Result.Author('Alexander Bertrand')]",,2023-10-17 09:50:31+00:00,"Linear Discriminant Analysis (LDA) is one of the oldest and most popular
linear methods for supervised classification problems. In this paper, we
demonstrate that it is possible to compute the exact projection vector from LDA
models based on unlabelled data, if some minimal prior information is
available. More precisely, we show that only one of the following three pieces
of information is actually sufficient to compute the LDA projection vector if
only unlabelled data are available: (1) the class average of one of the two
classes, (2) the difference between both class averages (up to a scaling), or
(3) the class covariance matrices (up to a scaling). These theoretical results
are validated in numerical experiments, demonstrating that this minimally
informed Linear Discriminant Analysis (MILDA) model closely matches the
performance of a supervised LDA model. Furthermore, we show that the MILDA
projection vector can be computed in a closed form with a computational cost
comparable to LDA and is able to quickly adapt to non-stationary data, making
it well-suited to use as an adaptive classifier.",,cs.LG,"['cs.LG', 'eess.SP', 'stat.ML']",http://arxiv.org/abs/2310.11110v1
123,MorphFlow: Estimating Motion in In Situ Tests of Concrete,http://arxiv.org/pdf/2310.11109v1,"[arxiv.Result.Author('Tessa Nogatz'), arxiv.Result.Author('Claudia Redenbach'), arxiv.Result.Author('Katja Schladitz')]",,2023-10-17 09:49:46+00:00,"We present a novel algorithm explicitly tailored to estimate motion from time
series of 3D images of concrete. Such volumetric images are usually acquired by
Computed Tomography and can contain for example in situ tests, or more complex
procedures like self-healing. Our algorithm is specifically designed to tackle
the challenge of large scale in situ investigations of concrete. That means it
cannot only cope with big images, but also with discontinuous displacement
fields that often occur in in situ tests of concrete. We show the superior
performance of our algorithm, especially regarding plausibility and time
efficient processing. Core of the algorithm is a novel multiscale
representation based on morphological wavelets. We use two examples for
validation: A classical in situ test on refractory concrete and and a three
point bending test on normal concrete. We show that for both applications
structural changes like crack initiation can be already found at low scales --
a central achievement of our algorithm.",,eess.IV,['eess.IV'],http://arxiv.org/abs/2310.11109v1
124,Extreme photometric and polarimetric variability of blazar S4 0954+65 at its maximum optical and $γ$-ray brightness levels,http://arxiv.org/pdf/2310.11108v1,"[arxiv.Result.Author('C. M. Raiteri'), arxiv.Result.Author('M. Villata'), arxiv.Result.Author('M. I. Carnerero'), arxiv.Result.Author('S. S. Savchenko'), arxiv.Result.Author('S. O. Kurtanidze'), arxiv.Result.Author('V. V. Vlasyuk'), arxiv.Result.Author('A. Marchini'), arxiv.Result.Author('K. Matsumoto'), arxiv.Result.Author('C. Lorey'), arxiv.Result.Author('M. D. Joner'), arxiv.Result.Author('K. Gazeas'), arxiv.Result.Author('D. Carosati'), arxiv.Result.Author('D. O. Mirzaqulov'), arxiv.Result.Author('J. A. Acosta Pulido'), arxiv.Result.Author('I. Agudo'), arxiv.Result.Author('R. Bachev'), arxiv.Result.Author('E. Benítez'), arxiv.Result.Author('G. A. Borman'), arxiv.Result.Author('P. Calcidese'), arxiv.Result.Author('W. P. Chen'), arxiv.Result.Author('G. Damljanovic'), arxiv.Result.Author('S. A. Ehgamberdiev'), arxiv.Result.Author('D. Elsässer'), arxiv.Result.Author('M. Feige'), arxiv.Result.Author('A. Frasca'), arxiv.Result.Author('H. Gaur'), arxiv.Result.Author('T. S. Grishina'), arxiv.Result.Author('A. C. Gupta'), arxiv.Result.Author('D. Hiriart'), arxiv.Result.Author('M. Holland'), arxiv.Result.Author('B. Horst'), arxiv.Result.Author('S. Ibryamov'), arxiv.Result.Author('R. Z. Ivanidze'), arxiv.Result.Author('J. Jensen'), arxiv.Result.Author('V. Jithesh'), arxiv.Result.Author('M. D. Jovanovic'), arxiv.Result.Author('S. Kiehlmann'), arxiv.Result.Author('G. N. Kimeridze'), arxiv.Result.Author('S. Kishore'), arxiv.Result.Author('E. N. Kopatskaya'), arxiv.Result.Author('O. M. Kurtanidze'), arxiv.Result.Author('E. G. Larionova'), arxiv.Result.Author('H. C. Lin'), arxiv.Result.Author('K. Mannheim'), arxiv.Result.Author('C. Marinelli'), arxiv.Result.Author('J. Moreira Reyes'), arxiv.Result.Author('D. A. Morozova'), arxiv.Result.Author('M. G. Nikolashvili'), arxiv.Result.Author('D. Reinhart'), arxiv.Result.Author('F. D. Romanov'), arxiv.Result.Author('E. Semkov'), arxiv.Result.Author('J. Seufert'), arxiv.Result.Author('E. V. Shishkina'), arxiv.Result.Author('L. A. Sigua'), arxiv.Result.Author('R. Skalidis'), arxiv.Result.Author('O. I. Spiridonova'), arxiv.Result.Author('M. Stojanovic'), arxiv.Result.Author('A. Strigachev'), arxiv.Result.Author('Y. V. Troitskaya'), arxiv.Result.Author('I. S. Troitskiy'), arxiv.Result.Author('A. Tsai'), arxiv.Result.Author('A. A. Vasilyev'), arxiv.Result.Author('O. Vince'), arxiv.Result.Author('K. Vrontaki'), arxiv.Result.Author('K. Wani'), arxiv.Result.Author('D. Watts'), arxiv.Result.Author('A. V. Zhovtan')]",,2023-10-17 09:48:02+00:00,"In 2022 the BL Lac object S4 0954+65 underwent a major variability phase,
reaching its historical maximum brightness in the optical and $\gamma$-ray
bands. We present optical photometric and polarimetric data acquired by the
Whole Earth Blazar Telescope (WEBT) Collaboration from 2022 April 6 to July 6.
Many episodes of unprecedented fast variability were detected, implying an
upper limit to the size of the emitting region as low as $10^{-4}$ parsec. The
WEBT data show rapid variability in both the degree and angle of polarization.
We analyse different models to explain the polarization behaviour in the
framework of a twisting jet model, which assumes that the long-term trend of
the flux is produced by variations in the emitting region viewing angle. All
the models can reproduce the average trend of the polarization degree, and can
account for its general anticorrelation with the flux, but the dispersion of
the data requires the presence of intrinsic mechanisms, such as turbulence,
shocks, or magnetic reconnection. The WEBT optical data are compared to
$\gamma$-ray data from the Fermi satellite. These are analysed with both fixed
and adaptive binning procedures. We show that the strong correlation between
optical and $\gamma$-ray data without measurable delay assumes different slopes
in faint and high brightness states, and this is compatible with a scenario
where in faint states we mainly see the imprint of the geometrical effects,
while in bright states the synchrotron self-Compton process dominates.",,astro-ph.HE,['astro-ph.HE'],http://arxiv.org/abs/2310.11108v1
125,Heat kernel fluctuations for stochastic processes on fractals and random media,http://arxiv.org/pdf/2310.11107v1,"[arxiv.Result.Author('Sebastian Andres'), arxiv.Result.Author('David Croydon'), arxiv.Result.Author('Takashi Kumagai')]",,2023-10-17 09:47:53+00:00,"It is well-known that stochastic processes on fractal spaces or in certain
random media exhibit anomalous heat kernel behaviour. One manifestation of such
irregular behaviour is the presence of fluctuations in the short- or long-time
asymptotics of the on-diagonal heat kernel. In this note we review some
examples for which such fluctuations are known to occur, including Brownian
motion on certain deterministic or random fractals, and simple random walks on
various examples of random graph trees, such as the incipient infinite cluster
of critical percolation on a regular tree and low-dimensional uniform spanning
trees. We also announce some new results that add the one-dimensional Bouchaud
trap model to this class of examples.",,math.PR,"['math.PR', 'math.AP']",http://arxiv.org/abs/2310.11107v1
126,3D Structure-guided Network for Tooth Alignment in 2D Photograph,http://arxiv.org/pdf/2310.11106v1,"[arxiv.Result.Author('Yulong Dou'), arxiv.Result.Author('Lanzhuju Mei'), arxiv.Result.Author('Dinggang Shen'), arxiv.Result.Author('Zhiming Cui')]",,2023-10-17 09:44:30+00:00,"Orthodontics focuses on rectifying misaligned teeth (i.e., malocclusions),
affecting both masticatory function and aesthetics. However, orthodontic
treatment often involves complex, lengthy procedures. As such, generating a 2D
photograph depicting aligned teeth prior to orthodontic treatment is crucial
for effective dentist-patient communication and, more importantly, for
encouraging patients to accept orthodontic intervention. In this paper, we
propose a 3D structure-guided tooth alignment network that takes 2D photographs
as input (e.g., photos captured by smartphones) and aligns the teeth within the
2D image space to generate an orthodontic comparison photograph featuring
aesthetically pleasing, aligned teeth. Notably, while the process operates
within a 2D image space, our method employs 3D intra-oral scanning models
collected in clinics to learn about orthodontic treatment, i.e., projecting the
pre- and post-orthodontic 3D tooth structures onto 2D tooth contours, followed
by a diffusion model to learn the mapping relationship. Ultimately, the aligned
tooth contours are leveraged to guide the generation of a 2D photograph with
aesthetically pleasing, aligned teeth and realistic textures. We evaluate our
network on various facial photographs, demonstrating its exceptional
performance and strong applicability within the orthodontic industry.",,cs.CV,['cs.CV'],http://arxiv.org/abs/2310.11106v1
127,Experimenting AI Technologies for Disinformation Combat: the IDMO Project,http://arxiv.org/pdf/2310.11097v1,"[arxiv.Result.Author('Lorenzo Canale'), arxiv.Result.Author('Alberto Messina')]",,2023-10-17 09:27:43+00:00,"The Italian Digital Media Observatory (IDMO) project, part of a European
initiative, focuses on countering disinformation and fake news. This report
outlines contributions from Rai-CRITS to the project, including: (i) the
creation of novel datasets for testing technologies (ii) development of an
automatic model for categorizing Pagella Politica verdicts to facilitate
broader analysis (iii) creation of an automatic model for recognizing textual
entailment with exceptional accuracy on the FEVER dataset (iv) assessment using
GPT-4 to identify textual entailmen (v) a game to raise awareness about fake
news at national events.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11097v1
128,Sparse-DySta: Sparsity-Aware Dynamic and Static Scheduling for Sparse Multi-DNN Workloads,http://arxiv.org/pdf/2310.11096v1,"[arxiv.Result.Author('Hongxiang Fan'), arxiv.Result.Author('Stylianos I. Venieris'), arxiv.Result.Author('Alexandros Kouris'), arxiv.Result.Author('Nicholas D. Lane')]",10.1145/3613424.3614263,2023-10-17 09:25:17+00:00,"Running multiple deep neural networks (DNNs) in parallel has become an
emerging workload in both edge devices, such as mobile phones where multiple
tasks serve a single user for daily activities, and data centers, where various
requests are raised from millions of users, as seen with large language models.
To reduce the costly computational and memory requirements of these workloads,
various efficient sparsification approaches have been introduced, resulting in
widespread sparsity across different types of DNN models. In this context,
there is an emerging need for scheduling sparse multi-DNN workloads, a problem
that is largely unexplored in previous literature. This paper systematically
analyses the use-cases of multiple sparse DNNs and investigates the
opportunities for optimizations. Based on these findings, we propose Dysta, a
novel bi-level dynamic and static scheduler that utilizes both static sparsity
patterns and dynamic sparsity information for the sparse multi-DNN scheduling.
Both static and dynamic components of Dysta are jointly designed at the
software and hardware levels, respectively, to improve and refine the
scheduling approach. To facilitate future progress in the study of this class
of workloads, we construct a public benchmark that contains sparse multi-DNN
workloads across different deployment scenarios, spanning from mobile phones
and AR/VR wearables to data centers. A comprehensive evaluation on the sparse
multi-DNN benchmark demonstrates that our proposed approach outperforms the
state-of-the-art methods with up to 10% decrease in latency constraint
violation rate and nearly 4X reduction in average normalized turnaround time.
Our artifacts and code are publicly available at:
https://github.com/SamsungLabs/Sparse-Multi-DNN-Scheduling.",,cs.DC,"['cs.DC', 'cs.AR', 'cs.LG']",http://arxiv.org/abs/2310.11096v1
129,SODA: Robust Training of Test-Time Data Adaptors,http://arxiv.org/pdf/2310.11093v1,"[arxiv.Result.Author('Zige Wang'), arxiv.Result.Author('Yonggang Zhang'), arxiv.Result.Author('Zhen Fang'), arxiv.Result.Author('Long Lan'), arxiv.Result.Author('Wenjing Yang'), arxiv.Result.Author('Bo Han')]",,2023-10-17 09:22:20+00:00,"Adapting models deployed to test distributions can mitigate the performance
degradation caused by distribution shifts. However, privacy concerns may render
model parameters inaccessible. One promising approach involves utilizing
zeroth-order optimization (ZOO) to train a data adaptor to adapt the test data
to fit the deployed models. Nevertheless, the data adaptor trained with ZOO
typically brings restricted improvements due to the potential corruption of
data features caused by the data adaptor. To address this issue, we revisit ZOO
in the context of test-time data adaptation. We find that the issue directly
stems from the unreliable estimation of the gradients used to optimize the data
adaptor, which is inherently due to the unreliable nature of the pseudo-labels
assigned to the test data. Based on this observation, we propose
pseudo-label-robust data adaptation (SODA) to improve the performance of data
adaptation. Specifically, SODA leverages high-confidence predicted labels as
reliable labels to optimize the data adaptor with ZOO for label prediction. For
data with low-confidence predictions, SODA encourages the adaptor to preserve
data information to mitigate data corruption. Empirical results indicate that
SODA can significantly enhance the performance of deployed models in the
presence of distribution shifts without requiring access to model parameters.",,cs.LG,"['cs.LG', 'cs.CV']",http://arxiv.org/abs/2310.11093v1
130,On a generalized density point defined by families of sequences involving ideals,http://arxiv.org/pdf/2310.11090v1,"[arxiv.Result.Author('Amar Kumar Banerjee'), arxiv.Result.Author('Indrajit Debnath')]",,2023-10-17 09:17:57+00:00,"In this paper we have introduced the notion of $\mathcal{I}_{(s)}$-density
point corresponding to the family of unbounded and $\mathcal{I}$-monotonic
increasing positive real sequences, where $\mathcal{I}$ is the ideal of subsets
of the set of natural numbers. We have studied the corresponding topology in
the space of reals and have investigated several properties of this topology.
Also we have formulated a weaker condition for the sequences so that the
classical density topology coincides with $\mathcal{I}_{(s)}$-density topology.",,math.GN,"['math.GN', '40A35, 54C30, 26E99']",http://arxiv.org/abs/2310.11090v1
131,MeKB-Rec: Personal Knowledge Graph Learning for Cross-Domain Recommendation,http://arxiv.org/pdf/2310.11088v1,"[arxiv.Result.Author('Xin Su'), arxiv.Result.Author('Yao Zhou'), arxiv.Result.Author('Zifei Shan'), arxiv.Result.Author('Qian Chen')]",,2023-10-17 09:13:24+00:00,"It is a long-standing challenge in modern recommender systems to effectively
make recommendations for new users, namely the cold-start problem. Cross-Domain
Recommendation (CDR) has been proposed to address this challenge, but current
ways to represent users' interests across systems are still severely limited.
We introduce Personal Knowledge Graph (PKG) as a domain-invariant interest
representation, and propose a novel CDR paradigm named MeKB-Rec. We first link
users and entities in a knowledge base to construct a PKG of users' interests,
named MeKB. Then we learn a semantic representation of MeKB for the
cross-domain recommendation. To efficiently utilize limited training data in
CDR, MeKB-Rec employs Pretrained Language Models to inject world knowledge into
understanding users' interests. Beyond most existing systems, our approach
builds a semantic mapping across domains which breaks the requirement for
in-domain user behaviors, enabling zero-shot recommendations for new users in a
low-resource domain. We experiment MeKB-Rec on well-established public CDR
datasets, and demonstrate that the new formulation % is more powerful than
previous approaches, achieves a new state-of-the-art that significantly
improves HR@10 and NDCG@10 metrics over best previous approaches by 24\%--91\%,
with a 105\% improvement for HR@10 of zero-shot users with no behavior in the
target domain. We deploy MeKB-Rec in WeiXin recommendation scenarios and
achieve significant gains in core online metrics. MeKB-Rec is now serving
hundreds of millions of users in real-world products.",,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']",http://arxiv.org/abs/2310.11088v1
132,Feature Pyramid biLSTM: Using Smartphone Sensors for Transportation Mode Detection,http://arxiv.org/pdf/2310.11087v1,"[arxiv.Result.Author('Qinrui Tang'), arxiv.Result.Author('Hao Cheng')]",,2023-10-17 09:13:10+00:00,"The widespread utilization of smartphones has provided extensive availability
to Inertial Measurement Units, providing a wide range of sensory data that can
be advantageous for the detection of transportation modes. The objective of
this study is to propose a novel end-to-end approach to effectively explore a
reduced amount of sensory data collected from a smartphone to achieve accurate
mode detection in common daily traveling activities. Our approach, called
Feature Pyramid biLSTM (FPbiLSTM), is characterized by its ability to reduce
the number of sensors required and processing demands, resulting in a more
efficient modeling process without sacrificing the quality of the outcomes than
the other current models. FPbiLSTM extends an existing CNN biLSTM model with
the Feature Pyramid Network, leveraging the advantages of both shallow layer
richness and deeper layer feature resilience for capturing temporal moving
patterns in various transportation modes. It exhibits an excellent performance
by employing the data collected from only three out of seven sensors, i.e.
accelerometers, gyroscopes, and magnetometers, in the 2018 Sussex-Huawei
Locomotion (SHL) challenge dataset, attaining a noteworthy accuracy of 95.1%
and an F1-score of 94.7% in detecting eight different transportation modes.",,cs.LG,"['cs.LG', 'cs.AI', 'eess.SP']",http://arxiv.org/abs/2310.11087v1
133,In-Context Few-Shot Relation Extraction via Pre-Trained Language Models,http://arxiv.org/pdf/2310.11085v1,"[arxiv.Result.Author('Yilmazcan Ozyurt'), arxiv.Result.Author('Stefan Feuerriegel'), arxiv.Result.Author('Ce Zhang')]",,2023-10-17 09:10:27+00:00,"Relation extraction aims at inferring structured human knowledge from textual
documents. State-of-the-art methods based on language models commonly have two
limitations: (1) they require named entities to be either given as input or
infer them, which introduces additional noise, and (2) they require human
annotations of documents. As a remedy, we present a novel framework for
in-context few-shot relation extraction via pre-trained language models. To the
best of our knowledge, we are the first to reformulate the relation extraction
task as a tailored in-context few-shot learning paradigm. Thereby, we achieve
crucial benefits in that we eliminate the need for both named entity
recognition and human annotation of documents. Unlike existing methods based on
fine-tuning, our framework is flexible in that it can be easily updated for a
new set of relations without re-training. We evaluate our framework using
DocRED, the largest publicly available dataset for document-level relation
extraction, and demonstrate that our framework achieves state-of-the-art
performance. Finally, our framework allows us to identify missing annotations,
and we thus show that our framework actually performs much better than the
original labels from the development set of DocRED.",,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']",http://arxiv.org/abs/2310.11085v1
134,Understanding writing style in social media with a supervised contrastively pre-trained transformer,http://arxiv.org/pdf/2310.11081v1,"[arxiv.Result.Author('Javier Huertas-Tato'), arxiv.Result.Author('Alejandro Martin'), arxiv.Result.Author('David Camacho')]",,2023-10-17 09:01:17+00:00,"Online Social Networks serve as fertile ground for harmful behavior, ranging
from hate speech to the dissemination of disinformation. Malicious actors now
have unprecedented freedom to misbehave, leading to severe societal unrest and
dire consequences, as exemplified by events such as the Capitol assault during
the US presidential election and the Antivaxx movement during the COVID-19
pandemic. Understanding online language has become more pressing than ever.
While existing works predominantly focus on content analysis, we aim to shift
the focus towards understanding harmful behaviors by relating content to their
respective authors. Numerous novel approaches attempt to learn the stylistic
features of authors in texts, but many of these approaches are constrained by
small datasets or sub-optimal training losses. To overcome these limitations,
we introduce the Style Transformer for Authorship Representations (STAR),
trained on a large corpus derived from public sources of 4.5 x 10^6 authored
texts involving 70k heterogeneous authors. Our model leverages Supervised
Contrastive Loss to teach the model to minimize the distance between texts
authored by the same individual. This author pretext pre-training task yields
competitive performance at zero-shot with PAN challenges on attribution and
clustering. Additionally, we attain promising results on PAN verification
challenges using a single dense layer, with our model serving as an embedding
encoder. Finally, we present results from our test partition on Reddit. Using a
support base of 8 documents of 512 tokens, we can discern authors from sets of
up to 1616 authors with at least 80\% accuracy. We share our pre-trained model
at huggingface (https://huggingface.co/AIDA-UPM/star) and our code is available
at (https://github.com/jahuerta92/star)",,cs.CL,"['cs.CL', 'cs.SI']",http://arxiv.org/abs/2310.11081v1
135,Learning from Red Teaming: Gender Bias Provocation and Mitigation in Large Language Models,http://arxiv.org/pdf/2310.11079v1,"[arxiv.Result.Author('Hsuan Su'), arxiv.Result.Author('Cheng-Chu Cheng'), arxiv.Result.Author('Hua Farn'), arxiv.Result.Author('Shachi H Kumar'), arxiv.Result.Author('Saurav Sahay'), arxiv.Result.Author('Shang-Tse Chen'), arxiv.Result.Author('Hung-yi Lee')]",,2023-10-17 08:56:04+00:00,"Recently, researchers have made considerable improvements in dialogue systems
with the progress of large language models (LLMs) such as ChatGPT and GPT-4.
These LLM-based chatbots encode the potential biases while retaining
disparities that can harm humans during interactions. The traditional biases
investigation methods often rely on human-written test cases. However, these
test cases are usually expensive and limited. In this work, we propose a
first-of-its-kind method that automatically generates test cases to detect
LLMs' potential gender bias. We apply our method to three well-known LLMs and
find that the generated test cases effectively identify the presence of biases.
To address the biases identified, we propose a mitigation strategy that uses
the generated test cases as demonstrations for in-context learning to
circumvent the need for parameter fine-tuning. The experimental results show
that LLMs generate fairer responses with the proposed approach.",,cs.CL,"['cs.CL', 'cs.AI']",http://arxiv.org/abs/2310.11079v1
136,A Lp-Theory for fractional stationary Navier-Stokes equations,http://arxiv.org/pdf/2310.11078v1,"[arxiv.Result.Author('Oscar Jarrín'), arxiv.Result.Author('Gastón Vergara-Hermosilla')]",,2023-10-17 08:54:12+00:00,"We consider the stationary (time-independent) Navier-Stokes equations in the
whole threedimensional space, under the action of a source term and with the
fractional Laplacian operator (--$\Delta$) $\alpha$/2 in the diffusion term. In
the framework of Lebesgue and Lorentz spaces, we find some natural sufficient
conditions on the external force and on the parameter $\alpha$ to prove the
existence and in some cases nonexistence of solutions. Secondly, we obtain
sharp pointwise decaying rates and asymptotic profiles of solutions, which
strongly depend on $\alpha$. Finally, we also prove the global regularity of
solutions. As a bi-product, we obtain some uniqueness theorems so-called
Liouville-type results. On the other hand, our regularity result yields a new
regularity criterion for the classical (with i.e. $\alpha$ = 2) stationary
Navier-Stokes equations. Contents",,math.AP,['math.AP'],http://arxiv.org/abs/2310.11078v1
137,Sim-to-Real Transfer of Adaptive Control Parameters for AUV Stabilization under Current Disturbance,http://arxiv.org/pdf/2310.11075v1,"[arxiv.Result.Author('Thomas Chaffre'), arxiv.Result.Author('Jonathan Wheare'), arxiv.Result.Author('Andrew Lammas'), arxiv.Result.Author('Paulo Santos'), arxiv.Result.Author('Gilles Le Chenadec'), arxiv.Result.Author('Karl Sammut'), arxiv.Result.Author('Benoit Clement')]",,2023-10-17 08:46:56+00:00,"Learning-based adaptive control methods hold the premise of enabling
autonomous agents to reduce the effect of process variations with minimal human
intervention. However, its application to autonomous underwater vehicles (AUVs)
has so far been restricted due to 1) unknown dynamics under the form of sea
current disturbance that we can not model properly nor measure due to limited
sensor capability and 2) the nonlinearity of AUVs tasks where the controller
response at some operating points must be overly conservative in order to
satisfy the specification at other operating points. Deep Reinforcement
Learning (DRL) can alleviates these limitations by training general-purpose
neural network policies, but applications of DRL algorithms to AUVs have been
restricted to simulated environments, due to their inherent high sample
complexity and distribution shift problem. This paper presents a novel
approach, merging the Maximum Entropy Deep Reinforcement Learning framework
with a classic model-based control architecture, to formulate an adaptive
controller. Within this framework, we introduce a Sim-to-Real transfer strategy
comprising the following components: a bio-inspired experience replay
mechanism, an enhanced domain randomisation technique, and an evaluation
protocol executed on a physical platform. Our experimental assessments
demonstrate that this method effectively learns proficient policies from
suboptimal simulated models of the AUV, resulting in control performance 3
times higher when transferred to a real-world vehicle, compared to its
model-based nonadaptive but optimal counterpart.",,cs.RO,"['cs.RO', 'cs.AI', 'cs.SY', 'eess.SY']",http://arxiv.org/abs/2310.11075v1
138,Highly Efficient Creation and Detection of Ultracold Deeply-Bound Molecules via Chainwise Stimulated Raman Shortcut-to-Adiabatic Passage,http://arxiv.org/pdf/2310.11071v1,"[arxiv.Result.Author('Jiahui Zhang'), arxiv.Result.Author('Li Deng'), arxiv.Result.Author('Yueping Niu'), arxiv.Result.Author('Shangqing Gong')]",,2023-10-17 08:38:04+00:00,"Chainwise stimulated Raman adiabatic passage (C-STIRAP) in M-type molecular
system is a good alternative in creating ultracold deeply-bound molecules when
the typical STIRAP in {\Lambda}-type system does not work due to weak
Frank-Condon factors between states. However, its creation efficiency under the
smooth evolution is generally low. During the process, the population in the
intermediate states may decay out quickly and the strong laser pulses may
induce multi-photon processes. In this paper, we find that
shortcut-to-adiabatic (STA) passage fits very well in improving the performance
of the C-STIRAP. Currently, related discussions on the so-called chainwise
stimulated Raman shortcut-to-adiabatic passage (C-STIRSAP) are rare. Here, we
investigate this topic under the adiabatic elimination. Given a relation among
the four incident pulses, it is quite interesting that the M-type system can be
generalized into an effective {\Lambda}-type structure with the simplest
resonant coupling. Consequently, all possible methods of STA for three-state
system can be borrowed. We take the counter-diabatic driving and ""chosen path""
method as instances to demonstrate our treatment on the molecular system.
Although the ""chosen path"" method does not work well in real three-state system
if there is strong decay in the excited state, our C-STIRSAP protocol under
both the two methods can create ultracold deeply-bound molecules with high
efficiency in the M-type system. The evolution time is shortened without strong
laser pulses and the robustness of STA is well preserved. Finally, the
detection of ultracold deeply-bound molecules is discussed.",,quant-ph,['quant-ph'],http://arxiv.org/abs/2310.11071v1
139,Intelligent Resource Allocation for UAV-Based Cognitive NOMA Networks: An Active Inference Approach,http://arxiv.org/pdf/2310.11070v1,"[arxiv.Result.Author('Felix Obite'), arxiv.Result.Author('Ali Krayani'), arxiv.Result.Author('Atm S. Alam'), arxiv.Result.Author('Lucio Marcenaro'), arxiv.Result.Author('Arumugam Nallanathan'), arxiv.Result.Author('Carlo Regazzoni')]",,2023-10-17 08:33:44+00:00,"Future wireless networks will need to improve adaptive resource allocation
and decision-making to handle the increasing number of intelligent devices.
Unmanned aerial vehicles (UAVs) are being explored for their potential in
real-time decision-making. Moreover, cognitive non-orthogonal multiple access
(Cognitive-NOMA) is envisioned as a remedy to address spectrum scarcity and
enable massive connectivity. This paper investigates the design of joint
subchannel and power allocation in an uplink UAV-based cognitive NOMA network.
We aim to maximize the cumulative sum rate by jointly optimizing the subchannel
and power allocation based on the UAV's mobility at each time step. This is
often formulated as an optimization problem with random variables. However,
conventional optimization algorithms normally introduce significant complexity,
and machine learning methods often rely on large but partially representative
datasets to build solution models, assuming stationary testing data.
Consequently, inference strategies for non stationary events are often
overlooked. In this study, we introduce a novel active inference-based learning
approach, rooted in cognitive neuroscience, to solve this complex problem. The
framework involves creating a training dataset using random or iterative
methods to find suboptimal resource allocations. This dataset trains a mobile
UAV offline, enabling it to learn a generative model of discrete subchannels
and continuous power allocation. The UAV then uses this model for online
inference. The method incrementally derives new generative models from training
data by identifying dynamic equilibrium conditions between required actions and
variables, represented within a unique dynamic Bayesian network. The proposed
approach is validated through numerical simulations, showing efficient
performance compared to suboptimal baseline schemes.",,eess.SP,['eess.SP'],http://arxiv.org/abs/2310.11070v1
140,VoxArabica: A Robust Dialect-Aware Arabic Speech Recognition System,http://arxiv.org/pdf/2310.11069v1,"[arxiv.Result.Author('Abdul Waheed'), arxiv.Result.Author('Bashar Talafha'), arxiv.Result.Author('Peter Suvellin'), arxiv.Result.Author('Abdelrahman Elmadney'), arxiv.Result.Author('Muhammad Abdul-Mageed')]",,2023-10-17 08:33:02+00:00,"Arabic is a complex language with many varieties and dialects spoken by over
450 millions all around the world. Due to the linguistic diversity and
variations, it is challenging to build a robust and generalized ASR system for
Arabic. In this work, we address this gap by developing and demoing a system,
dubbed VoxArabica, for dialect identification (DID) as well as automatic speech
recognition (ASR) of Arabic. We train a wide range of models such as HuBERT
(DID), Whisper, and XLS-R (ASR) in a supervised setting for Arabic DID and ASR
tasks. Our DID models are trained to identify 17 different dialects in addition
to MSA. We finetune our ASR models on MSA, Egyptian, Moroccan, and mixed data.
Additionally, for the remaining dialects in ASR, we provide the option to
choose various models such as Whisper and MMS in a zero-shot setting. We
integrate these models into a single web interface with diverse features such
as audio recording, file upload, model selection, and the option to raise flags
for incorrect outputs. Overall, we believe VoxArabica will be useful for a wide
range of audiences concerned with Arabic research. Our system is currently
running at https://cdce-206-12-100-168.ngrok.io/.",,cs.CL,"['cs.CL', 'cs.SD', 'eess.AS']",http://arxiv.org/abs/2310.11069v1
141,"Aerial-Aided mmWave VANETs Using NOMA: Performance Analysis, Comparison, and Insights",http://arxiv.org/pdf/2310.11068v1,"[arxiv.Result.Author('Abdullah Abu Zaid'), arxiv.Result.Author('Baha Eddine Youcef Belmekki'), arxiv.Result.Author('Mohamed-Slim Alouini')]",,2023-10-17 08:25:51+00:00,"In this paper, we propose the integration of tethered flying platforms in
cooperative vehicular ad hoc networks (VANETs) to alleviate the problems of
rapid urbanization. In this context, we study the performance of VANETs by
deriving approximate outage probability and average achievable rate expressions
using tools from stochastic geometry. We compare between the usage of networked
tethered flying platforms (NTFPs) and traditional roadside units (RSUs). On the
other hand, the rapid increase of smart devices in vehicles and the upcoming
urban air mobility (UAM) vision will congest the spectrum and require increased
data rates. Hence, we use non-orthogonal multiple access (NOMA) to improve
spectral efficiency and compare its performance to orthogonal access schemes.
Furthermore, we utilize millimeter-wave (mmWave) frequencies for high data
rates and implement a sectored beamforming model. We extensively study the
system using three transmission schemes: direct, relay, and hybrid
transmission. The results show that when acting as relays, NTFPs outperform
RSUs for larger distances between the transmitting and the receiving vehicles,
while RSUs outperform NTFPs for short distances. However, NTFPs are the best
solution when acting as a source. Moreover, we find that, in most cases, direct
transmission is preferred to achieve a high rate compared to other schemes.
Finally, the results are summarized in two tables that provide insights into
connecting VANETs by selecting the most suitable platform and type of
communication for a given set of parameters, configurations, and requirements.",,eess.SP,['eess.SP'],http://arxiv.org/abs/2310.11068v1
142,Sommerfeld effect for continuum gamma-ray spectra from Dark Matter annihilation,http://arxiv.org/pdf/2310.11067v1,"[arxiv.Result.Author('Barbara Jäger'), arxiv.Result.Author('Martin Vollmann')]",,2023-10-17 08:19:15+00:00,"We present a calculation of the continuum part of the gamma-ray spectra
resulting from Dark Matter annihilation in the framework of the MSSM taking
into account Sommerfeld effects. Concentrating on pure wino and pure higgsino
scenarios we compare our calculation to existing work and explore the numerical
impact of the features not captured by previous approximative descriptions. We
find that, in particular for large neutralino masses, when the Sommerfeld
enhancement is very large, chargino-antichargino annihilation processes, which
have not been considered before, lead to sizable differences with respect to
existing calculations. In scenarios with neutralinos in the intermediate-mass
range, we find that the role of the charginos is crucial in the endpoint
regime. Our calculation provides the currently most accurate prediction for the
continuum gamma-ray spectra.",,hep-ph,"['hep-ph', 'astro-ph.HE']",http://arxiv.org/abs/2310.11067v1
143,Causal Feature Selection via Transfer Entropy,http://arxiv.org/pdf/2310.11059v1,"[arxiv.Result.Author('Paolo Bonetti'), arxiv.Result.Author('Alberto Maria Metelli'), arxiv.Result.Author('Marcello Restelli')]",,2023-10-17 08:04:45+00:00,"Machine learning algorithms are designed to capture complex relationships
between features. In this context, the high dimensionality of data often
results in poor model performance, with the risk of overfitting. Feature
selection, the process of selecting a subset of relevant and non-redundant
features, is, therefore, an essential step to mitigate these issues. However,
classical feature selection approaches do not inspect the causal relationship
between selected features and target, which can lead to misleading results in
real-world applications. Causal discovery, instead, aims to identify causal
relationships between features with observational data. In this paper, we
propose a novel methodology at the intersection between feature selection and
causal discovery, focusing on time series. We introduce a new causal feature
selection approach that relies on the forward and backward feature selection
procedures and leverages transfer entropy to estimate the causal flow of
information from the features to the target in time series. Our approach
enables the selection of features not only in terms of mere model performance
but also captures the causal information flow. In this context, we provide
theoretical guarantees on the regression and classification errors for both the
exact and the finite-sample cases. Finally, we present numerical validations on
synthetic and real-world regression problems, showing results competitive
w.r.t. the considered baselines.",,cs.LG,['cs.LG'],http://arxiv.org/abs/2310.11059v1
144,Revisiting Renormalization Group Equations of the SMEFT Dimension-Seven Operators,http://arxiv.org/pdf/2310.11055v1,[arxiv.Result.Author('Di Zhang')],,2023-10-17 07:48:24+00:00,"In this work, we revisit the renormalization group equations (RGEs) of
dimension-seven (dim-7) operators in the Standard Model effective field theory
(SMEFT) resulting from mixing among dim-7 operators themselves by means of the
background field method. Adopting a recently proposed physical basis for dim-7
operators, we achieve the explicit RGEs of all non-redundant dim-7 operators in
the SMEFT for the first time. Together with those originating from the dim-5
and dim-6 operators, these results constitute the complete RGEs of dim-7
operators, and hence can be exploited to study full RG-running effects on some
lepton- or baryon-number-violating processes involving dim-7 operators in the
SMEFT, such as neutrino masses, neutrinoless double beta decay, meson and
nucleon decays. We perform an analysis of the structure and perturbative power
counting of the obtained one-loop anomalous dimension matrix, which is
consistent with a non-renormalization theorem and the naive dimension analysis.
Additionally, a partial check on some results is carried out by means of
different tools and quantum field gauges.",,hep-ph,"['hep-ph', 'hep-ex']",http://arxiv.org/abs/2310.11055v1
145,Denevil: Towards Deciphering and Navigating the Ethical Values of Large Language Models via Instruction Learning,http://arxiv.org/pdf/2310.11053v1,"[arxiv.Result.Author('Shitong Duan'), arxiv.Result.Author('Xiaoyuan Yi'), arxiv.Result.Author('Peng Zhang'), arxiv.Result.Author('Tun Lu'), arxiv.Result.Author('Xing Xie'), arxiv.Result.Author('Ning Gu')]",,2023-10-17 07:42:40+00:00,"Large Language Models (LLMs) have made unprecedented breakthroughs, yet their
increasing integration into everyday life might raise societal risks due to
generated unethical content. Despite extensive study on specific issues like
bias, the intrinsic values of LLMs remain largely unexplored from a moral
philosophy perspective. This work delves into ethical values utilizing Moral
Foundation Theory. Moving beyond conventional discriminative evaluations with
poor reliability, we propose DeNEVIL, a novel prompt generation algorithm
tailored to dynamically exploit LLMs' value vulnerabilities and elicit the
violation of ethics in a generative manner, revealing their underlying value
inclinations. On such a basis, we construct MoralPrompt, a high-quality dataset
comprising 2,397 prompts covering 500+ value principles, and then benchmark the
intrinsic values across a spectrum of LLMs. We discovered that most models are
essentially misaligned, necessitating further ethical value alignment. In
response, we develop VILMO, an in-context alignment method that substantially
enhances the value compliance of LLM outputs by learning to generate
appropriate value instructions, outperforming existing competitors. Our methods
are suitable for black-box and open-source models, offering a promising initial
step in studying the ethical values of LLMs.",,cs.CL,"['cs.CL', 'cs.AI', 'cs.CY']",http://arxiv.org/abs/2310.11053v1
146,$k$-$t$ CLAIR: Self-Consistency Guided Multi-Prior Learning for Dynamic Parallel MR Image Reconstruction,http://arxiv.org/pdf/2310.11050v1,"[arxiv.Result.Author('Liping Zhang'), arxiv.Result.Author('Weitian Chen')]",,2023-10-17 07:37:32+00:00,"Cardiac magnetic resonance imaging (CMR) has been widely used in clinical
practice for the medical diagnosis of cardiac diseases. However, the long
acquisition time hinders its development in real-time applications. Here, we
propose a novel self-consistency guided multi-prior learning framework named
$k$-$t$ CLAIR to exploit spatiotemporal correlations from highly undersampled
data for accelerated dynamic parallel MRI reconstruction. The $k$-$t$ CLAIR
progressively reconstructs faithful images by leveraging multiple complementary
priors learned in the $x$-$t$, $x$-$f$, and $k$-$t$ domains in an iterative
fashion, as dynamic MRI exhibits high spatiotemporal redundancy. Additionally,
$k$-$t$ CLAIR incorporates calibration information for prior learning,
resulting in a more consistent reconstruction. Experimental results on cardiac
cine and T1W/T2W images demonstrate that $k$-$t$ CLAIR achieves high-quality
dynamic MR reconstruction in terms of both quantitative and qualitative
performance.",,eess.IV,"['eess.IV', 'cs.CV', 'physics.med-ph']",http://arxiv.org/abs/2310.11050v1
147,Nonet at SemEval-2023 Task 6: Methodologies for Legal Evaluation,http://arxiv.org/pdf/2310.11049v1,"[arxiv.Result.Author('Shubham Kumar Nigam'), arxiv.Result.Author('Aniket Deroy'), arxiv.Result.Author('Noel Shallum'), arxiv.Result.Author('Ayush Kumar Mishra'), arxiv.Result.Author('Anup Roy'), arxiv.Result.Author('Shubham Kumar Mishra'), arxiv.Result.Author('Arnab Bhattacharya'), arxiv.Result.Author('Saptarshi Ghosh'), arxiv.Result.Author('Kripabandhu Ghosh')]",10.18653/v1/2023.semeval-1.180,2023-10-17 07:35:11+00:00,"This paper describes our submission to the SemEval-2023 for Task 6 on
LegalEval: Understanding Legal Texts. Our submission concentrated on three
subtasks: Legal Named Entity Recognition (L-NER) for Task-B, Legal Judgment
Prediction (LJP) for Task-C1, and Court Judgment Prediction with Explanation
(CJPE) for Task-C2. We conducted various experiments on these subtasks and
presented the results in detail, including data statistics and methodology. It
is worth noting that legal tasks, such as those tackled in this research, have
been gaining importance due to the increasing need to automate legal analysis
and support. Our team obtained competitive rankings of 15$^{th}$, 11$^{th}$,
and 1$^{st}$ in Task-B, Task-C1, and Task-C2, respectively, as reported on the
leaderboard.",https://aclanthology.org/2023.semeval-1.180,cs.CL,"['cs.CL', 'cs.AI', 'cs.IR', 'cs.LG']",http://arxiv.org/abs/2310.11049v1
148,A Tutorial on Near-Field XL-MIMO Communications Towards 6G,http://arxiv.org/pdf/2310.11044v1,"[arxiv.Result.Author('Haiquan Lu'), arxiv.Result.Author('Yong Zeng'), arxiv.Result.Author('Changsheng You'), arxiv.Result.Author('Yu Han'), arxiv.Result.Author('Jiayi Zhang'), arxiv.Result.Author('Zhe Wang'), arxiv.Result.Author('Zhenjun Dong'), arxiv.Result.Author('Shi Jin'), arxiv.Result.Author('Cheng-Xiang Wang'), arxiv.Result.Author('Tao Jiang'), arxiv.Result.Author('Xiaohu You'), arxiv.Result.Author('Rui Zhang')]",,2023-10-17 07:25:00+00:00,"Extremely large-scale multiple-input multiple-output (XL-MIMO) is a promising
technology for the sixth-generation (6G) mobile communication networks. By
significantly boosting the antenna number or size to at least an order of
magnitude beyond current massive MIMO systems, XL-MIMO is expected to
unprecedentedly enhance the spectral efficiency and spatial resolution for
wireless communication. The evolution from massive MIMO to XL-MIMO is not
simply an increase in the array size, but faces new design challenges, in terms
of near-field channel modelling, performance analysis, channel estimation, and
practical implementation. In this article, we give a comprehensive tutorial
overview on near-field XL-MIMO communications, aiming to provide useful
guidance for tackling the above challenges. First, the basic near-field
modelling for XL-MIMO is established, by considering the new characteristics of
non-uniform spherical wave (NUSW) and spatial non-stationarity. Next, based on
the near-field modelling, the performance analysis of XL-MIMO is presented,
including the near-field signal-to-noise ratio (SNR) scaling laws, beam
focusing pattern, achievable rate, and degrees-of-freedom (DoF). Furthermore,
various XL-MIMO design issues such as near-field beam codebook, beam training,
channel estimation, and delay alignment modulation (DAM) transmission are
elaborated. Finally, we point out promising directions to inspire future
research on near-field XL-MIMO communications.",,cs.IT,"['cs.IT', 'eess.SP', 'math.IT']",http://arxiv.org/abs/2310.11044v1
149,Spoofing Attack Detection in the Physical Layer with Robustness to User Movement,http://arxiv.org/pdf/2310.11043v1,"[arxiv.Result.Author('Daniel Romero'), arxiv.Result.Author('Tien Ngoc Ha'), arxiv.Result.Author('Peter Gerstoft')]",,2023-10-17 07:18:03+00:00,"In a spoofing attack, an attacker impersonates a legitimate user to access or
modify data belonging to the latter. Typical approaches for spoofing detection
in the physical layer declare an attack when a change is observed in certain
channel features, such as the received signal strength (RSS) measured by
spatially distributed receivers. However, since channels change over time, for
example due to user movement, such approaches are impractical. To sidestep this
limitation, this paper proposes a scheme that combines the decisions of a
position-change detector based on a deep neural network to distinguish spoofing
from movement. Building upon community detection on graphs, the sequence of
received frames is partitioned into subsequences to detect concurrent
transmissions from distinct locations. The scheme can be easily deployed in
practice since it just involves collecting a small dataset of measurements at a
few tens of locations that need not even be computed or recorded. The scheme is
evaluated on real data collected for this purpose.",,eess.SP,"['eess.SP', 'cs.AI']",http://arxiv.org/abs/2310.11043v1
150,Diagrammatic Modelling of Causality and Causal Relations,http://arxiv.org/pdf/2310.11042v1,[arxiv.Result.Author('Sabah Al-Fedaghi')],,2023-10-17 07:17:51+00:00,"It has been stated that the notion of cause and effect is one object of study
that sciences and engineering revolve around. Lately, in software engineering,
diagrammatic causal inference methods (e.g., Pearl s model) have gained
popularity (e.g., analyzing causes and effects of change in software
requirement development). This paper concerns diagrammatical (graphic) models
of causal relationships. Specifically, we experiment with using the conceptual
language of thinging machines (TMs) as a tool in this context. This would
benefit works on causal relationships in requirements engineering, enhance our
understanding of the TM modeling, and contribute to the study of the
philosophical notion of causality. To specify the causality in a system s
description is to constrain the system s behavior and thus exclude some
possible chronologies of events. The notion of causality has been studied based
on tools to express causal questions in diagrammatic and algebraic forms.
Causal models deploy diagrammatic models, structural equations, and
counterfactual and interventional logic. Diagrammatic models serve as a
language for representing what we know about the world. The research
methodology in the paper focuses on converting causal graphs into TM models and
contrasts the two types of representation. The results show that the TM
depiction of causality is more complete and therefore can provide a foundation
for causal graphs.",,cs.SE,['cs.SE'],http://arxiv.org/abs/2310.11042v1
151,Co-Learning Semantic-aware Unsupervised Segmentation for Pathological Image Registration,http://arxiv.org/pdf/2310.11040v1,"[arxiv.Result.Author('Yang Liu'), arxiv.Result.Author('Shi Gu')]",10.1007/978-3-031-43999-5_51,2023-10-17 07:13:28+00:00,"The registration of pathological images plays an important role in medical
applications. Despite its significance, most researchers in this field
primarily focus on the registration of normal tissue into normal tissue. The
negative impact of focal tissue, such as the loss of spatial correspondence
information and the abnormal distortion of tissue, are rarely considered. In
this paper, we propose GIRNet, a novel unsupervised approach for pathological
image registration by incorporating segmentation and inpainting through the
principles of Generation, Inpainting, and Registration (GIR). The registration,
segmentation, and inpainting modules are trained simultaneously in a
co-learning manner so that the segmentation of the focal area and the
registration of inpainted pairs can improve collaboratively. Overall, the
registration of pathological images is achieved in a completely unsupervised
learning framework. Experimental results on multiple datasets, including
Magnetic Resonance Imaging (MRI) of T1 sequences, demonstrate the efficacy of
our proposed method. Our results show that our method can accurately achieve
the registration of pathological images and identify lesions even in
challenging imaging modalities. Our unsupervised approach offers a promising
solution for the efficient and cost-effective registration of pathological
images. Our code is available at
https://github.com/brain-intelligence-lab/GIRNet.","International Conference on Medical Image Computing and
  Computer-Assisted Intervention, pp. 537-547. Cham: Springer Nature
  Switzerland, 2023",eess.IV,"['eess.IV', 'cs.CV']",http://arxiv.org/abs/2310.11040v1
152,Channel Autocorrelation Estimation for IRS-Aided Wireless Communications Based on Power Measurements,http://arxiv.org/pdf/2310.11038v1,"[arxiv.Result.Author('Ge Yan'), arxiv.Result.Author('Lipeng Zhu'), arxiv.Result.Author('Rui Zhang')]",,2023-10-17 07:07:44+00:00,"Intelligent reflecting surface (IRS) can bring significant performance
enhancement for wireless communication systems by reconfiguring wireless
channels via passive signal reflection. However, such performance improvement
generally relies on the knowledge of channel state information (CSI) for
IRS-associated links. Prior IRS channel estimation strategies mainly estimate
IRS-cascaded channels based on the excessive pilot signals received at the
users/base station (BS) with time-varying IRS reflections, which, however, are
not compatible with the existing channel training/estimation protocol for
cellular networks. To address this issue, we propose in this paper a new
channel estimation scheme for IRS-assisted communication systems based on the
received signal power measured at the user, which is practically attainable
without the need of changing the current protocol. Specifically, due to the
lack of signal phase information in power measurements, the autocorrelation
matrix of the BS-IRS-user cascaded channel is estimated by solving equivalent
matrix-rank-minimization problems. Simulation results are provided to verify
the effectiveness of the proposed channel estimation algorithm as well as the
IRS passive reflection design based on the estimated channel autocorrelation
matrix.",,eess.SP,['eess.SP'],http://arxiv.org/abs/2310.11038v1
153,Sampling for Remote Estimation of the Wiener Process over an Unreliable Channel,http://arxiv.org/pdf/2310.11037v1,"[arxiv.Result.Author('Jiayu Pan'), arxiv.Result.Author('Yin Sun'), arxiv.Result.Author('Ness B. Shroff')]",,2023-10-17 07:06:12+00:00,"In this paper, we study a sampling problem where a source takes samples from
a Wiener process and transmits them through a wireless channel to a remote
estimator. Due to channel fading, interference, and potential collisions, the
packet transmissions are unreliable and could take random time durations. Our
objective is to devise an optimal causal sampling policy that minimizes the
long-term average mean square estimation error. This optimal sampling problem
is a recursive optimal stopping problem, which is generally quite difficult to
solve. However, we prove that the optimal sampling strategy is, in fact, a
simple threshold policy where a new sample is taken whenever the instantaneous
estimation error exceeds a threshold. This threshold remains a constant value
that does not vary over time. By exploring the structure properties of the
recursive optimal stopping problem, a low-complexity iterative algorithm is
developed to compute the optimal threshold. This work generalizes previous
research by incorporating both transmission errors and random transmission
times into remote estimation. Numerical simulations are provided to compare our
optimal policy with the zero-wait and age-optimal policies.",,cs.IT,"['cs.IT', 'math.IT']",http://arxiv.org/abs/2310.11037v1
154,Radio Map Estimation in the Real-World: Empirical Validation and Analysis,http://arxiv.org/pdf/2310.11036v1,"[arxiv.Result.Author('Raju Shrestha'), arxiv.Result.Author('Tien Ngoc Ha'), arxiv.Result.Author('Pham Q. Viet'), arxiv.Result.Author('Daniel Romero')]",,2023-10-17 07:03:41+00:00,"Radio maps quantify received signal strength or other magnitudes of the radio
frequency environment at every point of a geographical region. These maps play
a vital role in a large number of applications such as wireless network
planning, spectrum management, and optimization of communication systems.
However, empirical validation of the large number of existing radio map
estimators is highly limited. To fill this gap, a large data set of
measurements has been collected with an autonomous unmanned aerial vehicle
(UAV) and a representative subset of these estimators were evaluated on this
data. The performance-complexity trade-off and the impact of fast fading are
extensively investigated. Although sophisticated estimators based on deep
neural networks (DNNs) exhibit the best performance, they are seen to require
large volumes of training data to offer a substantial advantage relative to
more traditional schemes. A novel algorithm that blends both kinds of
estimators is seen to enjoy the benefits of both, thereby suggesting the
potential of exploring this research direction further.",,eess.SP,"['eess.SP', 'cs.AI', 'physics.app-ph']",http://arxiv.org/abs/2310.11036v1
155,Lyricist-Singer Entropy Affects Lyric-Lyricist Classification Performance,http://arxiv.org/pdf/2310.11035v1,"[arxiv.Result.Author('Mitsuki Morita'), arxiv.Result.Author('Masato Kikuchi'), arxiv.Result.Author('Tadachika Ozono')]",,2023-10-17 07:02:26+00:00,"Although lyrics represent an essential component of music, few music
information processing studies have been conducted on the characteristics of
lyricists. Because these characteristics may be valuable for musical
applications, such as recommendations, they warrant further study. We
considered a potential method that extracts features representing the
characteristics of lyricists from lyrics. Because these features must be
identified prior to extraction, we focused on lyricists with easily
identifiable features. We believe that it is desirable for singers to perform
unique songs that share certain characteristics specific to the singer.
Accordingly, we hypothesized that lyricists account for the unique
characteristics of the singers they write lyrics for. In other words,
lyric-lyricist classification performance or the ease of capturing the features
of a lyricist from the lyrics may depend on the variety of singers. In this
study, we observed a relationship between lyricist-singer entropy or the
variety of singers associated with a single lyricist and lyric-lyricist
classification performance. As an example, the lyricist-singer entropy is
minimal when the lyricist writes lyrics for only one singer. In our
experiments, we grouped lyricists among five groups in terms of lyricist-singer
entropy and assessed the lyric-lyricist classification performance within each
group. Consequently, the best F1 score was obtained for the group with the
lowest lyricist-singer entropy. Our results suggest that further analyses of
the features contributing to lyric-lyricist classification performance on the
lowest lyricist-singer entropy group may improve the feature extraction task
for lyricists.",,cs.SD,"['cs.SD', 'cs.CL', 'eess.AS']",http://arxiv.org/abs/2310.11035v1
156,Slicenet: a Simple and Scalable Flow-Level Simulator for Network Slice Provisioning and Management,http://arxiv.org/pdf/2310.11033v1,"[arxiv.Result.Author('Viswanath KumarSkandPriya'), arxiv.Result.Author('Abdulhalim Dandoush'), arxiv.Result.Author('Gladys Diaz')]",,2023-10-17 07:01:44+00:00,"Network slicing plays a crucial role in the progression of 5G and beyond,
facilitating dedicated logical networks to meet diverse and specific service
requirements. The principle of End-to-End (E2E) slice includes not only a
service chain of physical or virtual functions for the radio and core of 5G/6G
networks but also the full path to the application servers that might be
running at some edge computing or at central cloud. Nonetheless, the
development and optimization of E2E network slice management systems
necessitate a reliable simulation tool for evaluating different aspects at
large-scale network topologies such as resource allocation and function
placement models. This paper introduces Slicenet, a mininetlike simulator
crafted for E2E network slicing experimentation at the flow level. Slicenet
aims at facilitating the investigation of a wide range of slice optimization
techniques, delivering measurable, reproducible results without the need for
physical resources or complex integration tools. It provides a well-defined
process for conducting experiments, which includes the creation and
implementation of policies for various components such as edge and central
cloud resources, network functions of multiple slices of different
characteristics. Furthermore, Slicenet effortlessly produces meaningful
visualizations from simulation results, aiding in comprehensive understanding.
Utilizing Slicenet, service providers can derive invaluable insights into
resource optimization, capacity planning, Quality of Service (QoS) assessment,
cost optimization, performance comparison, risk mitigation, and Service Level
Agreement (SLA) compliance, thereby fortifying network resource management and
slice orchestration.",,cs.NI,['cs.NI'],http://arxiv.org/abs/2310.11033v1
157,Core Building Blocks: Next Gen Geo Spatial GPT Application,http://arxiv.org/pdf/2310.11029v1,"[arxiv.Result.Author('Ashley Fernandez'), arxiv.Result.Author('Swaraj Dube')]",,2023-10-17 06:59:31+00:00,"This paper proposes MapGPT which is a novel approach that integrates the
capabilities of language models, specifically large language models (LLMs),
with spatial data processing techniques. This paper introduces MapGPT, which
aims to bridge the gap between natural language understanding and spatial data
analysis by highlighting the relevant core building blocks. By combining the
strengths of LLMs and geospatial analysis, MapGPT enables more accurate and
contextually aware responses to location-based queries. The proposed
methodology highlights building LLMs on spatial and textual data, utilizing
tokenization and vector representations specific to spatial information. The
paper also explores the challenges associated with generating spatial vector
representations. Furthermore, the study discusses the potential of
computational capabilities within MapGPT, allowing users to perform geospatial
computations and obtain visualized outputs. Overall, this research paper
presents the building blocks and methodology of MapGPT, highlighting its
potential to enhance spatial data understanding and generation in natural
language processing applications.",,cs.AI,['cs.AI'],http://arxiv.org/abs/2310.11029v1
158,Matrix Compression via Randomized Low Rank and Low Precision Factorization,http://arxiv.org/pdf/2310.11028v1,"[arxiv.Result.Author('Rajarshi Saha'), arxiv.Result.Author('Varun Srivastava'), arxiv.Result.Author('Mert Pilanci')]",,2023-10-17 06:56:57+00:00,"Matrices are exceptionally useful in various fields of study as they provide
a convenient framework to organize and manipulate data in a structured manner.
However, modern matrices can involve billions of elements, making their storage
and processing quite demanding in terms of computational resources and memory
usage. Although prohibitively large, such matrices are often approximately low
rank. We propose an algorithm that exploits this structure to obtain a low rank
decomposition of any matrix $\mathbf{A}$ as $\mathbf{A} \approx
\mathbf{L}\mathbf{R}$, where $\mathbf{L}$ and $\mathbf{R}$ are the low rank
factors. The total number of elements in $\mathbf{L}$ and $\mathbf{R}$ can be
significantly less than that in $\mathbf{A}$. Furthermore, the entries of
$\mathbf{L}$ and $\mathbf{R}$ are quantized to low precision formats $--$
compressing $\mathbf{A}$ by giving us a low rank and low precision
factorization. Our algorithm first computes an approximate basis of the range
space of $\mathbf{A}$ by randomly sketching its columns, followed by a
quantization of the vectors constituting this basis. It then computes
approximate projections of the columns of $\mathbf{A}$ onto this quantized
basis. We derive upper bounds on the approximation error of our algorithm, and
analyze the impact of target rank and quantization bit-budget. The tradeoff
between compression ratio and approximation accuracy allows for flexibility in
choosing these parameters based on specific application requirements. We
empirically demonstrate the efficacy of our algorithm in image compression,
nearest neighbor classification of image and text embeddings, and compressing
the layers of LlaMa-$7$b. Our results illustrate that we can achieve
compression ratios as aggressive as one bit per matrix coordinate, all while
surpassing or maintaining the performance of traditional compression
techniques.",,cs.LG,"['cs.LG', 'cs.IT', 'math.IT', 'stat.ML']",http://arxiv.org/abs/2310.11028v1
159,"Single-Shot, Spatio-Temporal Metrology of Relativistic Plasma Optics",http://arxiv.org/pdf/2310.11027v1,"[arxiv.Result.Author('Ankit Dulat'), arxiv.Result.Author('Amit D. Lad'), arxiv.Result.Author('C. Aparajit'), arxiv.Result.Author('Anandam Choudhary'), arxiv.Result.Author('Yash M. Ved'), arxiv.Result.Author('Laszlo Veisz'), arxiv.Result.Author('G. Ravindra Kumar')]",,2023-10-17 06:54:14+00:00,"Ultrahigh peak power femtosecond laser pulses create extreme states and are
currently being probed with great interest. Plasma optics have been proposed
for shaping and amplifying high-power pulses, but they are subject to huge
modulations and fluctuations due to the very nature of excitation at high
intensities. Multidimensional characterization (spatial, temporal, and
spectral) and control of relativistic plasma dynamics and their impact on the
spatio-temporal structure of intense femtosecond pulses are therefore essential
yet extremely difficult to achieve, particularly at the low repetition rates
typical at 100s terawatt to petawatt. Here, we present a single-shot,
two-dimensional (2D) spatio-temporal and spatio-spectral measurement of such
pulses based on spectral interferometry. We reconstruct the 3D temporal
structure of the laser pulse simultaneously resolving the complex plasma
dynamics. We demonstrate our method by measuring the sub-picosecond evolution
of a relativistically hot plasma deep within a solid. Our measurements reveal
that different spatial regions of the plasma surface move differently yet
exhibit a collective behavior globally. This all-optical measurement technique
can capture 2D spatio-temporal effects within pulses spanning the terawatt to
petawatt range, all in a single shot, enabling further progress in
high-intensity laser pulse technology.",,physics.plasm-ph,['physics.plasm-ph'],http://arxiv.org/abs/2310.11027v1
160,Exploring Automatic Evaluation Methods based on a Decoder-based LLM for Text Generation,http://arxiv.org/pdf/2310.11026v1,"[arxiv.Result.Author('Tomohito Kasahara'), arxiv.Result.Author('Daisuke Kawahara')]",,2023-10-17 06:53:00+00:00,"Automatic evaluation of text generation is essential for improving the
accuracy of generation tasks. In light of the current trend towards
increasingly larger decoder-based language models, we investigate automatic
evaluation methods based on such models for text generation. This paper
compares various methods, including tuning with encoder-based models and large
language models under equal conditions, on two different tasks, machine
translation evaluation and semantic textual similarity, in two languages,
Japanese and English. Experimental results show that compared to the tuned
encoder-based models, the tuned decoder-based models perform poorly. The
analysis of the causes for this suggests that the decoder-based models focus on
surface word sequences and do not capture meaning. It is also revealed that
in-context learning of very large decoder-based models such as ChatGPT makes it
difficult to identify fine-grained semantic differences.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11026v1
161,Dynamic quantum circuit compilation,http://arxiv.org/pdf/2310.11021v1,"[arxiv.Result.Author('Kun Fang'), arxiv.Result.Author('Munan Zhang'), arxiv.Result.Author('Ruqi Shi'), arxiv.Result.Author('Yinan Li')]",,2023-10-17 06:26:30+00:00,"Quantum computing has shown tremendous promise in addressing complex
computational problems, yet its practical realization is hindered by the
limited availability of qubits for computation. Recent advancements in quantum
hardware have introduced mid-circuit measurements and resets, enabling the
reuse of measured qubits and significantly reducing the qubit requirements for
executing quantum algorithms. In this work, we present a systematic study of
dynamic quantum circuit compilation, a process that transforms static quantum
circuits into their dynamic equivalents with a reduced qubit count through
qubit-reuse. We establish the first general framework for optimizing the
dynamic circuit compilation via graph manipulation. In particular, we
completely characterize the optimal quantum circuit compilation using binary
integer programming, provide efficient algorithms for determining whether a
given quantum circuit can be reduced to a smaller circuit and present heuristic
algorithms for devising dynamic compilation schemes in general. Furthermore, we
conduct a thorough analysis of quantum circuits with practical relevance,
offering optimal compilations for well-known quantum algorithms in quantum
computation, ansatz circuits utilized in quantum machine learning, and
measurement-based quantum computation crucial for quantum networking. We also
perform a comparative analysis against state-of-the-art approaches,
demonstrating the superior performance of our methods in both structured and
random quantum circuits. Our framework lays a rigorous foundation for
comprehending dynamic quantum circuit compilation via qubit-reuse, bridging the
gap between theoretical quantum algorithms and their physical implementation on
quantum computers with limited resources.",,quant-ph,"['quant-ph', 'cs.PL']",http://arxiv.org/abs/2310.11021v1
162,Numerical simulation of time fractional Kudryashov Sinelshchikov equation describing the pressure waves in a mixture of liquid and gas bubbles,http://arxiv.org/pdf/2310.11019v1,"[arxiv.Result.Author('Gayatri Das'), arxiv.Result.Author('S. Saha Ray')]",,2023-10-17 06:18:21+00:00,"This article is concerned with an approximate analytical solution for the
time fractional Kudryashov Sinelshchikov equation by using the reproducing
kernel Hilbert space method. The main tools of this method are reproducing
kernel theory, some important Hilbert spaces, the normal basis,
orthogonalisation process, and homogenization. The effectiveness of reproduc
ing kernel Hilbert space method is presented through the tables and graphs.
These computa tional results indicate that this method is highly accurate and
efficient for the time fractional Kudryashov Sinelshchikov equation. Also, it
is demonstrated that the approximate solution uniformly converges to exact
solution by using reproducing kernel Hilbert space method.",,math.NA,"['math.NA', 'cs.NA', 'math.AP']",http://arxiv.org/abs/2310.11019v1
163,Reading Order Matters: Information Extraction from Visually-rich Documents by Token Path Prediction,http://arxiv.org/pdf/2310.11016v1,"[arxiv.Result.Author('Chong Zhang'), arxiv.Result.Author('Ya Guo'), arxiv.Result.Author('Yi Tu'), arxiv.Result.Author('Huan Chen'), arxiv.Result.Author('Jinyang Tang'), arxiv.Result.Author('Huijia Zhu'), arxiv.Result.Author('Qi Zhang'), arxiv.Result.Author('Tao Gui')]",,2023-10-17 06:08:55+00:00,"Recent advances in multimodal pre-trained models have significantly improved
information extraction from visually-rich documents (VrDs), in which named
entity recognition (NER) is treated as a sequence-labeling task of predicting
the BIO entity tags for tokens, following the typical setting of NLP. However,
BIO-tagging scheme relies on the correct order of model inputs, which is not
guaranteed in real-world NER on scanned VrDs where text are recognized and
arranged by OCR systems. Such reading order issue hinders the accurate marking
of entities by BIO-tagging scheme, making it impossible for sequence-labeling
methods to predict correct named entities. To address the reading order issue,
we introduce Token Path Prediction (TPP), a simple prediction head to predict
entity mentions as token sequences within documents. Alternative to token
classification, TPP models the document layout as a complete directed graph of
tokens, and predicts token paths within the graph as entities. For better
evaluation of VrD-NER systems, we also propose two revised benchmark datasets
of NER on scanned documents which can reflect real-world scenarios. Experiment
results demonstrate the effectiveness of our method, and suggest its potential
to be a universal solution to various information extraction tasks on
documents.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.11016v1
164,From Identifiable Causal Representations to Controllable Counterfactual Generation: A Survey on Causal Generative Modeling,http://arxiv.org/pdf/2310.11011v1,"[arxiv.Result.Author('Aneesh Komanduri'), arxiv.Result.Author('Xintao Wu'), arxiv.Result.Author('Yongkai Wu'), arxiv.Result.Author('Feng Chen')]",,2023-10-17 05:45:32+00:00,"Deep generative models have shown tremendous success in data density
estimation and data generation from finite samples. While these models have
shown impressive performance by learning correlations among features in the
data, some fundamental shortcomings are their lack of explainability, the
tendency to induce spurious correlations, and poor out-of-distribution
extrapolation. In an effort to remedy such challenges, one can incorporate the
theory of causality in deep generative modeling. Structural causal models
(SCMs) describe data-generating processes and model complex causal
relationships and mechanisms among variables in a system. Thus, SCMs can
naturally be combined with deep generative models. Causal models offer several
beneficial properties to deep generative models, such as distribution shift
robustness, fairness, and interoperability. We provide a technical survey on
causal generative modeling categorized into causal representation learning and
controllable counterfactual generation methods. We focus on fundamental theory,
formulations, drawbacks, datasets, metrics, and applications of causal
generative models in fairness, privacy, out-of-distribution generalization, and
precision medicine. We also discuss open problems and fruitful research
directions for future work in the field.",,cs.LG,"['cs.LG', 'cs.AI', 'stat.ML']",http://arxiv.org/abs/2310.11011v1
165,Iterative Shallow Fusion of Backward Language Model for End-to-End Speech Recognition,http://arxiv.org/pdf/2310.11010v1,"[arxiv.Result.Author('Atsunori Ogawa'), arxiv.Result.Author('Takafumi Moriya'), arxiv.Result.Author('Naoyuki Kamo'), arxiv.Result.Author('Naohiro Tawara'), arxiv.Result.Author('Marc Delcroix')]",,2023-10-17 05:44:10+00:00,"We propose a new shallow fusion (SF) method to exploit an external backward
language model (BLM) for end-to-end automatic speech recognition (ASR). The BLM
has complementary characteristics with a forward language model (FLM), and the
effectiveness of their combination has been confirmed by rescoring ASR
hypotheses as post-processing. In the proposed SF, we iteratively apply the BLM
to partial ASR hypotheses in the backward direction (i.e., from the possible
next token to the start symbol) during decoding, substituting the newly
calculated BLM scores for the scores calculated at the last iteration. To
enhance the effectiveness of this iterative SF (ISF), we train a partial
sentence-aware BLM (PBLM) using reversed text data including partial sentences,
considering the framework of ISF. In experiments using an attention-based
encoder-decoder ASR system, we confirmed that ISF using the PBLM shows
comparable performance with SF using the FLM. By performing ISF, early pruning
of prospective hypotheses can be prevented during decoding, and we can obtain a
performance improvement compared to applying the PBLM as post-processing.
Finally, we confirmed that, by combining SF and ISF, further performance
improvement can be obtained thanks to the complementarity of the FLM and PBLM.",,eess.AS,['eess.AS'],http://arxiv.org/abs/2310.11010v1
166,Advanced accent/dialect identification and accentedness assessment with multi-embedding models and automatic speech recognition,http://arxiv.org/pdf/2310.11004v1,"[arxiv.Result.Author('Shahram Ghorbani'), arxiv.Result.Author('John H. L. Hansen')]",,2023-10-17 05:13:46+00:00,"Accurately classifying accents and assessing accentedness in non-native
speakers are both challenging tasks due to the complexity and diversity of
accent and dialect variations. In this study, embeddings from advanced
pre-trained language identification (LID) and speaker identification (SID)
models are leveraged to improve the accuracy of accent classification and
non-native accentedness assessment. Findings demonstrate that employing
pre-trained LID and SID models effectively encodes accent/dialect information
in speech. Furthermore, the LID and SID encoded accent information complement
an end-to-end accent identification (AID) model trained from scratch. By
incorporating all three embeddings, the proposed multi-embedding AID system
achieves superior accuracy in accent identification. Next, we investigate
leveraging automatic speech recognition (ASR) and accent identification models
to explore accentedness estimation. The ASR model is an end-to-end
connectionist temporal classification (CTC) model trained exclusively with
en-US utterances. The ASR error rate and en-US output of the AID model are
leveraged as objective accentedness scores. Evaluation results demonstrate a
strong correlation between the scores estimated by the two models.
Additionally, a robust correlation between the objective accentedness scores
and subjective scores based on human perception is demonstrated, providing
evidence for the reliability and validity of utilizing AID-based and ASR-based
systems for accentedness assessment in non-native speech.",,eess.AS,"['eess.AS', 'eess.SP']",http://arxiv.org/abs/2310.11004v1
167,Correction Focused Language Model Training for Speech Recognition,http://arxiv.org/pdf/2310.11003v1,"[arxiv.Result.Author('Yingyi Ma'), arxiv.Result.Author('Zhe Liu'), arxiv.Result.Author('Ozlem Kalinli')]",,2023-10-17 05:10:39+00:00,"Language models (LMs) have been commonly adopted to boost the performance of
automatic speech recognition (ASR) particularly in domain adaptation tasks.
Conventional way of LM training treats all the words in corpora equally,
resulting in suboptimal improvements in ASR performance. In this work, we
introduce a novel correction focused LM training approach which aims to
prioritize ASR fallible words. The word-level ASR fallibility score,
representing the likelihood of ASR mis-recognition, is defined and shaped as a
prior word distribution to guide the LM training. To enable correction focused
training with text-only corpora, large language models (LLMs) are employed as
fallibility score predictors and text generators through multi-task
fine-tuning. Experimental results for domain adaptation tasks demonstrate the
effectiveness of our proposed method. Compared with conventional LMs,
correction focused training achieves up to relatively 5.5% word error rate
(WER) reduction in sufficient text scenarios. In insufficient text scenarios,
LM training with LLM-generated text achieves up to relatively 13% WER
reduction, while correction focused training further obtains up to relatively
6% WER reduction.",,cs.CL,"['cs.CL', 'cs.LG', 'cs.SD', 'eess.AS']",http://arxiv.org/abs/2310.11003v1
168,RelativisticDynamics.jl: Relativistic Spin-Orbital Dynamics in Julia,http://arxiv.org/pdf/2310.11002v1,[arxiv.Result.Author('Tom Kimpson')],10.21105/joss.04992,2023-10-17 05:06:07+00:00,"RelativisticDynamics.jl is an open-source Julia package for relativistic
spin-orbital dynamics in the gravitational strong-field of a Kerr spacetime.
Existing codes for modelling the dynamics of spinning objects like pulsars in
the strong-field regime are generally lacking, since such systems occupy an
intermediate regime that is generally overlooked. At the ""low"" end of this
regime there are post-Newtonian descriptions which neglect the influence of the
pulsar spin on the underlying spacetime metric (""spin-curvature"" coupling). At
the ""high"" end there are the full numerical relativity solutions which are
primarily applicable toe two black holes with a mass ratio $\mathcal{O}(1)$,
and are computationally intractable for pulsar systems observed over a large
number of orbital cycles. RelativisticDynamics.jl aims to bridge this gap by
providing a modern, fast code for accurate numerical evolution of spinning
relativistic systems via the Mathisson-Papetrou-Dixon formalism. Julia is a
modern language that solves the ""two language problem"", enabling fast dynamic
typing and JIT compilation on conjunction with petaflop performance, comparable
with numerical languages that are better known in the astrophysics community
such as C or Fortran. RelativisticDynamics.jl is written to be fully type
flexible, being able to support arbitrary number formats, and fully
differentiable via automatic differentiation.",,astro-ph.HE,"['astro-ph.HE', 'astro-ph.IM', 'gr-qc']",http://arxiv.org/abs/2310.11002v1
169,A High Fidelity and Low Complexity Neural Audio Coding,http://arxiv.org/pdf/2310.10992v1,"[arxiv.Result.Author('Wenzhe Liu'), arxiv.Result.Author('Wei Xiao'), arxiv.Result.Author('Meng Wang'), arxiv.Result.Author('Shan Yang'), arxiv.Result.Author('Yupeng Shi'), arxiv.Result.Author('Yuyong Kang'), arxiv.Result.Author('Dan Su'), arxiv.Result.Author('Shidong Shang'), arxiv.Result.Author('Dong Yu')]",,2023-10-17 04:30:37+00:00,"Audio coding is an essential module in the real-time communication system.
Neural audio codecs can compress audio samples with a low bitrate due to the
strong modeling and generative capabilities of deep neural networks. To address
the poor high-frequency expression and high computational cost and storage
consumption, we proposed an integrated framework that utilizes a neural network
to model wide-band components and adopts traditional signal processing to
compress high-band components according to psychological hearing knowledge.
Inspired by auditory perception theory, a perception-based loss function is
designed to improve harmonic modeling. Besides, generative adversarial network
(GAN) compression is proposed for the first time for neural audio codecs. Our
method is superior to prior advanced neural codecs across subjective and
objective metrics and allows real-time inference on desktop and mobile.",,cs.SD,"['cs.SD', 'eess.AS']",http://arxiv.org/abs/2310.10992v1
170,HCI in e-Government and e-Democracy,http://arxiv.org/pdf/2310.10988v1,"[arxiv.Result.Author('Tianmu Zhu'), arxiv.Result.Author('Wei Xu')]",,2023-10-17 04:22:26+00:00,"This chapter introduces the application of HCI design processes and design
principles in e-government and e-democracy. We elaborate on HCI design
processes and six HCI design principles in the context of e-government and
e-democracy, including citizen-centered design, usability, accessibility,
access to information, transaction efficiency, and security and privacy. Then,
we present two cases to demonstrate the value of applying the HCI processes and
design principles in developing and deploying e-government and e-democracy.
Finally, we highlight the challenges faced by e-government and e-democracy as
well as the future trends. In conclusion, HCI can help the success of
e-government and e-democracy and their future growth.",,cs.HC,['cs.HC'],http://arxiv.org/abs/2310.10988v1
171,Computational synthesis of locomoting soft robots by topology optimization,http://arxiv.org/pdf/2310.10985v1,"[arxiv.Result.Author('Hiroki Kobayashi'), arxiv.Result.Author('Farzad Gholami'), arxiv.Result.Author('S. Macrae Montgomery'), arxiv.Result.Author('Masato Tanaka'), arxiv.Result.Author('Liang Yue'), arxiv.Result.Author('Changyoung Yuhn'), arxiv.Result.Author('Yuki Sato'), arxiv.Result.Author('Atsushi Kawamoto'), arxiv.Result.Author('H. Jerry Qi'), arxiv.Result.Author('Tsuyoshi Nomura')]",,2023-10-17 04:17:24+00:00,"Biological organisms have acquired sophisticated body shapes for walking or
climbing through million-year evolutionary processes. In contrast, the
components of locomoting soft robots, such as legs and arms, are designed in
trial-and-error loops guided by a priori knowledge and experience, which leaves
considerable room for improvement. Here, we present optimized soft robots that
performed a specific locomotion task without any a priori assumptions or
knowledge of the layout and shapes of the limbs by fully exploiting the
computational capabilities for topology optimization. The only requirements
introduced were a design domain and a periodically acting pneumatic actuator.
The freeform shape of a soft body was derived from iterative updates in a
gradient-based topology optimization that incorporated complex physical
phenomena, such as large deformations, contacts, material viscosity, and
fluid-structure interactions, in transient problems. The locomotion tasks
included a horizontal movement on flat ground (walking) and a vertical movement
between two walls (climbing). Without any human intervention, optimized soft
robots have limbs and exhibit locomotion similar to those of biological
organisms. Linkage-like structures were formed for the climbing task to assign
different movements to multiple legs with limited degrees of freedom in the
actuator. We fabricated the optimized design using 3D printing and confirmed
the performance of these robots. This study presents a new and efficient
strategy for designing soft robots and other bioinspired systems, suggesting
that a purely mathematical process can produce shapes reminiscent of nature's
long-term evolution.",,cs.CE,['cs.CE'],http://arxiv.org/abs/2310.10985v1
172,Instructive Dialogue Summarization with Query Aggregations,http://arxiv.org/pdf/2310.10981v1,"[arxiv.Result.Author('Bin Wang'), arxiv.Result.Author('Zhengyuan Liu'), arxiv.Result.Author('Nancy F. Chen')]",,2023-10-17 04:03:00+00:00,"Conventional dialogue summarization methods directly generate summaries and
do not consider user's specific interests. This poses challenges in cases where
the users are more focused on particular topics or aspects. With the
advancement of instruction-finetuned language models, we introduce
instruction-tuning to dialogues to expand the capability set of dialogue
summarization models. To overcome the scarcity of instructive dialogue
summarization data, we propose a three-step approach to synthesize high-quality
query-based summarization triples. This process involves summary-anchored query
generation, query filtering, and query-based summary generation. By training a
unified model called InstructDS (Instructive Dialogue Summarization) on three
summarization datasets with multi-purpose instructive triples, we expand the
capability of dialogue summarization models. We evaluate our method on four
datasets, including dialogue summarization and dialogue reading comprehension.
Experimental results show that our approach outperforms the state-of-the-art
models and even models with larger sizes. Additionally, our model exhibits
higher generalizability and faithfulness, as confirmed by human subjective
evaluations.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.10981v1
173,"Analysis of potential flow networks: Variations in transport time with $discrete$, $continuous$, and $selfish$ operation",http://arxiv.org/pdf/2310.10980v1,"[arxiv.Result.Author('Varghese Kurian'), arxiv.Result.Author('Sridharakumar Narasimhan')]",,2023-10-17 03:55:35+00:00,"In potential flow networks, the equilibrium flow rates are usually not
proportional to the demands and flow control elements are required to regulate
the flow. The control elements can broadly be classified into two types -
discrete and continuous. Discrete control elements can have only two
operational states: fully open or fully closed. On the other hand, continuous
control elements may be operated in any intermediate position in addition to
the fully open and fully closed states. Naturally, with their increased
flexibility, continuous control elements can provide better network
performance, but $to~what~extent$?
  We consider a class of branched networks with a single source and multiple
sinks. The potential drop across edges ($\Delta H$) is assumed to be
proportional to the $n^{th}$ power of flow rate ($Q$), i.e., $\Delta H=kQ^n$ ,
($n>=1$). We define $\textbf{R}$ as the ratio of minimal operational times
required to transport a given quantum of material with either type of control
element and show that $1\leq \textbf{R}\leq m^{\left(1-1/n\right)}$, where $m$
is the maximum depth of the network. The results point to the role of network
topology in the variations in operational time. Further analysis reveals that
the selfish operation of a network with continuous control valves has the same
bounds on the price of anarchy.",,eess.SY,"['eess.SY', 'cs.SY', '76B75, 90B10, 91A43']",http://arxiv.org/abs/2310.10980v1
174,NICE: Improving Panoptic Narrative Detection and Segmentation with Cascading Collaborative Learning,http://arxiv.org/pdf/2310.10975v1,"[arxiv.Result.Author('Haowei Wang'), arxiv.Result.Author('Jiayi Ji'), arxiv.Result.Author('Tianyu Guo'), arxiv.Result.Author('Yilong Yang'), arxiv.Result.Author('Yiyi Zhou'), arxiv.Result.Author('Xiaoshuai Sun'), arxiv.Result.Author('Rongrong Ji')]",,2023-10-17 03:42:12+00:00,"Panoptic Narrative Detection (PND) and Segmentation (PNS) are two challenging
tasks that involve identifying and locating multiple targets in an image
according to a long narrative description. In this paper, we propose a unified
and effective framework called NICE that can jointly learn these two panoptic
narrative recognition tasks. Existing visual grounding tasks use a two-branch
paradigm, but applying this directly to PND and PNS can result in prediction
conflict due to their intrinsic many-to-many alignment property. To address
this, we introduce two cascading modules based on the barycenter of the mask,
which are Coordinate Guided Aggregation (CGA) and Barycenter Driven
Localization (BDL), responsible for segmentation and detection, respectively.
By linking PNS and PND in series with the barycenter of segmentation as the
anchor, our approach naturally aligns the two tasks and allows them to
complement each other for improved performance. Specifically, CGA provides the
barycenter as a reference for detection, reducing BDL's reliance on a large
number of candidate boxes. BDL leverages its excellent properties to
distinguish different instances, which improves the performance of CGA for
segmentation. Extensive experiments demonstrate that NICE surpasses all
existing methods by a large margin, achieving 4.1% for PND and 2.9% for PNS
over the state-of-the-art. These results validate the effectiveness of our
proposed collaborative learning strategy. The project of this work is made
publicly available at https://github.com/Mr-Neko/NICE.",,cs.CV,['cs.CV'],http://arxiv.org/abs/2310.10975v1
175,A Non-Hermitian Moiré Valley Filter,http://arxiv.org/pdf/2310.10973v1,"[arxiv.Result.Author('Kai Shao'), arxiv.Result.Author('Hao Geng'), arxiv.Result.Author('Erfu Liu'), arxiv.Result.Author('Jose L. Lado'), arxiv.Result.Author('Wei Chen'), arxiv.Result.Author('D. Y. Xing')]",,2023-10-17 03:37:46+00:00,"A valley filter capable of generating a valley-polarized current is a crucial
element in valleytronics, yet its implementation remains challenging. Here, we
propose a valley filter made of a graphene bilayer which exhibits a 1D
moir\'{e} pattern in the overlapping region of the two layers controlled by
heterostrain. In the presence of a lattice modulation between layers, electrons
propagating in one layer can have valley-dependent dissipation due to valley
asymmetric interlayer coupling, thus giving rise to a valley-polarized current.
Such a process can be described by an effective non-Hermitian theory, in which
the valley filter is driven by a valley-resolved non-Hermitian skin effect.
Nearly 100\% valley-polarization can be achieved within a wide parameter range
and the functionality of the valley filter is electrically tunable. The
non-Hermitian topological scenario of the valley filter ensures high tolerance
against imperfections such as disorder and edge defects. Our work opens a new
route for efficient and robust valley filters while significantly relaxing the
stringent implementation requirements.",,cond-mat.mes-hall,['cond-mat.mes-hall'],http://arxiv.org/abs/2310.10973v1
176,Context-Aware Meta-Learning,http://arxiv.org/pdf/2310.10971v1,"[arxiv.Result.Author('Christopher Fifty'), arxiv.Result.Author('Dennis Duan'), arxiv.Result.Author('Ronald G. Junkins'), arxiv.Result.Author('Ehsan Amid'), arxiv.Result.Author('Jure Leskovec'), arxiv.Result.Author('Christopher Ré'), arxiv.Result.Author('Sebastian Thrun')]",,2023-10-17 03:35:27+00:00,"Large Language Models like ChatGPT demonstrate a remarkable capacity to learn
new concepts during inference without any fine-tuning. However, visual models
trained to detect new objects during inference have been unable to replicate
this ability, and instead either perform poorly or require meta-training and/or
fine-tuning on similar objects. In this work, we propose a meta-learning
algorithm that emulates Large Language Models by learning new visual concepts
during inference without fine-tuning. Our approach leverages a frozen
pre-trained feature extractor, and analogous to in-context learning, recasts
meta-learning as sequence modeling over datapoints with known labels and a test
datapoint with an unknown label. On 8 out of 11 meta-learning benchmarks, our
approach -- without meta-training or fine-tuning -- exceeds or matches the
state-of-the-art algorithm, P>M>F, which is meta-trained on these benchmarks.",,cs.LG,"['cs.LG', 'cs.CV']",http://arxiv.org/abs/2310.10971v1
177,SD-PINN: Deep Learning based Spatially Dependent PDEs Recovery,http://arxiv.org/pdf/2310.10970v1,"[arxiv.Result.Author('Ruixian Liu'), arxiv.Result.Author('Peter Gerstoft')]",,2023-10-17 03:31:47+00:00,"The physics-informed neural network (PINN) is capable of recovering partial
differential equation (PDE) coefficients that remain constant throughout the
spatial domain directly from physical measurements. In this work, we propose a
spatially dependent physics-informed neural network (SD-PINN), which enables
the recovery of coefficients in spatially-dependent PDEs using a single neural
network, eliminating the requirement for domain-specific physical expertise.
The proposed method exhibits robustness to noise owing to the incorporation of
physical constraints. It can also incorporate the low-rank assumption of the
spatial variation for the PDE coefficients to recover the coefficients at
locations without available measurements.",,cs.LG,"['cs.LG', 'eess.SP']",http://arxiv.org/abs/2310.10970v1
178,On the spectrum of the Hodge Laplacian on sequences,http://arxiv.org/pdf/2310.10969v1,"[arxiv.Result.Author('Hannah Santa Cruz Baur'), arxiv.Result.Author('Vladimir Itskov')]",,2023-10-17 03:30:51+00:00,"Hodge Laplacians have been previously proposed as a natural tool for
understanding higher-order interactions in networks and directed graphs. Here
we introduce a Hodge-theoretic approach to spectral theory and dimensionality
reduction for probability distributions on sequences and simplicial complexes.
We demonstrate that this Hodge theory has desirable properties with respect to
natural null-models, where the underlying vertices are independent.
  We prove that for the case of independent vertices in simplicial complexes,
the appropriate Laplacians are multiples of the identity and thus have no
meaningful Fourier modes. For the null model of independent vertices in
sequences, we prove that the appropriate Hodge Laplacian has an integer
spectrum, and describe its eigenspaces. We also prove that the underlying cell
complex of sequences has trivial reduced homology. Our results establish a
foundation for developing Fourier analyses of probabilistic models, which are
common in theoretical neuroscience and machine-learning.",,math.AT,"['math.AT', 'math.ST', 'stat.TH']",http://arxiv.org/abs/2310.10969v1
179,EXMODD: An EXplanatory Multimodal Open-Domain Dialogue dataset,http://arxiv.org/pdf/2310.10967v1,"[arxiv.Result.Author('Hang Yin'), arxiv.Result.Author('Pinren Lu'), arxiv.Result.Author('Ziang Li'), arxiv.Result.Author('Bin Sun'), arxiv.Result.Author('Kan Li')]",,2023-10-17 03:28:29+00:00,"The need for high-quality data has been a key issue hindering the research of
dialogue tasks. Recent studies try to build datasets through manual, web
crawling, and large pre-trained models. However, man-made data is expensive and
data collected from the internet often includes generic responses, meaningless
statements, and toxic dialogues. Automatic data generation through large models
is a cost-effective method, but for open-domain multimodal dialogue tasks,
there are still three drawbacks: 1) There is currently no open-source large
model that can accept multimodal input; 2) The content generated by the model
lacks interpretability; 3) The generated data is usually difficult to quality
control and require extensive resource to collect. To alleviate the significant
human and resource expenditure in data collection, we propose a Multimodal Data
Construction Framework (MDCF). MDCF designs proper prompts to spur the
large-scale pre-trained language model to generate well-formed and satisfactory
content. Additionally, MDCF also automatically provides explanation for a given
image and its corresponding dialogue, which can provide a certain degree of
interpretability and facilitate manual follow-up quality inspection. Based on
this, we release an Explanatory Multimodal Open-Domain dialogue dataset
(EXMODD). Experiments indicate a positive correlation between the model's
ability to generate accurate understandings and high-quality responses. Our
code and data can be found at https://github.com/poplpr/EXMODD.",,cs.CL,"['cs.CL', 'cs.AI', 'cs.HC']",http://arxiv.org/abs/2310.10967v1
180,Spectral-Efficiency and Energy-Efficiency of Variable-Length XP-HARQ,http://arxiv.org/pdf/2310.10964v1,"[arxiv.Result.Author('Jiahui Feng'), arxiv.Result.Author('Zheng Shi'), arxiv.Result.Author('Yaru Fu'), arxiv.Result.Author('Hong Wang'), arxiv.Result.Author('Guanghua Yang'), arxiv.Result.Author('Shaodan Ma')]",,2023-10-17 03:25:33+00:00,"A variable-length cross-packet hybrid automatic repeat request (VL-XP-HARQ)
is proposed to boost the spectral efficiency (SE) and the energy efficiency
(EE) of communications. The SE is firstly derived in terms of the outage
probabilities, with which the SE is proved to be upper bounded by the ergodic
capacity (EC). Moreover, to facilitate the maximization of the SE, the
asymptotic outage probability is obtained at high signal-to-noise ratio (SNR),
with which the SE is maximized by properly choosing the number of new
information bits while guaranteeing outage requirement. By applying
Dinkelbach's transform, the fractional objective function is transformed into a
subtraction form, which can be decomposed into multiple sub-problems through
alternating optimization. By noticing that the asymptotic outage probability is
a convex function, each sub-problem can be easily relaxed to a convex problem
by adopting successive convex approximation (SCA). Besides, the EE of
VL-XP-HARQ is also investigated. An upper bound of the EE is found and proved
to be attainable. Furthermore, by aiming at maximizing the EE via power
allocation while confining outage within a certain constraint, the methods to
the maximization of SE are invoked to solve the similar fractional problem.
Finally, numerical results are presented for verification.",,cs.IT,"['cs.IT', 'eess.SP', 'math.IT']",http://arxiv.org/abs/2310.10964v1
181,MRI brain tumor segmentation using informative feature vectors and kernel dictionary learning,http://arxiv.org/pdf/2310.10963v1,"[arxiv.Result.Author('Seyedeh Mahya Mousavi'), arxiv.Result.Author('Mohammad Mostafavi')]",,2023-10-17 03:25:22+00:00,"This paper presents a method based on a kernel dictionary learning algorithm
for segmenting brain tumor regions in magnetic resonance images (MRI). A set of
first-order and second-order statistical feature vectors are extracted from
patches of size 3 * 3 around pixels in the brain MRI scans. These feature
vectors are utilized to train two kernel dictionaries separately for healthy
and tumorous tissues. To enhance the efficiency of the dictionaries and reduce
training time, a correlation-based sample selection technique is developed to
identify the most informative and discriminative subset of feature vectors.
This technique aims to improve the performance of the dictionaries by selecting
a subset of feature vectors that provide valuable information for the
segmentation task. Subsequently, a linear classifier is utilized to distinguish
between healthy and unhealthy pixels based on the learned dictionaries. The
results demonstrate that the proposed method outperforms other existing methods
in terms of segmentation accuracy and significantly reduces both the time and
memory required, resulting in a remarkably fast training process.",,cs.CV,"['cs.CV', 'stat.ML']",http://arxiv.org/abs/2310.10963v1
182,Semantic-Aware Contrastive Sentence Representation Learning with Large Language Models,http://arxiv.org/pdf/2310.10962v1,"[arxiv.Result.Author('Huiming Wang'), arxiv.Result.Author('Liying Cheng'), arxiv.Result.Author('Zhaodonghui Li'), arxiv.Result.Author('De Wen Soh'), arxiv.Result.Author('Lidong Bing')]",,2023-10-17 03:21:43+00:00,"Contrastive learning has been proven to be effective in learning better
sentence representations. However, to train a contrastive learning model, large
numbers of labeled sentences are required to construct positive and negative
pairs explicitly, such as those in natural language inference (NLI) datasets.
Unfortunately, acquiring sufficient high-quality labeled data can be both
time-consuming and resource-intensive, leading researchers to focus on
developing methods for learning unsupervised sentence representations. As there
is no clear relationship between these unstructured randomly-sampled sentences,
building positive and negative pairs over them is tricky and problematic. To
tackle these challenges, in this paper, we propose SemCSR, a semantic-aware
contrastive sentence representation framework. By leveraging the generation and
evaluation capabilities of large language models (LLMs), we can automatically
construct a high-quality NLI-style corpus without any human annotation, and
further incorporate the generated sentence pairs into learning a contrastive
sentence representation model. Extensive experiments and comprehensive analyses
demonstrate the effectiveness of our proposed framework for learning a better
sentence representation with LLMs.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.10962v1
183,Enhancing Deep Neural Network Training Efficiency and Performance through Linear Prediction,http://arxiv.org/pdf/2310.10958v1,"[arxiv.Result.Author('Hejie Ying'), arxiv.Result.Author('Mengmeng Song'), arxiv.Result.Author('Yaohong Tang'), arxiv.Result.Author('Shungen Xiao'), arxiv.Result.Author('Zimin Xiao')]",,2023-10-17 03:11:30+00:00,"Deep neural networks (DNN) have achieved remarkable success in various
fields, including computer vision and natural language processing. However,
training an effective DNN model still poses challenges. This paper aims to
propose a method to optimize the training effectiveness of DNN, with the goal
of improving model performance. Firstly, based on the observation that the DNN
parameters change in certain laws during training process, the potential of
parameter prediction for improving model training efficiency and performance is
discovered. Secondly, considering the magnitude of DNN model parameters,
hardware limitations and characteristics of Stochastic Gradient Descent (SGD)
for noise tolerance, a Parameter Linear Prediction (PLP) method is exploit to
perform DNN parameter prediction. Finally, validations are carried out on some
representative backbones. Experiment results show that compare to the normal
training ways, under the same training conditions and epochs, by employing
proposed PLP method, the optimal model is able to obtain average about 1%
accuracy improvement and 0.01 top-1/top-5 error reduction for Vgg16, Resnet18
and GoogLeNet based on CIFAR-100 dataset, which shown the effectiveness of the
proposed method on different DNN structures, and validated its capacity in
enhancing DNN training efficiency and performance.",,cs.LG,"['cs.LG', 'cs.CV']",http://arxiv.org/abs/2310.10958v1
184,Medical Image Segmentation via Sparse Coding Decoder,http://arxiv.org/pdf/2310.10957v1,"[arxiv.Result.Author('Long Zeng'), arxiv.Result.Author('Kaigui Wu')]",,2023-10-17 03:08:35+00:00,"Transformers have achieved significant success in medical image segmentation,
owing to its capability to capture long-range dependencies. Previous works
incorporate convolutional layers into the encoder module of transformers,
thereby enhancing their ability to learn local relationships among pixels.
However, transformers may suffer from limited generalization capabilities and
reduced robustness, attributed to the insufficient spatial recovery ability of
their decoders. To address this issue, A convolution sparse vector coding based
decoder is proposed , namely CAScaded multi-layer Convolutional Sparse vector
Coding DEcoder (CASCSCDE), which represents features extracted by the encoder
using sparse vectors. To prove the effectiveness of our CASCSCDE, The
widely-used TransUNet model is chosen for the demonstration purpose, and the
CASCSCDE is incorporated with TransUNet to establish the TransCASCSCDE
architecture. Our experiments demonstrate that TransUNet with CASCSCDE
significantly enhances performance on the Synapse benchmark, obtaining up to
3.15\% and 1.16\% improvements in DICE and mIoU scores, respectively. CASCSCDE
opens new ways for constructing decoders based on convolutional sparse vector
coding.",,eess.IV,"['eess.IV', 'cs.CV', '68T07, 68U10', 'I.4.6; I.4.7; I.5.1']",http://arxiv.org/abs/2310.10957v1
185,Computing the optimal keyboard through a geometric analysis of the English language,http://arxiv.org/pdf/2310.10956v1,"[arxiv.Result.Author('Jules Deschamps'), arxiv.Result.Author('Quentin Hubert'), arxiv.Result.Author('Lucas Ryckelynck')]",,2023-10-17 03:05:42+00:00,"In the context of a group project for the course COMSW4995 002 - Geometric
Data Analysis, we bring our attention to the design of fast-typing keyboards.
Leveraging some geometric tools in an optimization framework allowed us to
propose novel keyboard layouts that offer a faster typing.",,cs.CL,"['cs.CL', 'cs.HC']",http://arxiv.org/abs/2310.10956v1
186,A State-Vector Framework for Dataset Effects,http://arxiv.org/pdf/2310.10955v1,"[arxiv.Result.Author('Esmat Sahak'), arxiv.Result.Author('Zining Zhu'), arxiv.Result.Author('Frank Rudzicz')]",,2023-10-17 03:05:06+00:00,"The impressive success of recent deep neural network (DNN)-based systems is
significantly influenced by the high-quality datasets used in training.
However, the effects of the datasets, especially how they interact with each
other, remain underexplored. We propose a state-vector framework to enable
rigorous studies in this direction. This framework uses idealized probing test
results as the bases of a vector space. This framework allows us to quantify
the effects of both standalone and interacting datasets. We show that the
significant effects of some commonly-used language understanding datasets are
characteristic and are concentrated on a few linguistic dimensions.
Additionally, we observe some ``spill-over'' effects: the datasets could impact
the models along dimensions that may seem unrelated to the intended tasks. Our
state-vector framework paves the way for a systematic understanding of the
dataset effects, a crucial component in responsible and robust model
development.",,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']",http://arxiv.org/abs/2310.10955v1
187,FusionU-Net: U-Net with Enhanced Skip Connection for Pathology Image Segmentation,http://arxiv.org/pdf/2310.10951v1,"[arxiv.Result.Author('Zongyi Li'), arxiv.Result.Author('Hongbing Lyu'), arxiv.Result.Author('Jun Wang')]",,2023-10-17 02:56:10+00:00,"In recent years, U-Net and its variants have been widely used in pathology
image segmentation tasks. One of the key designs of U-Net is the use of skip
connections between the encoder and decoder, which helps to recover detailed
information after upsampling. While most variations of U-Net adopt the original
skip connection design, there is semantic gap between the encoder and decoder
that can negatively impact model performance. Therefore, it is important to
reduce this semantic gap before conducting skip connection. To address this
issue, we propose a new segmentation network called FusionU-Net, which is based
on U-Net structure and incorporates a fusion module to exchange information
between different skip connections to reduce semantic gaps. Unlike the other
fusion modules in existing networks, ours is based on a two-round fusion design
that fully considers the local relevance between adjacent encoder layer outputs
and the need for bi-directional information exchange across multiple layers. We
conducted extensive experiments on multiple pathology image datasets to
evaluate our model and found that FusionU-Net achieves better performance
compared to other competing methods. We argue our fusion module is more
effective than the designs of existing networks, and it could be easily
embedded into other networks to further enhance the model performance.",,eess.IV,"['eess.IV', 'cs.CV']",http://arxiv.org/abs/2310.10951v1
188,Defects Vibrations Engineering for Enhancing Interfacial Thermal Transport,http://arxiv.org/pdf/2310.10945v1,"[arxiv.Result.Author('Yijie Zhou'), arxiv.Result.Author('Robert Ciarla'), arxiv.Result.Author('Artittaya Boonkird'), arxiv.Result.Author('Thanh Nguyen'), arxiv.Result.Author('Jiawei Zhou'), arxiv.Result.Author('Zhang Jiang'), arxiv.Result.Author('Xiaobing Zuo'), arxiv.Result.Author('Jeewan Ranasinghe'), arxiv.Result.Author('Weiguo Hu'), arxiv.Result.Author('Brendan Scott'), arxiv.Result.Author('Shengxi Huang'), arxiv.Result.Author('Mingda Li'), arxiv.Result.Author('Yanfei Xu')]",,2023-10-17 02:42:42+00:00,"To push upper boundaries of effective thermal conductivity in polymer
composites, a fundamental understanding of thermal transport mechanisms is
crucial. Although there is intensive simulation research, systematic
experimental investigation on thermal transport in polymer composites is
limited. To better understand thermal transport processes, we design polymer
composites with perfect fillers (graphite) and defective fillers (graphite
oxide); we choose polar polyvinyl alcohol (PVA) as a matrix model; and we
identify how thermal transport occurs across heterogeneous interfaces. Measured
thermal conductivities of in PVA/defective filler composites is higher than
those of PVA/perfect filler composites, while measured thermal conductivities
in defective fillers are lower than those of perfect fillers. An effective
quantum mechanical model is developed, showing that the vibrational state of
the defective level plays a critical role in enhancing the thermal conductivity
with increased defect concentration. Our experimental and model results have
suggested that defects in polymer composites may enhance thermal transport in
polymer composites by promoting vibrational resonant couplings.",,physics.app-ph,"['physics.app-ph', 'cond-mat.mtrl-sci']",http://arxiv.org/abs/2310.10945v1
189,TEQ: Trainable Equivalent Transformation for Quantization of LLMs,http://arxiv.org/pdf/2310.10944v1,"[arxiv.Result.Author('Wenhua Cheng'), arxiv.Result.Author('Yiyang Cai'), arxiv.Result.Author('Kaokao Lv'), arxiv.Result.Author('Haihao Shen')]",,2023-10-17 02:42:34+00:00,"As large language models (LLMs) become more prevalent, there is a growing
need for new and improved quantization methods that can meet the
computationalast layer demands of these modern architectures while maintaining
the accuracy. In this paper, we present TEQ, a trainable equivalent
transformation that preserves the FP32 precision of the model output while
taking advantage of low-precision quantization, especially 3 and 4 bits
weight-only quantization. The training process is lightweight, requiring only
1K steps and fewer than 0.1 percent of the original model's trainable
parameters. Furthermore, the transformation does not add any computational
overhead during inference. Our results are on-par with the state-of-the-art
(SOTA) methods on typical LLMs. Our approach can be combined with other methods
to achieve even better performance. The code is available at
https://github.com/intel/neural-compressor.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.10944v1
190,MASON-NLP at eRisk 2023: Deep Learning-Based Detection of Depression Symptoms from Social Media Texts,http://arxiv.org/pdf/2310.10941v1,"[arxiv.Result.Author('Fardin Ahsan Sakib'), arxiv.Result.Author('Ahnaf Atef Choudhury'), arxiv.Result.Author('Ozlem Uzuner')]",,2023-10-17 02:34:34+00:00,"Depression is a mental health disorder that has a profound impact on people's
lives. Recent research suggests that signs of depression can be detected in the
way individuals communicate, both through spoken words and written texts. In
particular, social media posts are a rich and convenient text source that we
may examine for depressive symptoms. The Beck Depression Inventory (BDI)
Questionnaire, which is frequently used to gauge the severity of depression, is
one instrument that can aid in this study. We can narrow our study to only
those symptoms since each BDI question is linked to a particular depressive
symptom. It's important to remember that not everyone with depression exhibits
all symptoms at once, but rather a combination of them. Therefore, it is
extremely useful to be able to determine if a sentence or a piece of
user-generated content is pertinent to a certain condition. With this in mind,
the eRisk 2023 Task 1 was designed to do exactly that: assess the relevance of
different sentences to the symptoms of depression as outlined in the BDI
questionnaire. This report is all about how our team, Mason-NLP, participated
in this subtask, which involved identifying sentences related to different
depression symptoms. We used a deep learning approach that incorporated
MentalBERT, RoBERTa, and LSTM. Despite our efforts, the evaluation results were
lower than expected, underscoring the challenges inherent in ranking sentences
from an extensive dataset about depression, which necessitates both appropriate
methodological choices and significant computational resources. We anticipate
that future iterations of this shared task will yield improved results as our
understanding and techniques evolve.",Working Notes of CLEF (2023): 18-21,cs.CL,"['cs.CL', 'cs.LG']",http://arxiv.org/abs/2310.10941v1
191,Fast and Simple Spectral Clustering in Theory and Practice,http://arxiv.org/pdf/2310.10939v1,[arxiv.Result.Author('Peter Macgregor')],,2023-10-17 02:31:57+00:00,"Spectral clustering is a popular and effective algorithm designed to find $k$
clusters in a graph $G$. In the classical spectral clustering algorithm, the
vertices of $G$ are embedded into $\mathbb{R}^k$ using $k$ eigenvectors of the
graph Laplacian matrix. However, computing this embedding is computationally
expensive and dominates the running time of the algorithm. In this paper, we
present a simple spectral clustering algorithm based on a vertex embedding with
$O(\log(k))$ vectors computed by the power method. The vertex embedding is
computed in nearly-linear time with respect to the size of the graph, and the
algorithm provably recovers the ground truth clusters under natural assumptions
on the input graph. We evaluate the new algorithm on several synthetic and
real-world datasets, finding that it is significantly faster than alternative
clustering algorithms, while producing results with approximately the same
clustering accuracy.",,cs.DS,"['cs.DS', 'cs.LG']",http://arxiv.org/abs/2310.10939v1
192,Tracking quantum clouds expansion in tunneling ionization,http://arxiv.org/pdf/2310.10937v1,"[arxiv.Result.Author('I. A. Ivanov'), arxiv.Result.Author('A. S. Kheifets'), arxiv.Result.Author('Kyung Taec Kim')]",,2023-10-17 02:19:10+00:00,"We study formation and evolution of the electron wave-packets in the process
of strong field ionization of various atomic targets. Our study is based on
reformulating the problem in terms of conditional amplitudes, i.e., the
amplitudes describing outcomes of measurements of different observables
provided that the electron is found in the ionized state after the end of the
pulse. By choosing the electron coordinate as such an observable, we were able
to define unambiguously the notion of the ionized wave-packets and to study
their formation and spread. We show that the evolution of the ionized wave
packets obtained in this way follows closely the classical trajectories at the
initial stages of evolution providing an {\it ab initio} quantum-mechanical
confirmation of the basic premises of the Classical Monte Carlo Calculations
approach. At the later stages of evolution the picture becomes more complicated
due to the wave packets' spread and due to interference of wave packets
originating from different field maxima. Our approach also allowed us to obtain
information about the coordinate and velocity electron distributions at the
tunnel exit.",,physics.atom-ph,['physics.atom-ph'],http://arxiv.org/abs/2310.10937v1
193,Intent Detection and Slot Filling for Home Assistants: Dataset and Analysis for Bangla and Sylheti,http://arxiv.org/pdf/2310.10935v1,"[arxiv.Result.Author('Fardin Ahsan Sakib'), arxiv.Result.Author('A H M Rezaul Karim'), arxiv.Result.Author('Saadat Hasan Khan'), arxiv.Result.Author('Md Mushfiqur Rahman')]",,2023-10-17 02:12:12+00:00,"As voice assistants cement their place in our technologically advanced
society, there remains a need to cater to the diverse linguistic landscape,
including colloquial forms of low-resource languages. Our study introduces the
first-ever comprehensive dataset for intent detection and slot filling in
formal Bangla, colloquial Bangla, and Sylheti languages, totaling 984 samples
across 10 unique intents. Our analysis reveals the robustness of large language
models for tackling downstream tasks with inadequate data. The GPT-3.5 model
achieves an impressive F1 score of 0.94 in intent detection and 0.51 in slot
filling for colloquial Bangla.",,cs.CL,"['cs.CL', 'cs.LG']",http://arxiv.org/abs/2310.10935v1
194,Optimizing the random search of a finite-lived target by a Lévy flight,http://arxiv.org/pdf/2310.10934v1,"[arxiv.Result.Author('Denis Boyer'), arxiv.Result.Author('Gabriel Mercado-Vásquez'), arxiv.Result.Author('Satya N. Majumdar'), arxiv.Result.Author('Grégory Schehr')]",,2023-10-17 02:10:27+00:00,"In many random search processes of interest in chemistry, biology or during
rescue operations, an entity must find a specific target site before the latter
becomes inactive, no longer available for reaction or lost. We present exact
results on a minimal model system, namely, a one-dimensional searcher
performing a discrete time random walk or L\'evy flight. In contrast with the
search of a permanent target, the capture probability and the conditional mean
first passage time can be optimized. The optimal L\'evy index takes a
non-trivial value, even in the infinite lifetime limit, and exhibits an abrupt
transition as the initial distance to the target is varied. Depending on the
target lifetime, this transition can be discontinuous or continuous, separated
by a tricritical point in the phase diagram. These results pave the way to the
study of search processes under time constraints.",,cond-mat.stat-mech,['cond-mat.stat-mech'],http://arxiv.org/abs/2310.10934v1
195,Open-Structure: a Structural Benchmark Dataset for SLAM Algorithms,http://arxiv.org/pdf/2310.10931v1,"[arxiv.Result.Author('Yanyan Li'), arxiv.Result.Author('Zhao Guo'), arxiv.Result.Author('Ze Yang'), arxiv.Result.Author('Yanbiao Sun'), arxiv.Result.Author('Liang Zhao'), arxiv.Result.Author('Federico Tombari')]",,2023-10-17 02:01:37+00:00,"This paper introduces a new benchmark dataset, Open-Structure, for evaluating
visual odometry and SLAM methods, which directly equips point and line
measurements, correspondences, structural associations, and co-visibility
factor graphs instead of providing raw images. Based on the proposed benchmark
dataset, these 2D or 3D data can be directly input to different stages of SLAM
pipelines to avoid the impact of the data preprocessing modules in ablation
experiments. First, we propose a dataset generator for real-world and simulated
scenarios. In real-world scenes, it maintains the same observations and
occlusions as actual feature extraction results. Those generated simulation
sequences enhance the dataset's diversity by introducing various carefully
designed trajectories and observations. Second, a SLAM baseline is proposed
using our dataset to evaluate widely used modules in camera pose tracking,
parametrization, and optimization modules. By evaluating these state-of-the-art
algorithms across different scenarios, we discern each module's strengths and
weaknesses within the camera tracking and optimization process. Our dataset and
baseline are available at \url{https://github.com/yanyan-li/Open-Structure}.",,cs.RO,['cs.RO'],http://arxiv.org/abs/2310.10931v1
196,Enhanced Transformer Architecture for Natural Language Processing,http://arxiv.org/pdf/2310.10930v1,"[arxiv.Result.Author('Woohyeon Moon'), arxiv.Result.Author('Taeyoung Kim'), arxiv.Result.Author('Bumgeun Park'), arxiv.Result.Author('Dongsoo Har')]",,2023-10-17 01:59:07+00:00,"Transformer is a state-of-the-art model in the field of natural language
processing (NLP). Current NLP models primarily increase the number of
transformers to improve processing performance. However, this technique
requires a lot of training resources such as computing capacity. In this paper,
a novel structure of Transformer is proposed. It is featured by full layer
normalization, weighted residual connection, positional encoding exploiting
reinforcement learning, and zero masked self-attention. The proposed
Transformer model, which is called Enhanced Transformer, is validated by the
bilingual evaluation understudy (BLEU) score obtained with the Multi30k
translation dataset. As a result, the Enhanced Transformer achieves 202.96%
higher BLEU score as compared to the original transformer with the translation
dataset.",,cs.CL,"['cs.CL', 'cs.AI']",http://arxiv.org/abs/2310.10930v1
197,Optical Regulation of Chiral-Induced Spin Selectivity,http://arxiv.org/pdf/2310.10929v1,"[arxiv.Result.Author('Wei Liu'), arxiv.Result.Author('Jingqi Chen'), arxiv.Result.Author('Wenjie Dou')]",,2023-10-17 01:56:04+00:00,"We present a non-perturbative theory that describes how light regulates
chiral-induced spin selectivity (CISS) from the perspective of strong
light-matter interactions. The research results indicate that 1) light can have
opposite effects on the CISS, 2) the difference in CISS is caused by the steady
states of nuclei coupled to spin electrons and 3) this steady state differences
are caused by the different light-induced Lorentz forces felt by spin-up and
spin-down electrons. The fundamental reason for these results is the impact of
light on spin-orbital coupling (SOC), which is a complex process. This
theoretical framework is verified by the calculations of Floquet SOC
non-adiabatic nuclear dynamics.",,quant-ph,['quant-ph'],http://arxiv.org/abs/2310.10929v1
198,Spatial HuBERT: Self-supervised Spatial Speech Representation Learning for a Single Talker from Multi-channel Audio,http://arxiv.org/pdf/2310.10922v1,"[arxiv.Result.Author('Antoni Dimitriadis'), arxiv.Result.Author('Siqi Pan'), arxiv.Result.Author('Vidhyasaharan Sethu'), arxiv.Result.Author('Beena Ahmed')]",,2023-10-17 01:31:59+00:00,"Self-supervised learning has been used to leverage unlabelled data, improving
accuracy and generalisation of speech systems through the training of
representation models. While many recent works have sought to produce effective
representations across a variety of acoustic domains, languages, modalities and
even simultaneous speakers, these studies have all been limited to
single-channel audio recordings. This paper presents Spatial HuBERT, a
self-supervised speech representation model that learns both acoustic and
spatial information pertaining to a single speaker in a potentially noisy
environment by using multi-channel audio inputs. Spatial HuBERT learns
representations that outperform state-of-the-art single-channel speech
representations on a variety of spatial downstream tasks, particularly in
reverberant and noisy environments. We also demonstrate the utility of the
representations learned by Spatial HuBERT on a speech localisation downstream
task. Along with this paper, we publicly release a new dataset of 100 000
simulated first-order ambisonics room impulse responses.",,cs.CL,"['cs.CL', 'cs.SD', 'eess.AS']",http://arxiv.org/abs/2310.10922v1
199,Intelligent Software Tooling for Improving Software Development,http://arxiv.org/pdf/2310.10921v1,[arxiv.Result.Author('Nathan Cooper')],,2023-10-17 01:29:07+00:00,"Software has eaten the world with many of the necessities and quality of life
services people use requiring software. Therefore, tools that improve the
software development experience can have a significant impact on the world such
as generating code and test cases, detecting bugs, question and answering,
etc., The success of Deep Learning (DL) over the past decade has shown huge
advancements in automation across many domains, including Software Development
processes. One of the main reasons behind this success is the availability of
large datasets such as open-source code available through GitHub or image
datasets of mobile Graphical User Interfaces (GUIs) with RICO and ReDRAW to be
trained on. Therefore, the central research question my dissertation explores
is: In what ways can the software development process be improved through
leveraging DL techniques on the vast amounts of unstructured software
engineering artifacts?",,cs.SE,"['cs.SE', 'cs.AI']",http://arxiv.org/abs/2310.10921v1
200,NuclearQA: A Human-Made Benchmark for Language Models for the Nuclear Domain,http://arxiv.org/pdf/2310.10920v1,"[arxiv.Result.Author('Anurag Acharya'), arxiv.Result.Author('Sai Munikoti'), arxiv.Result.Author('Aaron Hellinger'), arxiv.Result.Author('Sara Smith'), arxiv.Result.Author('Sridevi Wagle'), arxiv.Result.Author('Sameera Horawalavithana')]",,2023-10-17 01:27:20+00:00,"As LLMs have become increasingly popular, they have been used in almost every
field. But as the application for LLMs expands from generic fields to narrow,
focused science domains, there exists an ever-increasing gap in ways to
evaluate their efficacy in those fields. For the benchmarks that do exist, a
lot of them focus on questions that don't require proper understanding of the
subject in question. In this paper, we present NuclearQA, a human-made
benchmark of 100 questions to evaluate language models in the nuclear domain,
consisting of a varying collection of questions that have been specifically
designed by experts to test the abilities of language models. We detail our
approach and show how the mix of several types of questions makes our benchmark
uniquely capable of evaluating models in the nuclear domain. We also present
our own evaluation metric for assessing LLM's performances due to the
limitations of existing ones. Our experiments on state-of-the-art models
suggest that even the best LLMs perform less than satisfactorily on our
benchmark, demonstrating the scientific knowledge gap of existing LLMs.",,cs.CL,"['cs.CL', 'cs.AI', 'I.2.7']",http://arxiv.org/abs/2310.10920v1
201,On the Performance of Near-Field ISAC,http://arxiv.org/pdf/2310.10917v1,"[arxiv.Result.Author('Boqun Zhao'), arxiv.Result.Author('Chongjun Ouyang'), arxiv.Result.Author('Xingqi Zhang'), arxiv.Result.Author('Yuanwei Liu')]",,2023-10-17 01:25:23+00:00,"The technical trends for the next-generation wireless network significantly
extend the near-field region, necessitating a reevaluation for the performance
of integrated sensing and communications (ISAC) to account for the effects
introduced by the near field. In this paper, a near-field ISAC framework is
proposed with a more accurate channel model than the three conventional models
(TCMs): uniform plane wave, uniform spherical wave, and non-uniform spherical
wave. Based on the proposed model, sensing and communication (S\&C) performance
in both downlink and uplink scenarios are analyzed. For the downlink case,
three different designs are investigated: the sensing-centric (S-C) design, the
communications-centric (C-C) design, and the Pareto optimal design. For the
uplink case, the S-C design, the C-C design and the time-sharing strategy are
considered. Within each design, sensing rates (SRs) and communication rates
(CRs) are derived. To gain further insights, high signal-to-noise ratio slopes
and rate scaling laws concerning the number of antennas are also examined.
Finally, the attainable SR-CR regions of the near-field ISAC are characterized.
Numerical results reveal that 1) as the number of antennas grows, the SRs and
CRs of the proposed model converges to constants, while those of the TCMs
increase unboundedly; 2) ISAC achieves a more extensive rate region than the
conventional frequency-division S\&C in both downlink and uplink cases.",,cs.IT,"['cs.IT', 'eess.SP', 'math.IT']",http://arxiv.org/abs/2310.10917v1
202,Identifiability of the Multinomial Processing Tree-IRT model for the Philadelphia Naming Test,http://arxiv.org/pdf/2310.10915v1,"[arxiv.Result.Author('Andrew J. Womack'), arxiv.Result.Author('Daniel Taylor-Rodriguez'), arxiv.Result.Author('Gerasimos Fergadiotis'), arxiv.Result.Author('William D. Hula')]",,2023-10-17 01:22:40+00:00,"For persons with aphasia, naming tests are used to evaluate the severity of
the disease and observing progress toward recovery. The Philadelphia Naming
Test (PNT) is a leading naming test composed of 175 items. The items are common
nouns which are one to four syllables in length and with low, medium, and high
frequency. Since the target word is known to the administrator, the response
from the patient can be classified as correct or an error. If the patient
commits an error, the PNT provides procedures for classifying the type of error
in the response. Item response theory can be applied to PNT data to provide
estimates of item difficulty and subject naming ability. Walker et al. (2018)
developed a IRT multinomial processing tree (IRT-MPT) model to attempt to
understand the pathways through which the different errors are made by patients
when responding to an item. The MPT model expands on existing models by
considering items to be heterogeneous and estimating multiple latent parameters
for patients to more precisely determine at which step of word of production a
patient's ability has been affected. These latent parameters represent the
theoretical cognitive steps taken in responding to an item. Given the
complexity of the model proposed in Walker et al. (2018), here we investigate
the identifiability of the parameters included in the IRT-MPT model.",,stat.ME,"['stat.ME', 'stat.AP']",http://arxiv.org/abs/2310.10915v1
203,Global solutions of 2D non-resistive MHD system under a magnetic vortex background,http://arxiv.org/pdf/2310.10914v1,"[arxiv.Result.Author('Yuanyuan Qiao'), arxiv.Result.Author('Yi Zhou')]",,2023-10-17 01:20:02+00:00,"We investigate the global well-posedness of two-dimensional incompressible
viscous and non-resistive MHD system near a non-constant equilibrium. Assuming
that the initial data has certain symmetries, we can establish time-weighted
lower-order energy estimates and uniform higher-order energy estimates by
exploring the dissipation nature of the linearized equations. With these
estimates, we can get the global well-posedness result.",,math.AP,['math.AP'],http://arxiv.org/abs/2310.10914v1
204,Iterative Clustering Material Decomposition Aided by Empirical Spectral Correction for High-Resolution Photon-Counting Detectors in Micro-CT,http://arxiv.org/pdf/2310.10913v1,"[arxiv.Result.Author('Juan C. R. Luna'), arxiv.Result.Author('Mini Das')]",,2023-10-17 01:15:08+00:00,"Photon counting detectors (PCDs) offer promising advancements in computed
tomography (CT) imaging by enabling the quantification and 3D imaging of
contrast agents and tissue types through multi-energy projections. However, the
accuracy of these decomposition methods hinges on precise composite spectral
attenuation values that one must reconstruct from spectral micro CT. Factors
such as surface defects, local temperature, signal amplification, and impurity
levels can cause variations in detector efficiency between pixels, leading to
significant quantitative errors. In addition, some inaccuracies such as the
charge-sharing effects in PCDs are amplified with a high Z sensor material and
also with a smaller detector pixels that are preferred for micro CT. In this
work, we propose a comprehensive approach that combines practical
instrumentation and measurement strategies leading to the quantitation of
multiple materials within an object in a spectral micro CT with a photon
counting detector. Our Iterative Clustering Material Decomposition (ICMD)
includes an empirical method for detector spectral response corrections,
cluster analysis and multi-step iterative material decomposition. Utilizing a
CdTe-1mm Medipix detector with a 55$\mu$m pitch, we demonstrate the
quantitatively accurate decomposition of several materials in a phantom study,
where the sample includes mixtures of material, soft material and K-edge
materials. We also show an example of biological sample imaging and separating
three distinct types of tissue in mouse: muscle, fat and bone. Our experimental
results show that the combination of spectral correction and high-dimensional
data clustering enhances decomposition accuracy and reduces noise in micro CT.
This ICMD allows for quantitative separation of more than three materials
including mixtures and also effectively separates multi-contrast agents.",,physics.med-ph,"['physics.med-ph', 'eess.IV', 'physics.ins-det', 'physics.optics']",http://arxiv.org/abs/2310.10913v1
205,Towards Training-free Open-world Segmentation via Image Prompting Foundation Models,http://arxiv.org/pdf/2310.10912v1,"[arxiv.Result.Author('Lv Tang'), arxiv.Result.Author('Peng-Tao Jiang'), arxiv.Result.Author('Hao-Ke Xiao'), arxiv.Result.Author('Bo Li')]",,2023-10-17 01:12:08+00:00,"The realm of computer vision has witnessed a paradigm shift with the advent
of foundational models, mirroring the transformative influence of large
language models in the domain of natural language processing. This paper delves
into the exploration of open-world segmentation, presenting a novel approach
called Image Prompt Segmentation (IPSeg) that harnesses the power of vision
foundational models. At the heart of IPSeg lies the principle of a
training-free paradigm, which capitalizes on image prompting techniques. IPSeg
utilizes a single image containing a subjective visual concept as a flexible
prompt to query vision foundation models like DINOv2 and Stable Diffusion. Our
approach extracts robust features for the prompt image and input image, then
matches the input representations to the prompt representations via a novel
feature interaction module to generate point prompts highlighting target
objects in the input image. The generated point prompts are further utilized to
guide the Segment Anything Model to segment the target object in the input
image. The proposed method stands out by eliminating the need for exhaustive
training sessions, thereby offering a more efficient and scalable solution.
Experiments on COCO, PASCAL VOC, and other datasets demonstrate IPSeg's
efficacy for flexible open-world segmentation using intuitive image prompts.
This work pioneers tapping foundation models for open-world understanding
through visual concepts conveyed in images.",,cs.CV,['cs.CV'],http://arxiv.org/abs/2310.10912v1
206,Machine Learning in the Quantum Age: Quantum vs. Classical Support Vector Machines,http://arxiv.org/pdf/2310.10910v1,"[arxiv.Result.Author('Davut Emre Tasar'), arxiv.Result.Author('Kutan Koruyan'), arxiv.Result.Author('Ceren Ocal Tasar')]",,2023-10-17 01:06:59+00:00,"This work endeavors to juxtapose the efficacy of machine learning algorithms
within classical and quantum computational paradigms. Particularly, by
emphasizing on Support Vector Machines (SVM), we scrutinize the classification
prowess of classical SVM and Quantum Support Vector Machines (QSVM) operational
on quantum hardware over the Iris dataset. The methodology embraced
encapsulates an extensive array of experiments orchestrated through the Qiskit
library, alongside hyperparameter optimization. The findings unveil that in
particular scenarios, QSVMs extend a level of accuracy that can vie with
classical SVMs, albeit the execution times are presently protracted. Moreover,
we underscore that augmenting quantum computational capacity and the magnitude
of parallelism can markedly ameliorate the performance of quantum machine
learning algorithms. This inquiry furnishes invaluable insights regarding the
extant scenario and future potentiality of machine learning applications in the
quantum epoch. Colab: https://t.ly/QKuz0",,cs.LG,['cs.LG'],http://arxiv.org/abs/2310.10910v1
207,Emergent Mixture-of-Experts: Can Dense Pre-trained Transformers Benefit from Emergent Modular Structures?,http://arxiv.org/pdf/2310.10908v1,"[arxiv.Result.Author('Zihan Qiu'), arxiv.Result.Author('Zeyu Huang'), arxiv.Result.Author('Jie Fu')]",,2023-10-17 01:02:32+00:00,"Incorporating modular designs into neural networks demonstrates superior
out-of-generalization, learning efficiency, etc. Existing modular neural
networks are generally $\textit{explicit}$ because their modular architectures
are pre-defined, and individual modules are expected to implement distinct
functions. Conversely, recent works reveal that there exist $\textit{implicit}$
modular structures in standard pre-trained transformers, namely
$\textit{Emergent Modularity}$. They indicate that such modular structures
exhibit during the early pre-training phase and are totally spontaneous.
However, most transformers are still treated as monolithic models with their
modular natures underutilized. Therefore, given the excellent properties of
explicit modular architecture, we explore $\textit{whether and how dense
pre-trained transformers can benefit from emergent modular structures.}$ To
study this question, we construct \textbf{E}mergent
$\textbf{M}$ixture-$\textbf{o}$f-$\textbf{E}$xperts (EMoE). Without introducing
additional parameters, EMoE can be seen as the modular counterpart of the
original model and can be effortlessly incorporated into downstream tuning.
Extensive experiments (we tune 1785 models) on various downstream tasks (vision
and language) and models (22M to1.5B) demonstrate that EMoE effectively boosts
in-domain and out-of-domain generalization abilities. Further analysis and
ablation study suggest that EMoE mitigates negative knowledge transfer and is
robust to various configurations. Code is available at
\url{https://github.com/qiuzh20/EMoE}",,cs.LG,"['cs.LG', 'cs.AI']",http://arxiv.org/abs/2310.10908v1
208,Surrogate Active Subspaces for Jump-Discontinuous Functions,http://arxiv.org/pdf/2310.10907v1,[arxiv.Result.Author('Nathan Wycoff')],,2023-10-17 00:44:51+00:00,"Surrogate modeling and active subspaces have emerged as powerful paradigms in
computational science and engineering. Porting such techniques to computational
models in the social sciences brings into sharp relief their limitations in
dealing with discontinuous simulators, such as Agent-Based Models, which have
discrete outputs. Nevertheless, prior applied work has shown that surrogate
estimates of active subspaces for such estimators can yield interesting
results. But given that active subspaces are defined by way of gradients, it is
not clear what quantity is being estimated when this methodology is applied to
a discontinuous simulator. We begin this article by showing some pathologies
that can arise when conducting such an analysis. This motivates an extension of
active subspaces to discontinuous functions, clarifying what is actually being
estimated in such analyses. We also conduct numerical experiments on synthetic
test functions to compare Gaussian process estimates of active subspaces on
continuous and discontinuous functions. Finally, we deploy our methodology on
Flee, an agent-based model of refugee movement, yielding novel insights into
which parameters of the simulation are most important across 8 displacement
crises in Africa and the Middle East.",,stat.ML,"['stat.ML', 'cs.LG']",http://arxiv.org/abs/2310.10907v1
209,Eliminating qubit type cross-talk in the $\textit{omg}$ protocol,http://arxiv.org/pdf/2310.10905v1,"[arxiv.Result.Author('Samuel R. Vizvary'), arxiv.Result.Author('Zachary J. Wall'), arxiv.Result.Author('Matthew J. Boguslawski'), arxiv.Result.Author('Michael Bareian'), arxiv.Result.Author('Andrei Derevianko'), arxiv.Result.Author('Wesley C. Campbell'), arxiv.Result.Author('Eric R. Hudson')]",,2023-10-17 00:41:29+00:00,"The $\textit{omg}$ protocol is a promising paradigm that uses multiple,
application-specific qubit subspaces within the Hilbert space of each single
atom during quantum information processing. A key assumption for $\textit{omg}$
operation is that a subspace can be accessed independently without deleterious
effects on information stored in other subspaces. We find that intensity noise
during laser-based quantum gates in one subspace can cause decoherence in other
subspaces, potentially complicating $\textit{omg}$ operation. We show, however,
that a magnetic-field-induced vector light shift can be used to eliminate this
source of decoherence. As this technique requires simply choosing a certain,
magnetic field dependent, polarization for the gate lasers it is
straightforward to implement and potentially helpful for $\textit{omg}$ based
quantum technology.",,quant-ph,"['quant-ph', 'physics.atom-ph']",http://arxiv.org/abs/2310.10905v1
210,Emergent AI-Assisted Discourse: Case Study of a Second Language Writer Authoring with ChatGPT,http://arxiv.org/pdf/2310.10903v1,"[arxiv.Result.Author('Sharin Jacob'), arxiv.Result.Author('Tamara Tate'), arxiv.Result.Author('Mark Warschauer')]",,2023-10-17 00:22:10+00:00,"The rapid proliferation of ChatGPT has incited debates regarding its impact
on human writing. Amid concerns about declining writing standards, this study
investigates the role of ChatGPT in facilitating academic writing, especially
among language learners. Using a case study approach, this study examines the
experiences of Kailing, a doctoral student, who integrates ChatGPT throughout
their academic writing process. The study employs activity theory as a lens for
understanding writing with generative AI tools and data analyzed includes
semi-structured interviews, writing samples, and GPT logs. Results indicate
that Kailing effectively collaborates with ChatGPT across various writing
stages while preserving her distinct authorial voice and agency. This
underscores the potential of AI tools such as ChatGPT to enhance academic
writing for language learners without overshadowing individual authenticity.
This case study offers a critical exploration of how ChatGPT is utilized in the
academic writing process and the preservation of a student's authentic voice
when engaging with the tool.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.10903v1
211,Reuse Kernels or Activations? A Flexible Dataflow for Low-latency Spectral CNN Acceleration,http://arxiv.org/pdf/2310.10902v1,"[arxiv.Result.Author('Yue Niu'), arxiv.Result.Author('Rajgopal Kannan'), arxiv.Result.Author('Ajitesh Srivastava'), arxiv.Result.Author('Viktor Prasanna')]",,2023-10-17 00:21:07+00:00,"Spectral-domain CNNs have been shown to be more efficient than traditional
spatial CNNs in terms of reducing computation complexity. However they come
with a `kernel explosion' problem that, even after compression (pruning),
imposes a high memory burden and off-chip bandwidth requirement for kernel
access. This creates a performance gap between the potential acceleration
offered by compression and actual FPGA implementation performance, especially
for low-latency CNN inference. In this paper, we develop a principled approach
to overcoming this performance gap and designing a low-latency, low-bandwidth,
spectral sparse CNN accelerator on FPGAs. First, we analyze the
bandwidth-storage tradeoff of sparse convolutional layers and locate
communication bottlenecks. We then develop a dataflow for flexibly optimizing
data reuse in different layers to minimize off-chip communication. Finally, we
propose a novel scheduling algorithm to optimally schedule the on-chip memory
access of multiple sparse kernels and minimize read conflicts. On a
state-of-the-art FPGA platform, our design reduces data transfers by 42\% with
DSP utilization up to 90\% and achieves inference latency of 9 ms for VGG16,
compared to the baseline state-of-the-art latency of 68 ms.",,cs.AR,"['cs.AR', 'eess.SP']",http://arxiv.org/abs/2310.10902v1
212,The Stackage Repository: An Exploratory Study of its Evolution,http://arxiv.org/pdf/2310.10887v1,"[arxiv.Result.Author('Paul Leger'), arxiv.Result.Author('Felipe Ruiz'), arxiv.Result.Author('Nicolás Sepúlveda'), arxiv.Result.Author('Ismael Figueroa'), arxiv.Result.Author('Nicolás Cardozo')]",,2023-10-16 23:42:47+00:00,"Context. Package repositories for a programming language are increasingly
common. A repository can keep a register of the evolution of its packages. In
the programming language Haskell, with its defining characteristic monads, we
can find the Stackage repository, which is a curated repository for stable
Haskell packages in the Hackage repository. Despite the widespread use of
Stackage in its industrial target, we are not aware of much empirical research
about how this repository has evolved, including the use of monads. Objective.
This paper conducts empirical research about the evolution of Stackage
considering monad packages through 22 Long-Term Support releases during the
period 2014-2023. Focusing on five research questions, this evolution is
analyzed in terms of packages with their dependencies and imports; including
the most used monad packages. To the best of our knowledge, this is the first
large-scale analysis of the evolution of the Stackage repository regarding
packages used and monads. Method. We define six research questions regarding
the repository's evolution, and analyze them on 51,716 packages (17.05 GB)
spread over 22 releases. For each package, we parse its cabal file and source
code to extract the data, which is analyzed in terms of dependencies and
imports using Pandas scripts. Results. From the methodology we get different
findings. For example, there are packages that depend on other packages whose
versions are not available in a particular release of Stackage; opening a
potential stability issue. The mtl and transformers are on the top 10 packages
most used/imported across releases of the Stackage evolution. We discussed
these findings with Stackage maintainers, which allowed us to refine the
research questions.",,cs.SE,"['cs.SE', 'cs.PL']",http://arxiv.org/abs/2310.10887v1
213,The Calysto Scheme Project,http://arxiv.org/pdf/2310.10886v1,"[arxiv.Result.Author('Douglas S. Blank'), arxiv.Result.Author('James B. Marshall')]",,2023-10-16 23:41:21+00:00,"Calysto Scheme is written in Scheme in Continuation-Passing Style, and
converted through a series of correctness-preserving program transformations
into Python. It has support for standard Scheme functionality, including
call/cc, as well as syntactic extensions, a nondeterministic operator for
automatic backtracking, and many extensions to allow Python interoperation.
Because of its Python foundation, it can take advantage of modern Python
libraries, including those for machine learning and other pedagogical contexts.
Although Calysto Scheme was developed with educational purposes in mind, it has
proven to be generally useful due to its simplicity and ease of installation.
It has been integrated into the Jupyter Notebook ecosystem and used in the
classroom to teach introductory Programming Languages with some interesting and
unique twists.",,cs.PL,"['cs.PL', 'cs.LG', 'D.3.0']",http://arxiv.org/abs/2310.10886v1
214,Diamond photonic crystals assembled from DNA origami,http://arxiv.org/pdf/2310.10884v1,"[arxiv.Result.Author('Gregor Posnjak'), arxiv.Result.Author('Xin Yin'), arxiv.Result.Author('Paul Butler'), arxiv.Result.Author('Oliver Bienek'), arxiv.Result.Author('Mihir Dass'), arxiv.Result.Author('Ian D. Sharp'), arxiv.Result.Author('Tim Liedl')]",,2023-10-16 23:33:22+00:00,"Colloidal self-assembly allows rational design of structures on the micron
and submicron scale, potentially leading to physical material properties that
are rare or non-existent in nature. One of the architectures that can generate
complete 3D photonic band gaps is the diamond cubic lattice, which has remained
difficult to realize at length scales comparable to the wavelength of visible
light. Here, we demonstrate 3D photonic crystals self-assembled from DNA
origami that act as precisely programmable patchy colloids. Our DNA-based
nanoscale tetrapods crystallize into a rod-connected diamond cubic lattice with
a periodicity of 170 nm that serves as a scaffold for atomic layer deposition
of high refractive index materials such as TiO$_2$, yielding a tunable photonic
band gap in the near UV range.",,physics.app-ph,"['physics.app-ph', 'physics.bio-ph', 'physics.optics']",http://arxiv.org/abs/2310.10884v1
215,Filling the Holes on 3D Heritage Object Surface based on Automatic Segmentation Algorithm,http://arxiv.org/pdf/2310.10875v1,"[arxiv.Result.Author('Sinh Van Nguyen'), arxiv.Result.Author('Son Thanh Le'), arxiv.Result.Author('Minh Khai Tran'), arxiv.Result.Author('Le Thanh Sach')]",,2023-10-16 23:01:39+00:00,"Reconstructing and processing the 3D objects are popular activities in the
research field of computer graphics, image processing and computer vision. The
3D objects are processed based on the methods like geometric modeling, a branch
of applied mathematics and computational geometry, or the machine learning
algorithms based on image processing. The computation of geometrical objects
includes processing the curves and surfaces, subdivision, simplification,
meshing, holes filling, reconstructing, and refining the 3D surface objects on
both point cloud data and triangular mesh. While the machine learning methods
are developed using deep learning models. With the support of 3D laser scan
devices and Lidar techniques, the obtained dataset is close to original shape
of the real objects. Besides, the photography and its application based on the
modern techniques in recent years help us collect data and process the 3D
models more precise. This article proposes an improved method for filling holes
on the 3D object surface based on an automatic segmentation. Instead of filling
the hole directly as the existing methods, we now subdivide the hole before
filling it. The hole is first determined and segmented automatically based on
computation of its local curvature. It is then filled on each part of the hole
to match its local curvature shape. The method can work on both 3D point cloud
surfaces and triangular mesh surface. Comparing to the state of the art
methods, our proposed method obtained higher accuracy of the reconstructed 3D
objects.",,cs.CV,"['cs.CV', 'cs.CG']",http://arxiv.org/abs/2310.10875v1
216,IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models,http://arxiv.org/pdf/2310.10873v1,"[arxiv.Result.Author('Shaokun Zhang'), arxiv.Result.Author('Xiaobo Xia'), arxiv.Result.Author('Zhaoqing Wang'), arxiv.Result.Author('Ling-Hao Chen'), arxiv.Result.Author('Jiale Liu'), arxiv.Result.Author('Qingyun Wu'), arxiv.Result.Author('Tongliang Liu')]",,2023-10-16 22:53:54+00:00,"In-context learning is a promising paradigm that utilizes in-context examples
as prompts for the predictions of large language models. These prompts are
crucial for achieving strong performance. However, since the prompts need to be
sampled from a large volume of annotated examples, finding the right prompt may
result in high annotation costs. To address this challenge, this paper
introduces an influence-driven selective annotation method that aims to
minimize annotation costs while improving the quality of in-context examples.
The essence of our method is to select a pivotal subset from a large-scale
unlabeled data pool to annotate for the subsequent sampling of prompts.
Specifically, a directed graph is first constructed to represent unlabeled
data. Afterward, the influence of candidate unlabeled subsets is quantified
with a diffusion process. A simple yet effective greedy algorithm for unlabeled
data selection is lastly introduced. It iteratively selects the data if it
provides a maximum marginal gain with respect to quantified influence. Compared
with previous efforts on selective annotations, our influence-driven method
works in an end-to-end manner, avoids an intractable explicit balance between
data diversity and representativeness, and enjoys theoretical support.
Experiments confirm the superiority of the proposed method on various
benchmarks, achieving better performance under lower time consumption during
subset selection. The project page is available at
https://skzhang1.github.io/IDEAL/.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.10873v1
217,Basal force fluctuations and granular rheology: Linking macroscopic descriptions of granular flows to bed forces with implications for monitoring signals,http://arxiv.org/pdf/2310.10871v1,"[arxiv.Result.Author('P. J. Zrelak'), arxiv.Result.Author('Eric C. P. Breard'), arxiv.Result.Author('Josef Dufek')]",,2023-10-16 22:43:14+00:00,"Granular flows are ubiquitous in nature with single flows traversing a wide
range of dynamic conditions from initiation to deposition. Basal forces exerted
by environmental granular flows are responsible for the generation of
observable seismic signals. To fully realize the benefit of seismic
measurements, basal granular forces must be linked to macroscopic internal flow
dynamics across a wide range of flow conditions. We utilize discrete element
simulations to observe dry and submerged granular flows under plane-shear and
inclined flow configurations, relating bulk kinematics and rheology to basal
forcing signals. We find that regardless of the flow geometry/initiation the
variance in basal forcing scales with a local non-dimensional shear-rate (or
inertial number I), and this scaling tracks four different flow regimes spanned
by our simulations: (1) an unsteady particle rearrangement regime when
$I<10^{-3}$, where basal forces are dominated by low frequencies; (2) an
intermediate regime when $10^{-3}< I<10^{-2}$, where granular temperature is
isotropic and basal forces start to become noise-like, (3) a transitional
regime at $10^{-2}<I<10^{-1}$, where the increase in basal tractions with
increasing shear-rates stalls as the granular bed dilates, partially destroying
the contact network and configurational memory, and (4) a fully collisional
regime when $I>10^{-1}$, where granular temperature is anisotropic in the
stream-wise direction, and the signal becomes white noise-like up to a cutoff
frequency that is dependent on particle size and shear-rate. This effort
suggests that basal forces, recorded in instrumented channels or inverted from
seismic signals, can be used to interpret complex granular processes in
geophysical flows.",,cond-mat.soft,"['cond-mat.soft', 'physics.geo-ph']",http://arxiv.org/abs/2310.10871v1
218,Will the Prince Get True Love's Kiss? On the Model Sensitivity to Gender Perturbation over Fairytale Texts,http://arxiv.org/pdf/2310.10865v1,"[arxiv.Result.Author('Christina Chance'), arxiv.Result.Author('Da Yin'), arxiv.Result.Author('Dakuo Wang'), arxiv.Result.Author('Kai-Wei Chang')]",,2023-10-16 22:25:09+00:00,"Recent studies show that traditional fairytales are rife with harmful gender
biases. To help mitigate these gender biases in fairytales, this work aims to
assess learned biases of language models by evaluating their robustness against
gender perturbations. Specifically, we focus on Question Answering (QA) tasks
in fairytales. Using counterfactual data augmentation to the FairytaleQA
dataset, we evaluate model robustness against swapped gender character
information, and then mitigate learned biases by introducing counterfactual
gender stereotypes during training time. We additionally introduce a novel
approach that utilizes the massive vocabulary of language models to support
text genres beyond fairytales. Our experimental results suggest that models are
sensitive to gender perturbations, with significant performance drops compared
to the original testing set. However, when first fine-tuned on a counterfactual
training dataset, models are less sensitive to the later introduced anti-gender
stereotyped text.",,cs.CL,['cs.CL'],http://arxiv.org/abs/2310.10865v1
