{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e38251a",
   "metadata": {},
   "source": [
    "# Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e29eb4",
   "metadata": {},
   "source": [
    "## 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398efba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dglover\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a530cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f59da",
   "metadata": {},
   "source": [
    "## 1.0 Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b087717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['use', 'show', 'however', 'approach', 'well', 'provide',' present', 'include', 'word', 'nlp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f04a770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>PDF URL</th>\n",
       "      <th>Author</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Journal Ref</th>\n",
       "      <th>Primary Category</th>\n",
       "      <th>Category</th>\n",
       "      <th>Entry ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural Language Processing using Hadoop and K...</td>\n",
       "      <td>http://arxiv.org/pdf/1608.04434v1</td>\n",
       "      <td>[arxiv.Result.Author('Emre Erturk'), arxiv.Res...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-15 23:09:21+00:00</td>\n",
       "      <td>Natural language processing, as a data analyti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1608.04434v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Integrating AI Planning with Natural Language ...</td>\n",
       "      <td>http://arxiv.org/pdf/2202.07138v2</td>\n",
       "      <td>[arxiv.Result.Author('Kebing Jin'), arxiv.Resu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-15 02:19:09+00:00</td>\n",
       "      <td>Natural language processing (NLP) aims at inve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>['cs.AI', 'cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2202.07138v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simple Natural Language Processing Tools for D...</td>\n",
       "      <td>http://arxiv.org/pdf/1906.11608v2</td>\n",
       "      <td>[arxiv.Result.Author('Leon Derczynski')]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-27 13:15:12+00:00</td>\n",
       "      <td>This technical note describes a set of baselin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1906.11608v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Towards the Study of Morphological Processing ...</td>\n",
       "      <td>http://arxiv.org/pdf/2006.16212v1</td>\n",
       "      <td>[arxiv.Result.Author('Mirinso Shadang'), arxiv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-29 17:24:09+00:00</td>\n",
       "      <td>There is no or little work on natural language...</td>\n",
       "      <td>In proceeding of Regional International Confer...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2006.16212v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natural Language Understanding with Distribute...</td>\n",
       "      <td>http://arxiv.org/pdf/1511.07916v1</td>\n",
       "      <td>[arxiv.Result.Author('Kyunghyun Cho')]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-24 23:23:13+00:00</td>\n",
       "      <td>This is a lecture note for the course DS-GA 30...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL', 'stat.ML']</td>\n",
       "      <td>http://arxiv.org/abs/1511.07916v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Natural Language Processing using Hadoop and K...   \n",
       "1  Integrating AI Planning with Natural Language ...   \n",
       "2  Simple Natural Language Processing Tools for D...   \n",
       "3  Towards the Study of Morphological Processing ...   \n",
       "4  Natural Language Understanding with Distribute...   \n",
       "\n",
       "                             PDF URL  \\\n",
       "0  http://arxiv.org/pdf/1608.04434v1   \n",
       "1  http://arxiv.org/pdf/2202.07138v2   \n",
       "2  http://arxiv.org/pdf/1906.11608v2   \n",
       "3  http://arxiv.org/pdf/2006.16212v1   \n",
       "4  http://arxiv.org/pdf/1511.07916v1   \n",
       "\n",
       "                                              Author  DOI  \\\n",
       "0  [arxiv.Result.Author('Emre Erturk'), arxiv.Res...  NaN   \n",
       "1  [arxiv.Result.Author('Kebing Jin'), arxiv.Resu...  NaN   \n",
       "2           [arxiv.Result.Author('Leon Derczynski')]  NaN   \n",
       "3  [arxiv.Result.Author('Mirinso Shadang'), arxiv...  NaN   \n",
       "4             [arxiv.Result.Author('Kyunghyun Cho')]  NaN   \n",
       "\n",
       "              Published Date  \\\n",
       "0  2016-08-15 23:09:21+00:00   \n",
       "1  2022-02-15 02:19:09+00:00   \n",
       "2  2019-06-27 13:15:12+00:00   \n",
       "3  2020-06-29 17:24:09+00:00   \n",
       "4  2015-11-24 23:23:13+00:00   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Natural language processing, as a data analyti...   \n",
       "1  Natural language processing (NLP) aims at inve...   \n",
       "2  This technical note describes a set of baselin...   \n",
       "3  There is no or little work on natural language...   \n",
       "4  This is a lecture note for the course DS-GA 30...   \n",
       "\n",
       "                                         Journal Ref Primary Category  \\\n",
       "0                                                NaN            cs.CL   \n",
       "1                                                NaN            cs.AI   \n",
       "2                                                NaN            cs.CL   \n",
       "3  In proceeding of Regional International Confer...            cs.CL   \n",
       "4                                                NaN            cs.CL   \n",
       "\n",
       "               Category                           Entry ID  \n",
       "0             ['cs.CL']  http://arxiv.org/abs/1608.04434v1  \n",
       "1    ['cs.AI', 'cs.CL']  http://arxiv.org/abs/2202.07138v2  \n",
       "2             ['cs.CL']  http://arxiv.org/abs/1906.11608v2  \n",
       "3             ['cs.CL']  http://arxiv.org/abs/2006.16212v1  \n",
       "4  ['cs.CL', 'stat.ML']  http://arxiv.org/abs/1511.07916v1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_csv('..\\\\data\\\\arxiv_papers_full_v2.csv', index_col=0)\n",
    "#print(df.target_names.unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b7fba05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3558, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a5d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Summary'] = df['Summary'].map(lambda x: x.lower().replace('natural langauge processing', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "673facd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data = df['Summary'].values.tolist()\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b8ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35ef545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a4915d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0217ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dglover\\Anaconda3\\lib\\site-packages\\spacy\\language.py:1895: UserWarning: [W123] Argument disable with value ['parser', 'ner'] is used instead of ['senter'] as specified in the config. Be aware that this might affect other components in your pipeline.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "#nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9596f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7668877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38f3adb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.071*\"intent\" + 0.057*\"change\" + 0.056*\"unit\" + 0.050*\"fast\" + '\n",
      "  '0.044*\"precision\" + 0.042*\"meaning\" + 0.039*\"external\" + 0.036*\"rnn\" + '\n",
      "  '0.030*\"update\" + 0.029*\"bidirectional\"'),\n",
      " (1,\n",
      "  '0.000*\"sphere\" + 0.000*\"linguistics\" + 0.000*\"poll\" + 0.000*\"ascribing\" + '\n",
      "  '0.000*\"consolidate\" + 0.000*\"watermark\" + 0.000*\"watermarke\" + '\n",
      "  '0.000*\"watermarking\" + 0.000*\"opportunitie\" + 0.000*\"decentralized\"'),\n",
      " (2,\n",
      "  '0.211*\"entity\" + 0.075*\"event\" + 0.062*\"relation\" + 0.059*\"protein\" + '\n",
      "  '0.037*\"verify\" + 0.037*\"claim\" + 0.035*\"ontology\" + 0.025*\"molecular\" + '\n",
      "  '0.025*\"molecule\" + 0.021*\"think\"'),\n",
      " (3,\n",
      "  '0.214*\"bias\" + 0.060*\"gender\" + 0.053*\"encourage\" + 0.048*\"determine\" + '\n",
      "  '0.046*\"usually\" + 0.045*\"video\" + 0.037*\"gender_bia\" + 0.034*\"term_memory\" '\n",
      "  '+ 0.033*\"long_short\" + 0.022*\"dictionary\"'),\n",
      " (4,\n",
      "  '0.050*\"language\" + 0.048*\"model\" + 0.027*\"task\" + 0.017*\"natural\" + '\n",
      "  '0.017*\"processing\" + 0.016*\"text\" + 0.012*\"use\" + 0.012*\"method\" + '\n",
      "  '0.012*\"dataset\" + 0.012*\"performance\"'),\n",
      " (5,\n",
      "  '0.308*\"concept\" + 0.126*\"explanation\" + 0.079*\"causal\" + 0.021*\"validity\" + '\n",
      "  '0.015*\"experimentally\" + 0.013*\"strict\" + 0.006*\"put\" + '\n",
      "  '0.003*\"observational\" + 0.000*\"codev\" + 0.000*\"emotion\"'),\n",
      " (6,\n",
      "  '0.074*\"human\" + 0.059*\"generation\" + 0.058*\"generate\" + 0.039*\"network\" + '\n",
      "  '0.039*\"fine_tune\" + 0.037*\"sequence\" + 0.034*\"image\" + 0.029*\"graph\" + '\n",
      "  '0.021*\"gpt\" + 0.019*\"ability\"'),\n",
      " (7,\n",
      "  '0.098*\"orient\" + 0.074*\"logic\" + 0.044*\"computationally\" + 0.028*\"stack\" + '\n",
      "  '0.027*\"incrementally\" + 0.018*\"pos_tagger\" + 0.012*\"formalization\" + '\n",
      "  '0.011*\"essentially\" + 0.004*\"cnl\" + 0.000*\"attempto\"'),\n",
      " (8,\n",
      "  '0.027*\"parallelism\" + 0.000*\"huge\" + 0.000*\"demand\" + 0.000*\"tension\" + '\n",
      "  '0.000*\"parallel\" + 0.000*\"extremely\" + 0.000*\"kernel\" + 0.000*\"hardware\" + '\n",
      "  '0.000*\"speedup\" + 0.000*\"dimensional\"'),\n",
      " (9,\n",
      "  '0.087*\"research\" + 0.044*\"field\" + 0.035*\"reasoning\" + 0.024*\"future\" + '\n",
      "  '0.023*\"discuss\" + 0.022*\"area\" + 0.021*\"legal\" + 0.021*\"potential\" + '\n",
      "  '0.021*\"survey\" + 0.020*\"review\"'),\n",
      " (10,\n",
      "  '0.205*\"memory\" + 0.117*\"identification\" + 0.104*\"temporal\" + '\n",
      "  '0.094*\"character\" + 0.056*\"mining\" + 0.010*\"fuzzy\" + 0.004*\"uncertain\" + '\n",
      "  '0.001*\"quantifie\" + 0.000*\"llm\" + 0.000*\"store\"'),\n",
      " (11,\n",
      "  '0.275*\"embedding\" + 0.155*\"question\" + 0.100*\"answer\" + '\n",
      "  '0.063*\"publicly_available\" + 0.045*\"web\" + 0.033*\"variant\" + '\n",
      "  '0.029*\"question_answere\" + 0.022*\"comment\" + 0.017*\"vec\" + 0.014*\"ask\"'),\n",
      " (12,\n",
      "  '0.238*\"query\" + 0.235*\"retrieval\" + 0.027*\"music\" + 0.016*\"prototype\" + '\n",
      "  '0.013*\"musical\" + 0.000*\"llm\" + 0.000*\"private\" + 0.000*\"recommender\" + '\n",
      "  '0.000*\"privacy\" + 0.000*\"dp\"'),\n",
      " (13,\n",
      "  '0.045*\"system\" + 0.029*\"natural\" + 0.027*\"process\" + 0.025*\"semantic\" + '\n",
      "  '0.025*\"sentence\" + 0.024*\"information\" + 0.016*\"word\" + 0.015*\"use\" + '\n",
      "  '0.014*\"analysis\" + 0.014*\"user\"'),\n",
      " (14,\n",
      "  '0.189*\"parse\" + 0.066*\"read\" + 0.050*\"rapid\" + 0.049*\"informal\" + '\n",
      "  '0.035*\"carefully\" + 0.024*\"reading\" + 0.016*\"rewrite\" + '\n",
      "  '0.010*\"presentation\" + 0.010*\"man\" + 0.001*\"axiom\"'),\n",
      " (15,\n",
      "  '0.086*\"alternative\" + 0.067*\"engineering\" + 0.067*\"synthesis\" + '\n",
      "  '0.057*\"generic\" + 0.055*\"list\" + 0.047*\"curate\" + 0.044*\"coherent\" + '\n",
      "  '0.018*\"linguistically\" + 0.017*\"careful\" + 0.014*\"indexing\"'),\n",
      " (16,\n",
      "  '0.079*\"code\" + 0.055*\"layer\" + 0.041*\"significantly\" + 0.039*\"single\" + '\n",
      "  '0.032*\"rely\" + 0.031*\"source\" + 0.030*\"output\" + 0.028*\"program\" + '\n",
      "  '0.024*\"dependency\" + 0.022*\"name\"'),\n",
      " (17,\n",
      "  '0.121*\"grammar\" + 0.106*\"currently\" + 0.048*\"statement\" + 0.040*\"leave\" + '\n",
      "  '0.028*\"algorithmic\" + 0.025*\"ambiguous\" + 0.024*\"freely_available\" + '\n",
      "  '0.023*\"regular\" + 0.016*\"bound\" + 0.011*\"context_free\"'),\n",
      " (18,\n",
      "  '0.232*\"speech\" + 0.093*\"automatic\" + 0.069*\"annotation\" + '\n",
      "  '0.067*\"especially\" + 0.049*\"recognition\" + 0.044*\"speak\" + 0.031*\"sub\" + '\n",
      "  '0.031*\"morphological\" + 0.022*\"end\" + 0.020*\"hybrid\"'),\n",
      " (19,\n",
      "  '0.013*\"generalise\" + 0.000*\"reason\" + 0.000*\"functor\" + 0.000*\"sum\" + '\n",
      "  '0.000*\"ethnicity\" + 0.000*\"summarise\" + 0.000*\"generalisation\" + '\n",
      "  '0.000*\"harmful\" + 0.000*\"struggle\" + 0.000*\"perceive\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5cae0008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -11.235099735501308\n",
      "\n",
      "Coherence Score:  0.43171519090320076\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0ce76a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dglover\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1603220906057176486822838415\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1603220906057176486822838415_data = {\"mdsDat\": {\"x\": [0.35556825663724106, 0.3671863665895713, 0.24006854145605427, 0.2592415881542758, 0.13128172546766043, 0.03947186159084203, -0.011035206211992027, -0.03515969239905949, -0.07032920342616723, -0.061419843519454106, -0.10106662492511569, -0.11242022386607174, -0.10524048238895653, -0.11319723694428391, -0.12249771980770845, -0.12253667176522635, -0.13154257740615694, -0.1355021223668021, -0.13546885787267343, -0.13540187699597706], \"y\": [-0.20387396987262688, -0.14435558061214815, 0.2778411561257762, -0.06371825201581843, 0.2602345279598112, 0.10449129335570025, 0.04829931755935828, 0.03424921815435039, 0.00171383184595621, -0.004236591019927816, -0.01935668207102144, -0.026009636193561357, -0.02184453412224383, -0.026110948928174928, -0.03123339188603885, -0.03129679654380935, -0.03597021937429155, -0.0395067050715004, -0.0396067000768356, -0.039709337212954256], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [65.47783486701277, 16.477063899744998, 5.038401100651599, 4.5206556991899145, 2.633079460360928, 1.2967119848399233, 0.895201051854604, 0.8249806982920987, 0.5655872425178861, 0.4463340205205275, 0.309514648897335, 0.30314280908469315, 0.28956446289451615, 0.2774109463062152, 0.26093888244203844, 0.20526974553647584, 0.14310103357955767, 0.013787339302264478, 0.01328998647006675, 0.008130120501587379]}, \"tinfo\": {\"Term\": [\"speech\", \"system\", \"model\", \"research\", \"embedding\", \"human\", \"generate\", \"generation\", \"natural\", \"code\", \"process\", \"information\", \"task\", \"sentence\", \"semantic\", \"field\", \"challenge\", \"question\", \"extraction\", \"language\", \"end\", \"bias\", \"learn\", \"network\", \"fine_tune\", \"novel\", \"application\", \"question_answere\", \"sequence\", \"concept\", \"model\", \"task\", \"method\", \"dataset\", \"performance\", \"propose\", \"datum\", \"result\", \"large\", \"work\", \"training\", \"domain\", \"learning\", \"state\", \"achieve\", \"improve\", \"train\", \"art\", \"classification\", \"evaluation\", \"transformer\", \"pre_traine\", \"experiment\", \"many\", \"various\", \"evaluate\", \"introduce\", \"perform\", \"compare\", \"show\", \"text\", \"also\", \"different\", \"language\", \"processing\", \"study\", \"demonstrate\", \"representation\", \"natural\", \"use\", \"learn\", \"base\", \"knowledge\", \"paper\", \"system\", \"semantic\", \"user\", \"form\", \"describe\", \"dialogue\", \"support\", \"visual\", \"content\", \"rule\", \"mean\", \"automatically\", \"write\", \"arabic\", \"description\", \"object\", \"expression\", \"define\", \"pattern\", \"construct\", \"social_media\", \"project\", \"game\", \"advance\", \"characteristic\", \"tree\", \"usage\", \"implement\", \"requirement\", \"phrase\", \"process\", \"tool\", \"linguistic\", \"word\", \"complex\", \"sentence\", \"represent\", \"search\", \"allow\", \"information\", \"analysis\", \"framework\", \"machine\", \"design\", \"structure\", \"level\", \"extract\", \"natural\", \"type\", \"present\", \"use\", \"develop\", \"base\", \"paper\", \"language\", \"feature\", \"generation\", \"network\", \"fine_tune\", \"sequence\", \"image\", \"graph\", \"gpt\", \"self\", \"response\", \"generative\", \"long\", \"instruction\", \"style\", \"behavior\", \"distribution\", \"encode\", \"agent\", \"version\", \"procedure\", \"comparable\", \"environment\", \"guide\", \"hypothesis\", \"powerful\", \"explicit\", \"comprehension\", \"top\", \"probability\", \"dynamic\", \"easily\", \"human\", \"utterance\", \"generate\", \"action\", \"interaction\", \"ability\", \"novel\", \"enable\", \"input\", \"learn\", \"research\", \"reasoning\", \"future\", \"discuss\", \"area\", \"legal\", \"survey\", \"review\", \"social\", \"ai\", \"comprehensive\", \"technology\", \"direction\", \"scientific\", \"database\", \"recommendation\", \"science\", \"perspective\", \"unstructured\", \"previously\", \"recent_advance\", \"maintain\", \"literature\", \"always\", \"summarize\", \"overview\", \"outline\", \"discussion\", \"rare\", \"technical\", \"community\", \"distinct\", \"field\", \"article\", \"potential\", \"development\", \"current\", \"application\", \"challenge\", \"progress\", \"year\", \"impact\", \"offer\", \"code\", \"layer\", \"significantly\", \"single\", \"rely\", \"program\", \"dependency\", \"name\", \"student\", \"parser\", \"hierarchical\", \"programming\", \"function\", \"handle\", \"computation\", \"note\", \"abstract\", \"mlm\", \"story\", \"compute\", \"constraint\", \"manual\", \"paradigm\", \"optimal\", \"classical\", \"unify\", \"compositional\", \"argument\", \"probe\", \"final\", \"output\", \"source\", \"adopt\", \"structure\", \"computational\", \"syntactic\", \"speech\", \"automatic\", \"annotation\", \"especially\", \"speak\", \"sub\", \"morphological\", \"hybrid\", \"relative\", \"projection\", \"room\", \"spoken\", \"quite\", \"tagging\", \"weakness\", \"turkish\", \"proficiency\", \"documentation\", \"phoneme\", \"engine\", \"neglect\", \"bleu_score\", \"reasonable\", \"harness\", \"entry\", \"exponential\", \"general_purpose\", \"viable\", \"morpheme\", \"selectively\", \"recognition\", \"end\", \"synthesize\", \"annotate\", \"embedding\", \"question\", \"answer\", \"publicly_available\", \"web\", \"variant\", \"comment\", \"vec\", \"widespread\", \"volume\", \"page\", \"classifie\", \"crawl\", \"open_source\", \"uzbek\", \"fasttext\", \"ask\", \"question_answere\", \"space\", \"analogy\", \"reading_comprehension\", \"rationale\", \"textbf\", \"bangla\", \"contextualize\", \"vqa\", \"classifier\", \"hyperbolic\", \"candidate\", \"rationalization\", \"clinical\", \"rank\", \"lm\", \"obtain\", \"label\", \"llm\", \"intent\", \"change\", \"unit\", \"fast\", \"precision\", \"meaning\", \"external\", \"rnn\", \"update\", \"bidirectional\", \"law\", \"matching\", \"uncertainty\", \"template\", \"try\", \"incremental\", \"likely\", \"knowledge_base\", \"scaling\", \"decrease\", \"gram\", \"parsing\", \"labor_intensive\", \"convey\", \"possess\", \"restriction\", \"impose\", \"century\", \"accept\", \"alter\", \"usually\", \"match\", \"service\", \"bias\", \"gender\", \"encourage\", \"determine\", \"video\", \"gender_bia\", \"term_memory\", \"long_short\", \"dictionary\", \"assumption\", \"implicit\", \"formulation\", \"nearly\", \"distance\", \"lstms\", \"recover\", \"perfect\", \"usually\", \"surprisal\", \"song\", \"stereotype\", \"association\", \"lyric\", \"debiase\", \"toxicity\", \"affective\", \"mitigate\", \"disability\", \"sentiment_analysis\", \"subtype\", \"measure\", \"plm\", \"llm\", \"label\", \"entity\", \"event\", \"protein\", \"verify\", \"claim\", \"ontology\", \"molecular\", \"molecule\", \"think\", \"confidence\", \"complement\", \"time_consuming\", \"chemical\", \"correctness\", \"reproduce\", \"drug_discovery\", \"trust\", \"proof_assistant\", \"relation\", \"smile\", \"directive\", \"wrap\", \"bert\", \"evolutionary\", \"security\", \"discovery\", \"namely\", \"disease\", \"european\", \"biological\", \"extraction\", \"label\", \"obtain\", \"plm\", \"llm\", \"clinical\", \"knowledge\", \"memory\", \"identification\", \"temporal\", \"character\", \"mining\", \"fuzzy\", \"uncertain\", \"quantifie\", \"llm\", \"lomo\", \"store\", \"tune\", \"gb\", \"subtask\", \"demand\", \"participation\", \"deepspeed\", \"rtx\", \"optimizer\", \"saving\", \"lower\", \"threshold\", \"ppis\", \"normalization\", \"academia\", \"fuse\", \"personalize\", \"consequently\", \"coverage\", \"save\", \"revolutionize\", \"bert\", \"chinese\", \"sentiment_analysis\", \"obtain\", \"extensive\", \"clinical\", \"python\", \"multi\", \"optimization\", \"query\", \"retrieval\", \"music\", \"prototype\", \"musical\", \"private\", \"recommender\", \"dp\", \"privacy\", \"rank\", \"recommend\", \"securely\", \"privacy_preserve\", \"incur\", \"differentially\", \"compromise\", \"guarantee\", \"freely\", \"significant_improvement\", \"publicly\", \"bag\", \"representative\", \"overcome\", \"candidate\", \"sql\", \"lass\", \"genre\", \"company\", \"ranking\", \"clir\", \"llm\", \"obtain\", \"joint\", \"business\", \"multi\", \"concept\", \"explanation\", \"causal\", \"validity\", \"experimentally\", \"strict\", \"put\", \"observational\", \"codev\", \"adjustment\", \"rationale\", \"neuron\", \"emotion\", \"rectify\", \"shortcut\", \"rationalization\", \"drug\", \"interfere\", \"delineation\", \"improper\", \"enumerate\", \"interference\", \"disagree\", \"dictate\", \"operationalize\", \"undesired\", \"enforce\", \"exhaustive\", \"skos\", \"thereby\", \"multi\", \"clinical\", \"lm\", \"avoid\", \"alignment\", \"label\", \"business\", \"region\", \"value\", \"mitigate\", \"desire\", \"llm\", \"reason\", \"alternative\", \"engineering\", \"synthesis\", \"generic\", \"list\", \"curate\", \"coherent\", \"linguistically\", \"careful\", \"indexing\", \"frequent\", \"removal\", \"syntactically\", \"stopword\", \"theorem\", \"discriminator\", \"chess\", \"rigorously\", \"deductive\", \"noun\", \"koko\", \"italian\", \"toxic\", \"elastic\", \"consolidation\", \"gendere\", \"fusional\", \"fusion\", \"possibility\", \"assignment\", \"prosody\", \"bangla\", \"plm\", \"weight\", \"device\", \"manually\", \"clinical\", \"label\", \"overall\", \"obtain\", \"prompt\", \"classifier\", \"space\", \"llm\", \"grammar\", \"currently\", \"statement\", \"leave\", \"algorithmic\", \"ambiguous\", \"freely_available\", \"regular\", \"bound\", \"context_free\", \"infinite\", \"danish\", \"parallel\", \"ccg\", \"sufficiently\", \"predictability\", \"cfg\", \"inductive\", \"operation\", \"pointer\", \"naturalistic\", \"programme\", \"gec\", \"geh\", \"correct\", \"excessively\", \"reentrancie\", \"nod\", \"algebra\", \"polynomial\", \"right\", \"device\", \"arbitrary\", \"psychology\", \"multimodal\", \"superior\", \"tag\", \"obtain\", \"llm\", \"parse\", \"read\", \"rapid\", \"informal\", \"carefully\", \"reading\", \"rewrite\", \"presentation\", \"man\", \"axiom\", \"serial\", \"treebank\", \"discrepancy\", \"necessitating\", \"unlikely\", \"stone\", \"automl\", \"deteriorate\", \"dedicated\", \"viseme\", \"lip\", \"universal_dependencie\", \"ultimate\", \"overlook\", \"distinction\", \"mathbf\", \"pronunciation\", \"face\", \"significance\", \"drop\", \"detail\", \"llm\", \"substantial\", \"clinical_note\", \"obtain\", \"creation\", \"orient\", \"logic\", \"computationally\", \"stack\", \"incrementally\", \"pos_tagger\", \"formalization\", \"essentially\", \"cnl\", \"attempto\", \"programme\", \"branching\", \"stochastic\", \"replay\", \"ppis\", \"factorization\", \"sort\", \"symptom\", \"humor\", \"dependency_parse\", \"deformable\", \"compress\", \"inductive\", \"polynomial\", \"vulnerability\", \"tamil\", \"rte\", \"pspace\", \"sparse\", \"status\", \"offline\", \"bert\", \"filter\", \"tag\", \"biomedical\", \"parallel\", \"obtain\", \"space\", \"together\", \"parallelism\", \"huge\", \"tension\", \"academy\", \"asic\", \"explode\", \"moore\", \"refreshing\", \"spawn\", \"incredible\", \"gpu\", \"iterate\", \"speedup\", \"expedite\", \"kernel\", \"load\", \"meet\", \"hardware\", \"imperative\", \"balance\", \"demand\", \"mapreduce\", \"ouali\", \"adaptable\", \"substructure\", \"frequently\", \"amortized\", \"speculatively\", \"dimensional\", \"speculation\", \"extremely\", \"alleviate\", \"inductive\", \"industry\", \"latency\", \"execute\", \"parallel\", \"device\", \"llm\", \"generalise\", \"generalisable\", \"sexual\", \"ethnicity\", \"orientation\", \"member\", \"summarise\", \"hate\", \"generalisation\", \"struggle\", \"functor\", \"identity\", \"perceive\", \"religion\", \"sum\", \"parameterise\", \"discopy\", \"estonian\", \"monoidal\", \"formulae\", \"quantum_circuit\", \"optimise\", \"entanglement\", \"silt\", \"functorial\", \"harmful\", \"gradient_descent\", \"differentiation\", \"qubit\", \"riesz\", \"rise\", \"category_theory\", \"analogy\", \"reason\", \"attack\", \"distributional\", \"space\", \"motivate\", \"diagrammatic\", \"koshik\", \"anxious\", \"coinciding\", \"embarrassed\", \"flourish\", \"fluently\", \"germane\", \"survival\", \"cedille\", \"creolization\", \"jamaican\", \"jampatoisnli\", \"underserve\", \"satisfiability\", \"veal\", \"unix\", \"dividable\", \"alternately\", \"cca\", \"understate\", \"vicinity\", \"weakly_supervised\", \"netwhitepaper\", \"ofsentiment\", \"authentic\", \"parole\", \"bosch\", \"digitising\", \"hardcopie\", \"hrl\", \"advantage\", \"amount\", \"analytic\", \"analyze\", \"architecture\", \"area\", \"build\", \"challenge\", \"component\", \"contain\", \"datum\", \"describe\", \"disadvantage\", \"discusse\", \"due\", \"evaluate\", \"explosive\", \"finally\", \"give\", \"growth\", \"hadoop\", \"human\", \"improve\", \"language\", \"large\", \"many\", \"natural\", \"performance\", \"platform\"], \"Freq\": [906.0, 2213.0, 9450.0, 1183.0, 742.0, 1141.0, 1094.0, 898.0, 4808.0, 624.0, 1340.0, 1710.0, 5406.0, 1389.0, 1238.0, 721.0, 1124.0, 417.0, 503.0, 10442.0, 542.0, 364.0, 1552.0, 595.0, 594.0, 752.0, 1007.0, 391.0, 557.0, 269.0, 9449.923787307365, 5405.510316297868, 2382.9738733788536, 2328.7618193719454, 2290.004112959517, 2200.722895691168, 2171.9013206024792, 1897.727447856326, 1699.5154918899584, 1673.5708225386388, 1573.7225268530667, 1500.714088842659, 1460.480285744851, 1274.728892175465, 1231.5859565606295, 1229.6147059644302, 1219.5371807926163, 1136.6531170077417, 1071.638481193799, 1063.1270306106842, 1056.4477321303714, 1045.0901335625533, 931.9570595227528, 921.4547101074078, 914.5032743766462, 833.7549003969974, 793.2110407894842, 768.7113431141304, 758.4840690032199, 688.9660850352163, 3151.355603561435, 1244.0997711861069, 1194.7354144418316, 9910.479174388704, 3292.5096329787525, 1247.7144957306978, 1107.2076645179736, 1402.5999795222951, 3367.040350210631, 2400.1875644257957, 1406.7349232507738, 2126.399678522047, 1198.4058701979689, 1501.9098768149415, 2212.4063535246432, 1237.8935448454913, 682.2989419702984, 419.74026151838194, 399.13295593074594, 383.52258462339466, 364.16885623917193, 354.57658892728426, 349.5059746112127, 332.72880634955925, 302.05663227975674, 298.720074948918, 276.18833185084276, 265.3247431312507, 263.1718951994291, 240.51548058266283, 237.7473616088209, 231.34147281541254, 224.75074856063873, 211.74891391067294, 210.47297161643445, 209.70417161931746, 198.09264620531007, 193.14789328621208, 186.180046929171, 184.98265970601284, 183.15142547696715, 179.3038789609672, 177.71892643197467, 174.3845178133743, 1330.0262592467998, 506.68104022766505, 464.2809868209256, 793.4634244865637, 358.7306503993098, 1220.0845557251978, 326.50096031431116, 243.33546900785043, 377.565175972557, 1190.5590315444088, 695.6745139231452, 629.2690473892962, 521.0978827521142, 453.7787745327357, 511.6477077011512, 575.6013780488526, 408.32514688650804, 1422.6449984937688, 382.3013305212877, 572.6868462851766, 745.0233640821888, 412.53694633577766, 646.275758189533, 476.41511139751117, 531.3599937759902, 367.48524340028916, 897.5204037954651, 594.4171924811222, 593.7153334967538, 556.4728916841569, 513.5947223060646, 441.9233787228948, 324.63642920829045, 257.49828756587203, 235.6786713035446, 232.78593333094813, 226.4121743096722, 209.6049039355902, 204.1072817355565, 183.86438959039162, 172.2919823232262, 163.27274395327592, 157.19807192511735, 154.17225882136486, 152.68253232392283, 152.27282256569393, 136.5102159919684, 126.5586745609856, 126.4669999537505, 123.26874589643802, 122.22128438149578, 121.56652025932141, 107.75807493414926, 103.8059639648135, 103.14575277711984, 98.34540441810559, 1129.7694867831194, 169.36637826918258, 884.6011795526788, 177.35741413924322, 196.12261843760794, 295.0738269726367, 275.7717158114916, 170.31180798097367, 184.16452219401071, 145.1090341609826, 1182.804858502394, 472.522634280085, 324.1614250286511, 308.68017709545387, 296.00337940785596, 286.72719697050934, 279.3511510287231, 273.82201980873225, 258.86071741761543, 222.96629492269702, 206.2624548615733, 197.061857992399, 178.14298805391948, 151.11885273458907, 148.62172717165754, 148.04464238842442, 125.5516603026057, 120.8935887324665, 113.90953040931834, 111.04757326381471, 108.23836881022069, 96.32369601995507, 210.7286592749329, 80.3142619174866, 76.9108575318784, 70.85904868494617, 66.97111443734639, 66.15929855805311, 56.56502157219464, 52.69704865922875, 268.4442625712938, 104.43898961020287, 593.3047716992669, 166.73520892005268, 280.3743073007424, 225.80388516749161, 226.41488330108717, 236.67596014451146, 200.12682615822186, 122.98323429764112, 116.4645051751298, 120.18481872672315, 117.01889653886805, 623.3060285053488, 433.7408084648572, 326.7688279225, 310.499733982353, 253.26581174598857, 219.89974024277987, 193.3966241543246, 173.87728542826648, 150.99299417062448, 150.08153501883606, 148.53716735142947, 140.7403192757236, 131.78558312531243, 129.62338568676194, 129.5002893741338, 121.72871776382244, 121.49362374431787, 120.0813464692503, 112.75586053655525, 109.36662103603113, 101.05123989679447, 100.77321354605897, 100.1977844364094, 89.9844457177155, 88.67427118498199, 87.47386429995196, 83.31106748557164, 81.85196635217324, 76.72717222381934, 73.90496588168754, 234.28778665481445, 246.7169254595314, 126.61599582164945, 161.26055581815032, 96.60382993438625, 98.21354128928212, 905.7094224616851, 362.1240402775891, 268.46193560147293, 261.57652979850167, 169.97307342398497, 122.5098004101988, 120.10887319066408, 76.75017614457255, 72.00119707435181, 58.174859058027494, 57.5706725101161, 43.266012415703145, 41.5455010069276, 32.53228708359724, 31.22078883579289, 31.214326694771973, 30.980224090257813, 29.979657739792025, 29.869766795255927, 23.52459161777912, 19.217530988792827, 17.70122978205988, 17.673228383151002, 17.37220425351728, 14.028802676616747, 13.992219939905892, 13.939746409314248, 13.909134880007079, 12.431912898342254, 12.358441045977935, 190.3029763488869, 84.5229280962396, 27.974664846010867, 32.11537534620655, 741.2981112126035, 416.9315283921383, 270.3784786153708, 169.7392749343089, 120.1948054071108, 90.25174982565154, 59.332166914226164, 47.154215458557054, 30.023239518585296, 26.957398309941336, 21.73231732635568, 12.066343167717857, 10.620964874914234, 9.058789648551947, 6.8377047578224355, 4.55050872684719, 38.156507723535924, 78.36121933575504, 0.05011758891878086, 0.050110125964967424, 0.05010940516719438, 0.050110081834491525, 0.05010890992518705, 0.050109037413228544, 0.05011026325978134, 0.05010754678382034, 0.05011144007247203, 0.05010706134858543, 0.05010952775184966, 0.050107399682234, 0.05011232268199004, 0.05010923354867699, 0.05011113115914072, 0.0501117784061206, 0.050111709758713645, 0.05011542652546173, 176.0281403381315, 142.50792374130992, 139.69830000112285, 124.41192124681258, 108.86568760215155, 104.25325635760956, 97.28464949843365, 89.02249667417107, 73.55882634744387, 72.01664647760242, 58.337672753117666, 52.29599796675145, 51.08694486640007, 43.20156266158281, 42.39318435040418, 41.65150727937666, 40.25140590962817, 34.430786853108586, 30.669075209929265, 30.641621969706126, 30.211684700983206, 29.588448024928148, 23.405060288102824, 20.80353146099768, 20.06515590470119, 16.905770573078634, 16.5910693560188, 15.484142263025388, 15.447906577168753, 14.644008562610052, 36.315340972734376, 40.72648161731565, 22.135608208376308, 363.67319068056827, 102.70526091926612, 89.59563004202452, 82.37971236768641, 76.36066135284042, 63.664312162874026, 57.526166434387314, 55.36142285514636, 38.29288092268464, 34.925221096318715, 30.52135287793765, 27.28992456248183, 21.95972553050492, 18.88618288704043, 14.58571757043541, 10.758772860644342, 9.800711848883427, 78.90723003258813, 1.4815748817907946, 0.04766243303310489, 0.04766257553904062, 0.047656017168041735, 0.04765397561561459, 0.04765350782439076, 0.0476542916070373, 0.04765324449820517, 0.04765434427227442, 0.04765234918917414, 0.0476562897880927, 0.047652203585283284, 9.084932539205415, 0.04765510636923508, 0.047660400774543116, 0.047654777985991874, 284.1562566493325, 101.16779503809538, 79.8791063447071, 50.27174482308153, 49.62662090665122, 47.29373450272019, 33.518673104561664, 33.09924091962095, 28.405039159834992, 27.336159634725625, 25.72634644944881, 22.739619185568714, 21.083089491675132, 19.250250727937868, 13.560215777465901, 7.314098911446813, 2.964669228566559, 0.48144038765719344, 83.9668021003891, 0.0366980846090981, 0.036695290253067885, 0.03669252523410885, 0.03669465950603744, 0.03669180403110892, 0.03669183336818011, 0.03669163289819369, 0.03669212673889194, 0.036691500881373365, 0.0366909068056819, 0.03669014648658706, 15.375445414060444, 0.03669455193677643, 0.03669328555320368, 0.03669301663005117, 0.03669615325191186, 0.03669247144947835, 0.03732797353020827, 191.3099889511271, 109.29472902536425, 96.88333138188125, 87.27397292726225, 52.59163327118134, 9.378455469229648, 3.468422585031673, 0.7899126263489654, 0.035218043828702424, 0.03519536018383217, 0.03519564161021845, 0.035195387309266996, 0.035193376636410784, 0.03519301722439938, 0.035193396980486895, 0.035192600170838986, 0.03519241707415394, 0.03519241707415394, 0.03519241707415394, 0.03519242046483329, 0.035192427246191996, 0.03519241707415394, 0.03519295958285039, 0.03519269850054022, 0.03519241707415394, 0.035192515403855165, 0.035192342479208175, 0.03519248827842034, 0.035193081647307084, 0.03519209156893607, 0.03519245776230617, 0.03519411919518904, 0.035193108772741906, 0.03519319014904638, 0.03519354277969907, 0.03519274597005116, 0.03519319693040508, 0.03519250184113776, 0.035192569654724816, 0.035192474715702936, 217.01302664604918, 214.5035633109251, 24.633855032448547, 14.787170285003036, 11.590682225837357, 0.039742707828413326, 0.03973832427083718, 0.03973820804014387, 0.03973824456979034, 0.039737231702320096, 0.0397343956734034, 0.03973370825187442, 0.03973370825187442, 0.03973370825187442, 0.03973370825187442, 0.03973370825187442, 0.03973377466941345, 0.03973370825187442, 0.039733721535382224, 0.039733718214505276, 0.03973333963453279, 0.03973402041430787, 0.03973408351096995, 0.039734581642512694, 0.03973233340881644, 0.03973155300273281, 0.039731612778517944, 0.039732014604629086, 0.03973154968185586, 0.03973117442276033, 0.03974818063362961, 0.039734747686360275, 0.03973205445515251, 0.039731699121318687, 0.03973188509042797, 268.8969329841537, 109.68923130973857, 68.58130413735087, 18.46100110522888, 13.250821119171807, 11.313426723461188, 5.283491987271429, 2.526290260225751, 0.03454747726243756, 0.03454330591343156, 0.03454376269993868, 0.034542611217285316, 0.03454532021504282, 0.03453985146547146, 0.034539543769004866, 0.03453993711294155, 0.034540247981536674, 0.03453918849061044, 0.03453913773655409, 0.03453913773655409, 0.03453913773655409, 0.03453915676932522, 0.03453913773655409, 0.03453913773655409, 0.03453913773655409, 0.03453913773655409, 0.034539258277437916, 0.03453917897422487, 0.03453896961374244, 0.03453940419534991, 0.03454254143045784, 0.03454265562708462, 0.03454204340627994, 0.03453956914603304, 0.03453994028507007, 0.034541748398327424, 0.034539451777277734, 0.034539296342980176, 0.03453972775245912, 0.03453944226089217, 0.03453923607253826, 0.03454015916193807, 0.034539299515108694, 71.7042443352013, 56.350394308433145, 55.79988862538895, 47.88430389168501, 46.122780308451, 39.03811678220087, 37.09326660970379, 15.39591702331648, 14.0809981850622, 12.071752179133872, 10.376663517915834, 8.573969950395306, 7.518174848535886, 6.983045184869211, 4.908874318330084, 3.4726584945871903, 2.9588630189077616, 2.725987977401977, 1.4748591197611816, 0.03613321582413892, 0.036131620354991026, 0.03613186043511042, 0.03613191209792093, 0.036131121960819114, 0.03613109764890829, 0.03613138939183819, 0.03613124352037324, 0.03613200630657538, 0.036131535263303136, 0.03613104598609778, 0.036131483600492634, 0.03613186043511042, 0.036135017944528836, 0.03613218560691771, 0.03613223726972821, 0.03613198807264226, 0.036133392085492405, 0.036133741569210516, 0.03613229501051642, 0.036133072991662823, 0.03613299093896379, 0.0361324196090594, 0.036132726546933565, 0.03613452866732348, 94.97528347072765, 83.47659649195724, 38.064479268723595, 31.11359535786799, 21.775352301012546, 19.54140776279011, 18.749061752130935, 18.32781189375849, 12.210294274795787, 8.386947206820397, 7.445882461092347, 2.2274492029939887, 0.03968799852206617, 0.03967929712555302, 0.03967986311652201, 0.03967929712555302, 0.03967851960260572, 0.03967874256874502, 0.03967939145738118, 0.03967856533924968, 0.03967825661690296, 0.039678416695156815, 0.039678582490491165, 0.0396780422263844, 0.03968039766354828, 0.039677713494255945, 0.039677713494255945, 0.039677713494255945, 0.039677713494255945, 0.03967789072375129, 0.03967866252961809, 0.039679368589059204, 0.039677982197039205, 0.03967849101720325, 0.03967874256874502, 0.039678393826834836, 0.0396786510954571, 0.03967911417897718, 0.03968085788852811, 116.7188089828309, 40.81105719334, 31.16385413432703, 30.225053756350285, 21.578063101942924, 14.704705658895142, 10.146894781945946, 6.418929169962704, 6.07894843720437, 0.7145352333672116, 0.6193223421710137, 0.03132309780980593, 0.031313066383651514, 0.03131278754553379, 0.03131278754553379, 0.03131278754553379, 0.03131340143913167, 0.03131278754553379, 0.031313190061848885, 0.03131283027072925, 0.031312832519423746, 0.03131278754553379, 0.03131278754553379, 0.03131278754553379, 0.03131280778378427, 0.03131256717347301, 0.03131281902725676, 0.031313907395393664, 0.03131289323417519, 0.031312985430649594, 0.03131351162516206, 0.031321483247156556, 0.03131319905662688, 0.03131285950375772, 0.031312933710676144, 0.03131279204292279, 42.30668724410465, 31.924859962889567, 18.865972735180783, 12.070101564149558, 11.719923028775947, 7.943646843849247, 5.065499069026055, 4.724419608493862, 1.5820580449229804, 0.1733816611305391, 0.02720815395533365, 0.02720726039652685, 0.027207583331814923, 0.02720768052593075, 0.027207777720046577, 0.02720711303770608, 0.027207125578882316, 0.02720755824946245, 0.027207097361235784, 0.02720767425534263, 0.02720684340241701, 0.027207755772988163, 0.02720716947299914, 0.027206987625943722, 0.027207066008295196, 0.02720695627300313, 0.027206824590652656, 0.0272067524788893, 0.02720731996711397, 0.027207031520060546, 0.027207138120058552, 0.027208887614143445, 0.027207131849470434, 0.027207366996524856, 0.02720761782004957, 0.027207489272993154, 0.027207934484749525, 0.02720776517887034, 0.027207156931822903, 1.1108945723180683, 0.0037295248192318773, 0.0037293716667878007, 0.003729295241603676, 0.003729295241603676, 0.003729295241603676, 0.003729295241603676, 0.003729295241603676, 0.003729295241603676, 0.003729295241603676, 0.003729295241603676, 0.003729295241603676, 0.0037292961478311557, 0.003729295241603676, 0.0037293154806840568, 0.003729295241603676, 0.003729295241603676, 0.0037292961478311557, 0.003729295241603676, 0.003729295241603676, 0.0037293716667878007, 0.0037292426804098507, 0.0037292426804098507, 0.0037292426804098507, 0.0037292426804098507, 0.003729295241603676, 0.0037292429824856772, 0.0037292429824856772, 0.0037292961478311557, 0.0037292429824856772, 0.0037293194076698025, 0.003729295241603676, 0.0037292783253573872, 0.003729295241603676, 0.0037292913146179303, 0.003729267752703457, 0.0037293423654326226, 0.0037292961478311557, 0.003729291616693757, 0.5254526195298009, 0.0036450806142207864, 0.0036450806142207864, 0.0036450806142207864, 0.0036450806142207864, 0.0036450806142207864, 0.0036450806142207864, 0.0036450806142207864, 0.0036450806142207864, 0.0036450806142207864, 0.0036450838171897685, 0.0036450806142207864, 0.0036450806142207864, 0.0036450806142207864, 0.0036450806142207864, 0.0036450695494188484, 0.0036450695494188484, 0.0036450413050560064, 0.0036450555728269264, 0.0036450418874140033, 0.0036450695494188484, 0.0036450418874140033, 0.0036450418874140033, 0.003645033734402049, 0.0036450418874140033, 0.0036450806142207864, 0.0036450418874140033, 0.0036450418874140033, 0.0036450418874140033, 0.003645030531433067, 0.0036450806142207864, 0.0036450555728269264, 0.0036450695494188484, 0.003645095464349703, 0.0036450806142207864, 0.003645042760950998, 0.0036450436344879935, 0.003645042760950998, 0.0036450418874140033, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177, 0.0022592969541478177], \"Total\": [906.0, 2213.0, 9450.0, 1183.0, 742.0, 1141.0, 1094.0, 898.0, 4808.0, 624.0, 1340.0, 1710.0, 5406.0, 1389.0, 1238.0, 721.0, 1124.0, 417.0, 503.0, 10442.0, 542.0, 364.0, 1552.0, 595.0, 594.0, 752.0, 1007.0, 391.0, 557.0, 269.0, 9450.664908918521, 5406.248859379933, 2383.712416460918, 2329.50036245401, 2290.7426560415815, 2201.461466064346, 2172.639863684544, 1898.4659909383904, 1700.2540349720227, 1674.3094274280386, 1574.461069935131, 1501.4526319247234, 1461.2188310244985, 1275.4674352575294, 1232.3244996426938, 1230.3532490464945, 1220.2757238746806, 1137.391660089806, 1072.3770242758633, 1063.8655736927485, 1057.1862752124357, 1045.8286766446176, 932.6956026048175, 922.1932531894724, 915.2418174587109, 834.4934434790621, 793.9495838715488, 769.449886196195, 759.2226120852846, 689.704628117281, 3171.357125215962, 1249.1174592352902, 1205.5941012628753, 10442.511154665634, 3395.874765196574, 1269.5503714025717, 1132.573855965893, 1534.9348204836617, 4808.037491879278, 3145.8827373920226, 1552.522889276794, 2773.3472456025174, 1304.016841896408, 2036.4071491020034, 2213.142000584998, 1238.6263440772118, 683.0316925153945, 420.47301308899034, 399.8657064758419, 384.2553351684906, 364.9016112225513, 355.3093394792796, 350.23872516191255, 333.4615568946552, 302.7893828248527, 299.4530291731181, 276.9210823959387, 266.05749368685395, 263.90464574452506, 241.24823112775874, 238.4801121608588, 232.07422336611236, 225.48349911263398, 212.48166445576885, 211.20572216153036, 210.43692216441337, 198.8253967690996, 193.880643831308, 186.9127974742669, 185.71541025471439, 183.88417603776125, 180.03662950606312, 178.45167697707058, 175.1172683584702, 1340.38523742148, 512.5268738845862, 482.47505128107105, 846.4970019727635, 373.8234127274574, 1389.986208387738, 345.1719506999516, 251.64400180350316, 419.3449250825812, 1710.9935241779335, 912.568894010636, 830.7017347473426, 654.3180510681091, 549.8767348583538, 681.0815578905198, 895.3063467532509, 546.0322007563075, 4808.037491879278, 511.84417506343704, 1357.6612708235316, 3145.8827373920226, 673.9956604215419, 2773.3472456025174, 2036.4071491020034, 10442.511154665634, 804.7838259338315, 898.2602773327686, 595.157066007218, 594.4552070284535, 557.2127652102527, 514.3345958321603, 442.66325224899055, 325.3763027343862, 258.23816109196775, 236.41854482964027, 233.5258068570438, 227.15204783821264, 210.34477746168585, 204.84715526165218, 184.6042631196594, 173.03185584932186, 164.01262906822282, 157.937945451213, 154.9121323615191, 153.4224058500185, 153.0126961009991, 137.25008956883065, 127.2985480870813, 127.20687347984621, 124.00861942253373, 122.96115791068945, 122.30639379387183, 108.49794846024497, 104.54583749090921, 103.88562630321555, 99.0852779442013, 1141.340779963394, 171.09464412845702, 1094.7353464385615, 187.53228678179357, 216.90751514931125, 500.7633946810811, 752.9955672656483, 381.69790531828465, 621.148670391833, 1552.522889276794, 1183.5423383857126, 473.26009935231383, 324.8988901008799, 309.4176421676827, 296.7408444856887, 287.46466204273815, 280.0886161009519, 274.55948488096107, 259.59818249294216, 223.70375999492578, 206.99991993380206, 197.79932306462777, 178.88045312614824, 151.8563178092626, 149.3591922438863, 148.78210746397406, 126.2891253748345, 121.63105381029919, 114.64699548399189, 111.78503834616616, 108.97583389495274, 97.06116111281148, 212.48643263935213, 81.05172700096003, 77.64832260410721, 71.59651375717498, 67.70857950957519, 66.89676363028191, 57.30248666751344, 53.43451373145756, 274.0030742400731, 106.02712149693753, 721.9819552287578, 206.97444111372917, 452.50711113587835, 358.3364606895568, 502.8621117997761, 1007.7571520923553, 1124.5849986254589, 207.20653629589273, 175.7669750371389, 252.77923159362413, 188.36743938875892, 624.0476008260297, 434.48238078553817, 327.5104002487849, 311.241306303034, 254.00738406666946, 220.71311646967627, 194.13894004999736, 174.61885774894736, 151.73456649130537, 150.82310734176565, 149.27873967211036, 141.4818915964045, 132.52715544599332, 130.36495801998868, 130.2418616948147, 122.47029009629763, 122.23519606499879, 120.82291880217686, 113.49743287538014, 110.10819335671205, 101.79281221747539, 101.51478587238061, 100.93935675709032, 90.72601803839642, 89.4158435056629, 88.21543662624975, 84.05263980625256, 82.5935386752989, 77.46874455010415, 74.64653820236846, 248.11261371388136, 392.14137105250234, 171.14381165870557, 681.0815578905198, 188.93851266775144, 246.6438140374166, 906.4564348106362, 362.8710526265403, 269.20894795042415, 262.3235421474529, 170.72008577293607, 123.25681275914997, 120.85588554186394, 77.49718849352371, 72.74820942330297, 58.921871423087524, 58.31768487160735, 44.013024766903, 42.29251335587877, 33.279299432548406, 31.967801194032376, 31.96133904372313, 31.727236467148934, 30.726670092348794, 30.616779144207083, 24.271603966730275, 19.964543337743983, 18.44824214786257, 18.420240737005543, 18.119216602468434, 14.775815025567901, 14.739232342319916, 14.686758811183811, 14.656147238167742, 13.178925247293408, 13.105453424373184, 370.4640916393173, 542.2575531229907, 71.55045831816315, 347.01640389942025, 742.0474925424967, 417.6809097220315, 271.127859945264, 170.48865626420198, 120.94418673700396, 91.0011311577934, 60.08154824411932, 47.90359678845021, 30.77262084847844, 27.70677963983448, 22.481698656248824, 12.815724497611, 11.370346204807378, 9.80817097844509, 7.587086111030295, 5.299890056740335, 74.48422304329605, 391.61212218103105, 0.799605883936822, 0.7995141064787198, 0.7995070713272869, 0.7995200839428004, 0.7995027212780803, 0.7995122643958904, 0.7995344093228914, 0.799498108010318, 0.7995611223673544, 0.7994919801412425, 0.7995351983770541, 0.7995024535457026, 0.7995922213416645, 0.7995371864914058, 0.7995920657340421, 0.799617404972402, 0.7996480198116998, 0.7999747239145131, 176.77567926092982, 143.25546266410825, 140.44583892392117, 125.15946016961095, 109.61322652494992, 105.00079528040793, 98.03218842123202, 89.77003559696944, 74.30636527673089, 72.76418540040079, 59.085211682106426, 53.043536889549834, 51.83448378919845, 43.9491015843812, 43.14072327320256, 42.399046208639206, 40.998944835524505, 35.17832577590697, 31.416614148836494, 31.389160892504496, 30.959223623781575, 30.335986952833757, 24.152599251732013, 21.55107038379605, 20.81269482749956, 17.653309495877004, 17.33860827881717, 16.231681185823756, 16.19544549996712, 15.391547485408424, 115.92246226613781, 154.19049918850234, 73.56104928972638, 364.4250277617076, 103.45709800040545, 90.34746712316385, 83.13154944882574, 77.11249843397975, 64.41614924401335, 58.27800351552665, 56.113259936285694, 39.044718003823974, 35.67705817745805, 31.273189969148447, 28.041761643621143, 22.71156261783461, 19.638019968179744, 15.337554654965407, 11.510609945104537, 10.55254893032482, 115.92246226613781, 2.2334119692899796, 0.7995092849588463, 0.799520326293944, 0.7995053095289529, 0.7994950019350363, 0.7994972139320651, 0.7995135757152065, 0.7994989892013635, 0.7995238902912795, 0.7994938694343648, 0.7995605771454602, 0.7994924924381939, 240.36589709865865, 0.7996086587568543, 0.7999747239145131, 0.7996480198116998, 284.91905492288123, 101.9305933116441, 80.64190461825582, 51.034543096630266, 50.38941918019996, 48.05653277626893, 34.2814713781104, 33.862039193169686, 29.167837439574086, 28.098957908274343, 26.48914472860142, 23.50241745911743, 21.84588776522385, 20.01304900971085, 14.323014054565938, 8.076897197263891, 3.7274675021152825, 1.2442386612059175, 315.8243590802168, 0.7995054465943856, 0.799503506387611, 0.7994954943320162, 0.7995572362369737, 0.7995010068496016, 0.7995070798341708, 0.7995078414983028, 0.799523512278094, 0.7995121366752014, 0.7994999210887721, 0.7994932681524007, 503.7843936694069, 0.7996480198116998, 0.799617404972402, 0.7996086587568543, 0.7999747239145131, 0.7995922213416645, 1304.016841896408, 192.074284220285, 110.05902429452216, 97.64762665103916, 88.03826819642016, 53.355928540339264, 10.14275073838756, 4.232717858708346, 1.5542078955068792, 0.7999747239145131, 0.7994958432521861, 0.7995153939530925, 0.7995208588490835, 0.7994936936315273, 0.7995018227681279, 0.7995109078943988, 0.7994937835577915, 0.7994902932856236, 0.7994902932856236, 0.7994907206366513, 0.7994910752309355, 0.7994923045108704, 0.7994936563348777, 0.7995072293931398, 0.7995018005196932, 0.7994956399983267, 0.7994982629162249, 0.7994964842016551, 0.7995030456323751, 0.7995195540510113, 0.7994972218243892, 0.7995062171158066, 0.7995572362369737, 0.799535107206033, 0.7995605771454602, 0.799617404972402, 0.7995314866210224, 0.7995922213416645, 0.7995191632325014, 0.7995874186667696, 0.7995209442228157, 217.77278218402884, 215.26331884890476, 25.393610570428205, 15.546925822982697, 12.350437763817018, 0.7995133858926528, 0.7995058382800139, 0.7995040435982382, 0.7995365839652337, 0.7995371864914058, 0.7995012972402381, 0.7994914375042469, 0.7994928377675853, 0.7994929025975163, 0.7994934307817015, 0.7994945596447579, 0.7994981328740409, 0.799502369817548, 0.7995047894953148, 0.7995047250376829, 0.7995032224451696, 0.7995192623395118, 0.7995232461856738, 0.7995351983770541, 0.7994921394437574, 0.7994893399765431, 0.7994913074654549, 0.7995013073665415, 0.7994929466779177, 0.7994892580739732, 0.7999747239145131, 0.799617404972402, 0.7995377435582678, 0.7995161602247408, 0.7995874186667696, 269.6618827577164, 110.4541810833013, 69.34625391091359, 19.22595087879159, 14.01577090118922, 12.078376500575216, 6.048441764155017, 3.2912400337884637, 0.7995048796306261, 0.7994993671029529, 0.7995200839428004, 0.799509221090624, 0.7995971751381116, 0.7994992450452318, 0.7994928991862328, 0.7995024535457026, 0.7995106603364168, 0.799491712073806, 0.7994914575684504, 0.7994914575684504, 0.7994914637588253, 0.7994919980357477, 0.7994919635169034, 0.7994919783989246, 0.7994924442963315, 0.7994924760921923, 0.7994975475741591, 0.7994968553464531, 0.7994924158190286, 0.7995033883635766, 0.7995874186667696, 0.7995922213416645, 0.7995920657340421, 0.7995120212393091, 0.799532122429424, 0.7996480198116998, 0.7995161602247408, 0.7995049011766833, 0.7995446754051769, 0.7995238902912795, 0.7995118386905979, 0.7999747239145131, 0.7995430376665893, 72.46759934214178, 57.11374931537364, 56.56324363588076, 48.6476588986255, 46.88613531539149, 39.80147178914137, 37.85662161664428, 16.159272030256965, 14.844353192002687, 12.835107189395238, 11.140018524856321, 9.337324957335793, 8.281529855476375, 7.746400219658706, 5.67222932527057, 4.236013501527677, 3.7222180258482487, 3.4893430328084403, 2.238214126701669, 0.799511087866844, 0.7994921671204734, 0.7994997096889943, 0.7995037979538644, 0.7994875748800977, 0.7994872536087099, 0.7994945140329627, 0.7994914364750114, 0.79950978138882, 0.799500968135485, 0.7994926550503146, 0.7995028947583938, 0.7995122643958904, 0.7996086587568543, 0.7995250192754754, 0.7995315089116147, 0.7995217973931303, 0.7995922213416645, 0.7996480198116998, 0.7995477791846388, 0.799617404972402, 0.7996156978207362, 0.7995611223673544, 0.799605883936822, 0.7999747239145131, 95.73509203825043, 84.23640505948002, 38.824287836246384, 31.873403925390775, 22.535160868535332, 20.301216330312897, 19.50887031965372, 19.08762046372603, 12.970102842318575, 9.146755774343184, 8.205691028615135, 2.987257770516775, 0.7995520809094179, 0.7994930474181438, 0.79950472794437, 0.799494668250235, 0.7994914105514501, 0.7994976863218933, 0.7995113054150828, 0.7994963932365213, 0.7994902243438946, 0.7994946595445359, 0.7994987350230636, 0.7994881787943806, 0.7995385943265174, 0.7994879406205906, 0.7994879406205906, 0.7994879599015798, 0.799488154862291, 0.7994923963777818, 0.7995091645123125, 0.7995315089116147, 0.7994962199849146, 0.7995120114541344, 0.7995266639817741, 0.799515708807204, 0.7995284848857387, 0.799617404972402, 0.7999747239145131, 117.48698325681177, 41.57923146732088, 31.93202840830791, 30.993228030331167, 22.346237375923806, 15.472879932876024, 10.91506907767642, 7.187103443943586, 6.847122711185253, 1.482709507348094, 1.387496616151896, 0.7995159891544155, 0.7994932573234184, 0.7994891301780831, 0.7994894806739477, 0.7994895790616136, 0.7995058930505349, 0.7994902909068693, 0.799500570856443, 0.7994916468497725, 0.7994917043651105, 0.7994909350499751, 0.7994938641285017, 0.7994941290177464, 0.7994955371222303, 0.7994916704087995, 0.799499474086787, 0.7995275997675473, 0.799503408243695, 0.7995063550438035, 0.7995270204588714, 0.7999747239145131, 0.7995271438485537, 0.7995163782747982, 0.799617404972402, 0.7995046781107361, 43.078965745801085, 32.697138464586, 19.638251236877213, 12.84238006584599, 12.492201539816486, 8.715925345545678, 5.837777570722486, 5.496698110190293, 2.354336546619412, 0.9456601628269705, 0.7994946595445359, 0.7994872327847948, 0.7994978420952856, 0.799501136221235, 0.7995072293931398, 0.7994915512526064, 0.799492666424208, 0.7995060671614641, 0.7994940643901646, 0.799511214850017, 0.799487071639353, 0.7995146541442725, 0.7994976863218933, 0.7994923963777818, 0.7994947349272028, 0.7994917834057182, 0.7994879256488302, 0.7994859812346998, 0.7995030443517754, 0.7994949169825366, 0.7994986259958954, 0.7995572362369737, 0.7995023701134442, 0.7995284848857387, 0.7995628957660418, 0.7995520809094179, 0.799617404972402, 0.799605883936822, 0.799518723039798, 1.9066500969261135, 0.7995052078292685, 0.7994862451232964, 0.7994853432796541, 0.7994853432796541, 0.7994853432796541, 0.7994853432796541, 0.7994853432796541, 0.7994854425519482, 0.7994867665277303, 0.7994868506375563, 0.7994868934799307, 0.799487459788077, 0.7994874417933653, 0.7994928940950708, 0.7994890028214992, 0.7994898499038203, 0.7994909648451879, 0.7994911517948112, 0.7994915739097245, 0.7995109078943988, 0.7994854926957494, 0.7994854926957494, 0.7994856043224311, 0.7994856185726051, 0.7994969334440994, 0.7994859208246654, 0.7994859208246654, 0.7994975235735733, 0.7994861864704095, 0.7995074408659163, 0.7995026294631173, 0.7994976863218933, 0.799504389257004, 0.799505729716888, 0.7994965406337842, 0.7995520809094179, 0.7995315089116147, 0.7999747239145131, 1.3212923347413679, 0.7994852506756224, 0.7994856320021309, 0.7994860783770563, 0.7994866319791566, 0.7994877078116036, 0.7994878930411085, 0.7994887120638957, 0.799489899582412, 0.7994899635894369, 0.7994911679863975, 0.79949090908079, 0.7994917270449695, 0.799491747002378, 0.7994918239541181, 0.7994895194035314, 0.7994895322554942, 0.7994851724826002, 0.7994884497191698, 0.7994863924645255, 0.799492467987081, 0.799486449581882, 0.7994866345427193, 0.7994849962299703, 0.799486880209072, 0.7994954739698431, 0.7994870674608731, 0.7994870929917559, 0.7994871676220263, 0.7994849130389489, 0.7994978644145703, 0.7994914842063847, 0.7995141064787198, 0.7995430376665893, 0.7995352171285653, 0.7994973142183242, 0.799605883936822, 0.7995077963721265, 0.7994900111462098, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 0.7994847431223892, 135.20778812494336, 234.85358761740102, 41.270260868828224, 348.62509287621634, 677.3187106543796, 296.7408444856887, 350.9629929372651, 1124.5849986254589, 307.1833548673632, 399.0734048130219, 2172.639863684544, 399.8657064758419, 7.695206483101808, 0.7994848177093011, 486.12429663345716, 834.4934434790621, 0.799485019200926, 259.32348961031335, 588.0266185634848, 52.458652320569904, 0.7994848938881921, 1141.340779963394, 1230.3532490464945, 10442.511154665634, 1700.2540349720227, 922.1932531894724, 4808.037491879278, 2290.7426560415815, 161.6624967586089], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.0381, -3.5966, -4.4157, -4.4387, -4.4555, -4.4953, -4.5085, -4.6434, -4.7537, -4.7691, -4.8306, -4.8781, -4.9053, -5.0413, -5.0758, -5.0774, -5.0856, -5.156, -5.2149, -5.2228, -5.2292, -5.24, -5.3545, -5.3659, -5.3734, -5.4659, -5.5157, -5.5471, -5.5605, -5.6566, -4.1362, -5.0657, -5.1061, -2.9905, -4.0924, -5.0628, -5.1822, -4.9457, -4.07, -4.4085, -4.9428, -4.5296, -5.1031, -4.8773, -3.1102, -3.6909, -4.2866, -4.7724, -4.8228, -4.8627, -4.9145, -4.9412, -4.9556, -5.0047, -5.1015, -5.1126, -5.191, -5.2311, -5.2393, -5.3293, -5.3409, -5.3682, -5.3971, -5.4567, -5.4627, -5.4664, -5.5233, -5.5486, -5.5854, -5.5918, -5.6018, -5.623, -5.6319, -5.6508, -3.6191, -4.5842, -4.6716, -4.1357, -4.9295, -3.7054, -5.0236, -5.3176, -4.8783, -3.7299, -4.2672, -4.3675, -4.5561, -4.6945, -4.5744, -4.4567, -4.8, -3.5518, -4.8659, -4.4617, -4.1987, -4.7898, -4.3409, -4.6458, -4.5366, -4.9054, -2.8276, -3.2396, -3.2408, -3.3056, -3.3858, -3.5361, -3.8445, -4.0762, -4.1647, -4.1771, -4.2048, -4.282, -4.3086, -4.413, -4.478, -4.5318, -4.5697, -4.5891, -4.5988, -4.6015, -4.7108, -4.7865, -4.7872, -4.8128, -4.8214, -4.8267, -4.9473, -4.9847, -4.9911, -5.0387, -2.5974, -4.4951, -2.8421, -4.449, -4.3485, -3.94, -4.0076, -4.4896, -4.4114, -4.6497, -2.4431, -3.3607, -3.7375, -3.7865, -3.8284, -3.8602, -3.8863, -3.9063, -3.9625, -4.1117, -4.1896, -4.2352, -4.3362, -4.5007, -4.5174, -4.5213, -4.686, -4.7239, -4.7834, -4.8088, -4.8344, -4.951, -4.1682, -5.1328, -5.1761, -5.2581, -5.3145, -5.3267, -5.4834, -5.5542, -3.9261, -4.8702, -3.1331, -4.4024, -3.8826, -4.0991, -4.0964, -4.0521, -4.2198, -4.7067, -4.7612, -4.7297, -4.7564, -2.5432, -2.9058, -3.189, -3.2401, -3.4438, -3.5851, -3.7135, -3.8199, -3.961, -3.9671, -3.9774, -4.0313, -4.0971, -4.1136, -4.1146, -4.1765, -4.1784, -4.1901, -4.253, -4.2836, -4.3626, -4.3654, -4.3711, -4.4786, -4.4933, -4.5069, -4.5557, -4.5733, -4.638, -4.6755, -3.5217, -3.47, -4.1371, -3.8952, -4.4076, -4.3911, -1.4612, -2.378, -2.6772, -2.7032, -3.1343, -3.4617, -3.4815, -3.9294, -3.9933, -4.2065, -4.2169, -4.5026, -4.5431, -4.7877, -4.8289, -4.8291, -4.8366, -4.8694, -4.8731, -5.1119, -5.3141, -5.3963, -5.3979, -5.4151, -5.6288, -5.6314, -5.6352, -5.6374, -5.7497, -5.7556, -3.0213, -3.8329, -4.9386, -4.8006, -1.291, -1.8665, -2.2996, -2.7651, -3.1103, -3.3968, -3.8162, -4.046, -4.4974, -4.6051, -4.8206, -5.409, -5.5366, -5.6957, -5.9769, -6.3842, -4.2577, -3.5381, -10.8928, -10.8929, -10.8929, -10.8929, -10.893, -10.893, -10.8929, -10.893, -10.8929, -10.893, -10.8929, -10.893, -10.8929, -10.893, -10.8929, -10.8929, -10.8929, -10.8928, -2.6471, -2.8583, -2.8782, -2.9941, -3.1276, -3.1709, -3.2401, -3.3288, -3.5196, -3.5408, -3.7515, -3.8608, -3.8842, -4.0518, -4.0707, -4.0884, -4.1226, -4.2788, -4.3945, -4.3954, -4.4095, -4.4303, -4.6648, -4.7826, -4.8187, -4.9901, -5.0088, -5.0779, -5.0802, -5.1337, -4.2255, -4.1108, -4.7205, -1.544, -2.8084, -2.9449, -3.0289, -3.1047, -3.2866, -3.388, -3.4263, -3.795, -3.887, -4.0218, -4.1337, -4.351, -4.5018, -4.7602, -5.0645, -5.1578, -3.0719, -7.0471, -10.4838, -10.4838, -10.484, -10.484, -10.484, -10.484, -10.484, -10.484, -10.484, -10.484, -10.484, -5.2336, -10.484, -10.4839, -10.484, -1.5539, -2.5866, -2.8229, -3.286, -3.2989, -3.347, -3.6913, -3.7039, -3.8569, -3.8952, -3.9559, -4.0793, -4.1549, -4.2459, -4.5963, -5.2136, -6.1167, -7.9344, -2.773, -10.5085, -10.5085, -10.5086, -10.5085, -10.5086, -10.5086, -10.5086, -10.5086, -10.5086, -10.5086, -10.5087, -4.4706, -10.5085, -10.5086, -10.5086, -10.5085, -10.5086, -10.4914, -1.5835, -2.1433, -2.2638, -2.3683, -2.8748, -4.5989, -5.5937, -7.0732, -10.1836, -10.1842, -10.1842, -10.1842, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -10.1842, -10.1843, -10.1843, -10.1842, -10.1843, -10.1843, -10.1843, -10.1843, -10.1843, -1.4366, -1.4482, -3.6124, -4.1228, -4.3664, -10.0419, -10.042, -10.042, -10.042, -10.042, -10.0421, -10.0421, -10.0421, -10.0421, -10.0421, -10.0421, -10.0421, -10.0421, -10.0421, -10.0421, -10.0421, -10.0421, -10.0421, -10.0421, -10.0421, -10.0422, -10.0422, -10.0422, -10.0422, -10.0422, -10.0417, -10.0421, -10.0422, -10.0422, -10.0422, -1.1764, -2.0731, -2.5427, -3.8551, -4.1867, -4.3447, -5.1061, -5.844, -10.1362, -10.1363, -10.1363, -10.1363, -10.1362, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1363, -10.1363, -10.1363, -10.1364, -10.1364, -10.1363, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -10.1364, -2.4553, -2.6963, -2.7061, -2.8591, -2.8965, -3.0633, -3.1144, -3.9937, -4.083, -4.237, -4.3883, -4.5791, -4.7105, -4.7844, -5.1368, -5.4829, -5.643, -5.725, -6.3393, -10.0484, -10.0484, -10.0484, -10.0484, -10.0485, -10.0485, -10.0484, -10.0484, -10.0484, -10.0484, -10.0485, -10.0484, -10.0484, -10.0483, -10.0484, -10.0484, -10.0484, -10.0484, -10.0484, -10.0484, -10.0484, -10.0484, -10.0484, -10.0484, -10.0484, -2.113, -2.2421, -3.0274, -3.229, -3.5859, -3.6941, -3.7355, -3.7582, -4.1644, -4.54, -4.659, -5.8658, -9.8933, -9.8936, -9.8935, -9.8936, -9.8936, -9.8936, -9.8936, -9.8936, -9.8936, -9.8936, -9.8936, -9.8936, -9.8935, -9.8936, -9.8936, -9.8936, -9.8936, -9.8936, -9.8936, -9.8936, -9.8936, -9.8936, -9.8936, -9.8936, -9.8936, -9.8936, -9.8935, -1.6669, -2.7177, -2.9874, -3.018, -3.355, -3.7385, -4.1095, -4.5674, -4.6218, -6.7628, -6.9058, -9.8901, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8904, -9.8901, -9.8904, -9.8904, -9.8904, -9.8904, -2.321, -2.6025, -3.1285, -3.5752, -3.6046, -3.9935, -4.4435, -4.5132, -5.6072, -7.8182, -9.6701, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6702, -9.6701, -9.6702, -9.6702, -9.6702, -9.6702, -9.6701, -9.6702, -9.6702, -3.6209, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3177, -9.3177, -9.3177, -9.3177, -9.3176, -9.3177, -9.3177, -9.3176, -9.3177, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -9.3176, -4.3329, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3038, -9.3037, -9.3038, -9.3037, -9.3038, -9.3038, -9.3038, -9.3038, -9.3037, -9.3038, -9.3038, -9.3038, -9.3038, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3037, -9.3038, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906, -9.2906], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.4234, 0.4233, 0.4231, 0.4231, 0.4231, 0.4231, 0.4231, 0.4231, 0.423, 0.423, 0.423, 0.423, 0.423, 0.4229, 0.4229, 0.4229, 0.4229, 0.4228, 0.4228, 0.4228, 0.4228, 0.4228, 0.4227, 0.4227, 0.4227, 0.4226, 0.4225, 0.4225, 0.4225, 0.4224, 0.4171, 0.4194, 0.4144, 0.3712, 0.3925, 0.4061, 0.4008, 0.3333, 0.0672, 0.1529, 0.3248, 0.1578, 0.339, 0.119, 1.8029, 1.8026, 1.8021, 1.8015, 1.8014, 1.8013, 1.8012, 1.8011, 1.8011, 1.801, 1.8008, 1.8008, 1.8006, 1.8004, 1.8004, 1.8002, 1.8001, 1.8, 1.7999, 1.7997, 1.7997, 1.7997, 1.7995, 1.7994, 1.7993, 1.7992, 1.7992, 1.7991, 1.7991, 1.799, 1.7954, 1.7917, 1.7648, 1.7385, 1.762, 1.6728, 1.7476, 1.7696, 1.6983, 1.4405, 1.5318, 1.5255, 1.5755, 1.6111, 1.5172, 1.3615, 1.5126, 0.5854, 1.5114, 0.94, 0.3628, 1.3123, 0.3466, 0.3505, -1.175, 1.0193, 2.9873, 2.9868, 2.9868, 2.9868, 2.9866, 2.9864, 2.9858, 2.9852, 2.9849, 2.9849, 2.9848, 2.9846, 2.9845, 2.9841, 2.9838, 2.9836, 2.9834, 2.9833, 2.9832, 2.9832, 2.9827, 2.9823, 2.9822, 2.9821, 2.982, 2.982, 2.9812, 2.981, 2.9809, 2.9806, 2.9779, 2.9779, 2.775, 2.9323, 2.8874, 2.4592, 1.9836, 2.1811, 1.7723, 0.6179, 3.0959, 3.095, 3.0942, 3.0941, 3.094, 3.0939, 3.0939, 3.0938, 3.0937, 3.0932, 3.0929, 3.0928, 3.0924, 3.0916, 3.0916, 3.0915, 3.0907, 3.0904, 3.0901, 3.0899, 3.0897, 3.0889, 3.0882, 3.0874, 3.087, 3.0862, 3.0856, 3.0854, 3.0836, 3.0826, 3.076, 3.0814, 2.9002, 2.8803, 2.6178, 2.6347, 2.2986, 1.6477, 1.3703, 2.5748, 2.6849, 2.353, 2.6205, 3.6358, 3.6353, 3.6347, 3.6346, 3.6341, 3.6333, 3.6332, 3.6328, 3.6321, 3.6321, 3.632, 3.6318, 3.6314, 3.6313, 3.6313, 3.6309, 3.6309, 3.6309, 3.6305, 3.6303, 3.6297, 3.6297, 3.6296, 3.6288, 3.6287, 3.6286, 3.6282, 3.628, 3.6274, 3.627, 3.5797, 3.1736, 3.3357, 2.1964, 2.9662, 2.7162, 4.3445, 4.3433, 4.3426, 4.3425, 4.341, 4.3393, 4.3391, 4.3357, 4.335, 4.3326, 4.3324, 4.3282, 4.3275, 4.3226, 4.3217, 4.3217, 4.3215, 4.3207, 4.3206, 4.3141, 4.3072, 4.304, 4.3039, 4.3032, 4.2935, 4.2933, 4.2931, 4.293, 4.287, 4.2866, 3.6792, 2.4866, 3.4062, 1.9653, 4.7149, 4.7141, 4.7131, 4.7115, 4.7097, 4.7076, 4.7033, 4.7001, 4.6912, 4.6885, 4.682, 4.6556, 4.6477, 4.6364, 4.6119, 4.5634, 4.047, 3.1069, 1.9461, 1.9461, 1.9461, 1.9461, 1.9461, 1.9461, 1.9461, 1.9461, 1.9461, 1.9461, 1.9461, 1.9461, 1.946, 1.946, 1.946, 1.946, 1.946, 1.9456, 4.7933, 4.7923, 4.7922, 4.7916, 4.7907, 4.7904, 4.7899, 4.7892, 4.7875, 4.7872, 4.7848, 4.7834, 4.783, 4.7804, 4.7801, 4.7798, 4.7792, 4.7761, 4.7735, 4.7735, 4.7731, 4.7726, 4.7661, 4.7623, 4.761, 4.7543, 4.7535, 4.7504, 4.7503, 4.7478, 3.6369, 3.4663, 3.5966, 5.173, 5.1678, 5.1667, 5.166, 5.1653, 5.1633, 5.1621, 5.1616, 5.1556, 5.1538, 5.1507, 5.1479, 5.1414, 5.136, 5.1248, 5.1075, 5.1011, 4.7904, 4.7646, 2.3552, 2.3552, 2.3551, 2.355, 2.355, 2.355, 2.355, 2.355, 2.355, 2.355, 2.355, 1.8995, 2.3549, 2.3546, 2.3549, 5.4092, 5.4043, 5.4024, 5.3968, 5.3966, 5.3959, 5.3894, 5.3891, 5.3854, 5.3843, 5.3826, 5.3789, 5.3763, 5.373, 5.3571, 5.3127, 5.1829, 4.4624, 4.0871, 2.3306, 2.3305, 2.3305, 2.3304, 2.3304, 2.3304, 2.3304, 2.3304, 2.3304, 2.3304, 2.3304, 1.9225, 2.3303, 2.3303, 2.3303, 2.3299, 2.3303, -5.0494, 5.7739, 5.771, 5.7701, 5.7692, 5.7635, 5.6996, 5.5788, 5.1011, 2.6549, 2.6549, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6548, 2.6547, 2.6547, 2.6547, 2.6546, 2.6547, 2.6547, 2.6547, 2.6547, 2.6547, 5.7952, 5.7952, 5.7683, 5.7486, 5.7352, 2.7971, 2.797, 2.797, 2.797, 2.797, 2.797, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7969, 2.7967, 2.7968, 2.7968, 2.7969, 2.7968, 5.8417, 5.8376, 5.8335, 5.8039, 5.7884, 5.7791, 5.7093, 5.58, 2.7029, 2.7028, 2.7028, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7027, 2.7026, 2.7026, 2.7026, 2.7027, 2.7026, 2.7025, 2.7026, 2.7027, 2.7026, 2.7026, 2.7026, 2.7021, 2.7026, 5.8768, 5.874, 5.8738, 5.8716, 5.871, 5.8681, 5.8671, 5.839, 5.8346, 5.8261, 5.8164, 5.8021, 5.7907, 5.7837, 5.7429, 5.6887, 5.6579, 5.6405, 5.4703, 2.7906, 2.7906, 2.7906, 2.7906, 2.7906, 2.7906, 2.7906, 2.7906, 2.7906, 2.7906, 2.7906, 2.7906, 2.7906, 2.7906, 2.7906, 2.7906, 2.7906, 2.7905, 2.7905, 2.7906, 2.7905, 2.7905, 2.7906, 2.7905, 2.7901, 5.9407, 5.9396, 5.9289, 5.9245, 5.9143, 5.9105, 5.9089, 5.908, 5.8883, 5.8619, 5.8515, 5.6551, 2.9456, 2.9455, 2.9455, 2.9455, 2.9455, 2.9455, 2.9455, 2.9455, 2.9455, 2.9455, 2.9455, 2.9455, 2.9455, 2.9455, 2.9455, 2.9455, 2.9455, 2.9455, 2.9455, 2.9454, 2.9455, 2.9454, 2.9454, 2.9454, 2.9454, 2.9453, 2.9449, 6.182, 6.17, 6.1642, 6.1635, 6.1536, 6.1377, 6.1156, 6.0756, 6.0696, 5.4586, 5.382, 2.9489, 2.9487, 2.9487, 2.9487, 2.9487, 2.9487, 2.9487, 2.9487, 2.9487, 2.9487, 2.9487, 2.9486, 2.9486, 2.9486, 2.9486, 2.9486, 2.9486, 2.9486, 2.9486, 2.9486, 2.9483, 2.9486, 2.9486, 2.9485, 2.9486, 6.5313, 6.5255, 6.5093, 6.4874, 6.4856, 6.4566, 6.4075, 6.398, 6.1518, 4.853, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1689, 3.1688, 3.1688, 3.1688, 3.1687, 3.1688, 3.1688, 8.349, 3.5215, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5214, 3.5208, 8.0038, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5353, 3.5352, 3.5353, 3.5353, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, 3.5484, -1.5822, -2.1343, -0.3955, -2.5293, -3.1935, -2.3682, -2.536, -3.7005, -2.4028, -2.6645, -4.3591, -2.6665, 1.2841, 3.5484, -2.8618, -3.4022, 3.5484, -2.2334, -3.0521, -0.6354, 3.5484, -3.7153, -3.7904, -5.929, -4.1139, -3.5021, -5.1534, -4.412, -1.7609]}, \"token.table\": {\"Topic\": [1, 3, 5, 8, 1, 2, 3, 4, 5, 2, 1, 3, 4, 15, 1, 2, 3, 1, 2, 8, 14, 4, 15, 1, 1, 2, 4, 1, 2, 4, 1, 6, 6, 7, 1, 2, 4, 2, 1, 4, 5, 1, 2, 4, 2, 7, 9, 6, 2, 16, 1, 2, 3, 9, 8, 6, 15, 1, 2, 14, 16, 13, 8, 1, 4, 8, 11, 2, 10, 14, 10, 5, 1, 7, 17, 5, 14, 7, 1, 4, 3, 1, 10, 1, 2, 3, 1, 2, 5, 3, 4, 5, 1, 2, 5, 17, 5, 13, 10, 5, 2, 1, 2, 2, 15, 8, 10, 7, 14, 1, 4, 15, 15, 4, 1, 1, 8, 14, 2, 1, 3, 5, 2, 2, 1, 2, 9, 1, 2, 1, 2, 4, 2, 9, 1, 2, 4, 1, 14, 4, 4, 9, 4, 5, 3, 6, 1, 10, 1, 3, 3, 7, 1, 2, 3, 3, 9, 1, 2, 6, 6, 14, 10, 6, 3, 6, 17, 1, 1, 10, 1, 13, 13, 3, 6, 2, 8, 1, 2, 1, 10, 8, 7, 1, 2, 1, 4, 5, 1, 4, 3, 2, 17, 9, 1, 2, 15, 14, 5, 4, 11, 2, 9, 9, 6, 19, 1, 2, 3, 3, 3, 14, 1, 2, 3, 8, 15, 3, 4, 3, 5, 6, 5, 2, 3, 6, 3, 11, 3, 1, 4, 2, 9, 8, 1, 8, 17, 14, 15, 16, 1, 2, 1, 2, 3, 3, 8, 2, 3, 1, 1, 2, 3, 4, 8, 8, 1, 2, 1, 8, 5, 1, 3, 1, 15, 4, 1, 2, 8, 1, 2, 14, 14, 1, 4, 17, 3, 9, 9, 1, 2, 4, 4, 16, 5, 1, 1, 8, 8, 2, 8, 1, 2, 9, 11, 1, 11, 5, 1, 10, 10, 6, 6, 12, 12, 5, 1, 2, 3, 4, 9, 6, 3, 5, 1, 3, 2, 13, 1, 4, 10, 7, 5, 17, 4, 2, 5, 4, 7, 1, 2, 4, 5, 18, 16, 5, 8, 2, 9, 1, 1, 4, 6, 2, 1, 17, 8, 1, 4, 3, 1, 8, 1, 2, 4, 16, 4, 3, 5, 3, 2, 3, 1, 2, 4, 6, 5, 5, 1, 4, 2, 6, 1, 10, 12, 7, 13, 11, 12, 7, 1, 7, 6, 16, 4, 16, 16, 6, 4, 4, 1, 6, 4, 9, 15, 2, 3, 10, 6, 5, 14, 1, 2, 1, 2, 10, 2, 4, 3, 8, 1, 12, 4, 16, 14, 8, 6, 2, 8, 4, 4, 1, 2, 6, 3, 2, 1, 2, 3, 16, 1, 8, 1, 5, 5, 4, 2, 1, 5, 6, 6, 6, 17, 1, 15, 14, 5, 13, 2, 3, 5, 5, 1, 4, 3, 6, 4, 2, 9, 4, 2, 5, 14, 14, 3, 6, 2, 6, 1, 4, 4, 8, 11, 9, 1, 2, 14, 10, 10, 2, 4, 3, 1, 1, 1, 2, 10, 8, 6, 1, 2, 11, 8, 5, 8, 4, 8, 2, 1, 2, 2, 8, 9, 3, 6, 7, 13, 7, 1, 7, 10, 3, 6, 9, 2, 7, 6, 7, 7, 1, 2, 1, 2, 1, 4], \"Freq\": [0.40937497064967665, 0.5891005675202664, 0.9898949230273908, 0.9261863157781274, 0.9997366767902546, 0.05332415111876534, 0.9438374748021465, 0.2570937247076433, 0.7420659781334249, 0.9954578042763556, 0.9910671704515478, 0.9940613039600243, 0.9968540537944389, 0.9762521833477324, 0.09538687034813367, 0.9014059247898631, 0.004769343517406683, 0.9959031400950691, 0.003202260900627232, 0.974560875975621, 0.9935474702296387, 0.9870240025737197, 0.9851626461482934, 0.9963654478261937, 0.23669445826791738, 0.7626821433077338, 0.9934514378358981, 0.5277875969339116, 0.31839360467208805, 0.15489418605669147, 0.9048563597328103, 0.09221466086449022, 0.9955092579216691, 0.9958401178488566, 0.4683668074396795, 0.29570616232420444, 0.23517570627797466, 0.9960253189181034, 0.9995294524581024, 0.9975033956414975, 0.9928137396118565, 0.9996556506403651, 0.1932605774160329, 0.8068629107119374, 0.4833238305926073, 0.5101751545144189, 0.9810225895282522, 0.9975995532841889, 0.9984871444634603, 0.6744409441257, 0.7665826929429894, 0.23293152381993, 0.9967267109142126, 0.9988337031506367, 0.9894977811378538, 0.9757027176752175, 0.9252046915809068, 0.3704094238312972, 0.6268467172529646, 0.9431195700424605, 0.9845057863612937, 0.9950068836975908, 0.924118692837593, 0.8216364268858051, 0.17784338244281495, 0.9982167335237524, 0.9882066263036466, 0.995116452770482, 0.9612793137859837, 0.8059710578926489, 0.992271806531301, 0.9953493308416135, 0.9996484219007603, 0.9363497164937448, 0.8494962212907907, 0.9983212805807714, 0.9773719476259959, 0.9819986622228035, 0.018247970442912452, 0.9780912157401074, 0.9933816204354006, 0.9983896526976106, 0.9815341441328881, 0.005350119687281694, 0.960346483867064, 0.03210071812369016, 0.10091692635294415, 0.8952307982922464, 0.9874764218151986, 0.997494866912778, 0.9951694670504132, 0.9981429803623244, 0.37049090210154806, 0.11643999780334369, 0.5133945357692881, 0.9674995889817986, 0.9899354142237, 0.9975455086534752, 0.9608897272325273, 0.9922115108109836, 0.9977331481424407, 0.7216717439112156, 0.2756385132994226, 0.9993183930137874, 0.8746270478151549, 0.9744295585331859, 0.9493805761821053, 0.967428766183848, 0.9798632625098044, 0.5488582128651095, 0.4494273772011404, 0.9853222005544161, 0.6695103515134597, 0.9975951112315887, 0.9997852061059639, 0.9997054902217164, 0.9876020613027147, 0.44678477723382265, 0.9953712077518505, 0.9774197013014371, 0.022073615657214028, 0.9941333765925371, 0.9978350069490288, 0.9965720734397348, 0.1727659927719467, 0.8256395865101454, 0.986388447510866, 0.38724284936309666, 0.6127635892220649, 0.0753481796076323, 0.29302069847412565, 0.6306921700490704, 0.9993355065105898, 0.9732430388222638, 0.9912125471982836, 0.008294665666931243, 0.9950779802333833, 0.9096572022299287, 0.708213040142124, 0.998650231561598, 0.986594812938365, 0.9675109828173333, 0.9808811041145159, 0.00943154907802419, 0.9940366134070687, 0.9763505095031517, 0.9996985373263869, 0.8666694436040738, 0.9976872239440752, 0.9914749871110116, 0.9890470313378699, 0.9985883753357785, 0.3170046214927543, 0.23316868853599285, 0.4453783938327953, 0.9938259079561391, 0.9961541022208162, 0.8335522435728634, 0.00922071065899185, 0.15675208120286147, 0.9888098056023586, 0.9804994536565323, 0.996774329736809, 0.9474942651741756, 0.9981778549681366, 0.9987666293890198, 0.9096370038460967, 0.9994086910054022, 0.9991863880981278, 0.9908703238016197, 0.9992542019037349, 0.9275265764294824, 0.9958880589322484, 0.9921832395935343, 0.9498459400631469, 0.9979867832310689, 0.9894709233991917, 0.2509009538452892, 0.7472086800648029, 0.96866835521752, 0.029774642066112297, 0.9907361363812236, 0.9434157966430005, 0.5430029604445973, 0.456023081197179, 0.1772897495193541, 0.8213501676951327, 0.9913386713176747, 0.6362709380779439, 0.3624816253292529, 0.9992342450312969, 0.9988750453078656, 0.8564903234881553, 0.962849636308134, 0.24196410286916523, 0.7571911477846016, 0.9739159514971468, 0.8976645754840856, 0.9960222835522329, 0.9972333235715247, 0.88733325230378, 0.9958486351215073, 0.995581762786313, 0.9935396752383172, 0.9532395935677209, 0.7568347849348129, 0.03653851145861844, 0.15437521091266287, 0.8084145660219328, 0.9997102428557327, 0.9977483993562832, 0.9866867406718353, 0.5475942582099896, 0.4506598708871033, 0.998843484509401, 0.9690165478489344, 0.9923216030548472, 0.9985016776395582, 0.9912568794606632, 0.9976547408311596, 0.9972004898744897, 0.9382304087961529, 0.9981327570642503, 0.009637787585538475, 0.9900636337871344, 0.9935844318589021, 0.9905125136179264, 0.990377669606736, 0.9993494588253024, 0.5221947988678411, 0.47472254442531014, 0.9942421189015416, 0.9912644034900836, 0.980470850175971, 0.9997128881101681, 0.9905883210986501, 0.9605992956287418, 0.9349357058673239, 0.8530664846616071, 0.9679533855150824, 0.30391698896104236, 0.6960867958703875, 0.582791233814673, 0.1207440401549737, 0.2962253785135355, 0.9983608936440143, 0.9956120702566507, 0.09220519623874132, 0.903610923139665, 0.9988039745963234, 0.9186997909151007, 0.0023005837835937413, 0.01610408648515619, 0.06211576215703101, 0.9665042110470765, 0.9522784591538586, 0.9490054502429034, 0.05084983794944316, 0.9998505899902029, 0.9816331083326714, 0.9988897575439859, 0.9062668316957424, 0.09339636858271687, 0.9991658805658534, 0.9725977204243627, 0.9983835855181773, 0.3563026232940549, 0.6433552069510207, 0.9756348647622037, 0.03730762855448438, 0.9617077582933751, 0.9282596376813065, 0.9811002696334283, 0.004706182825786693, 0.9930045762409923, 0.9786789151184877, 0.9949282964904935, 0.9801604836797977, 0.9779916249650574, 0.10698161220790404, 0.7962488565759716, 0.09628345098711365, 0.9890670882086593, 0.8762804835085811, 0.9949289567233311, 0.998706070354185, 0.7328596806853465, 0.2659048398946832, 0.9803267853023688, 0.9973929639887363, 0.990468688568165, 0.8487060871046437, 0.11232874682267342, 0.03744291560755781, 0.9944069336265081, 0.9997011315391914, 0.9933291660350327, 0.9931890504687756, 0.9999296442181657, 0.9917894020648679, 0.9745426083688554, 0.9105446593578996, 0.9929181310614164, 0.9844996216927663, 0.9716254783418534, 0.9964559512247119, 0.7002857206681158, 0.2959627503744368, 0.003535746139399456, 0.00020798506702349742, 0.9686695878303044, 0.9516871825502532, 0.9980558644544364, 0.9961599658502659, 0.6334698645466524, 0.366536022253409, 0.9989710551385254, 0.9115105459344985, 0.3769228919307432, 0.6211264557168585, 0.9780147939264011, 0.9176022746523111, 0.9919976865061007, 0.9749537685707728, 0.9895348637542309, 0.05239556266571496, 0.9431201279828693, 0.9916683966038053, 0.9785737428646241, 0.7375735253445455, 0.23374500536884396, 0.027990473331983415, 0.9906938503744295, 0.5244800824294884, 0.9958550024580402, 0.9945425647550115, 0.988924475958005, 0.9978557228598246, 0.947638344633782, 0.9994153144938144, 0.999675801190665, 0.9948117377057062, 0.9798548651606359, 0.9936198847267128, 0.9959019762041772, 0.9178600874648891, 0.9609519654117181, 0.3778946137901738, 0.6187748062061326, 0.9918665377678542, 0.9992076363336332, 0.9944055426120465, 0.5384259061588973, 0.42204930811087293, 0.039774280345527296, 0.8348286687116028, 0.9929772502851847, 0.994778964863554, 0.9939492429775859, 0.9972467786065653, 0.9922520502826051, 0.007460541731448158, 0.969705960228301, 0.008539773108600282, 0.021791145173669684, 0.9770784805697802, 0.9967690344775035, 0.9965939697938224, 0.4053926169589905, 0.5936106176899504, 0.9979237380972907, 0.984354342439872, 0.9997903819478744, 0.9920400612895431, 0.9648209665878648, 0.9971337901599464, 0.826659195039553, 0.6434145669256599, 0.996451428978963, 0.9983697849095265, 0.7992602431630272, 0.19917667401506747, 0.9930835665069759, 0.9708121138942297, 0.994721229651541, 0.9860692117944477, 0.969438143711613, 0.9771859259058816, 0.9994504092936003, 0.9910454101604453, 0.4831777331182582, 0.5128702195110003, 0.9947432693533835, 0.9556400618612135, 0.9430195887542433, 0.7092549816371378, 0.022164218176160558, 0.2659706181139267, 0.9897150812475765, 0.9960340362924054, 0.9638734906542181, 0.052147922110991285, 0.9473539183496751, 0.9140453270568918, 0.08599713697185296, 0.9774478993502791, 0.997468911557897, 0.9995417668062029, 0.9982296446755399, 0.9629922368930547, 0.9997545434363245, 0.9987767593182488, 0.9979622452992158, 0.9161646095719241, 0.8597606975847867, 0.9914221310947611, 0.9945525122901095, 0.9986158617534404, 0.9867390500178415, 0.9977106075129085, 0.9943609997817926, 0.031790942532565584, 0.9656498794266797, 0.9156493569068515, 0.995205351963737, 0.9994943236269704, 0.12158394017162599, 0.8777065503513829, 0.9978235150269843, 0.7207224784255079, 0.6933016928447038, 0.2990713184820291, 0.9989783624923549, 0.9984415754479944, 0.9960117559016238, 0.9976957369762848, 0.994291242920927, 0.3697646071130467, 0.6298748824615348, 0.9957820676478935, 0.9994964624960365, 0.976983523121438, 0.9344062345510019, 0.9996335184696934, 0.9787687583678785, 0.9036455387672196, 0.9956172323657195, 0.9107184230824515, 0.75174550546603, 0.01174602352290672, 0.23638872339849773, 0.9951588717831974, 0.9830251938891064, 0.016541289320249387, 0.9958644519101566, 0.9979164416684067, 0.9916505266003915, 0.9975291662332468, 0.4477454288551648, 0.9961133154352851, 0.6000555926269773, 0.39733410863137686, 0.9660050907997142, 0.9900422323813929, 0.6009744872463578, 0.39133222425344233, 0.9994839912736299, 0.9916074124963328, 0.9999539681974682, 0.9918682944577495, 0.9959589191093106, 0.9784045281890702, 0.9933677174422931, 0.9952297007660432, 0.9935809420345318, 0.005991125959586196, 0.8814876326886688, 0.9599614663927879, 0.9786227327469019, 0.9892164212918312, 0.009755586008795178, 0.9954105264909463, 0.9997740478899269, 0.9997071569796578, 0.9988778938582065, 0.9961478142619765, 0.804835990735679, 0.9735580864980273, 0.9699218157784936, 0.25202982916433886, 0.7463208894633911, 0.708764462962688, 0.9839009916141511, 0.9862219507975764, 0.9968255455103752, 0.9943566293973903, 0.9958769982142186, 0.9951916687079171, 0.762901926214081, 0.2368174729289543, 0.9984895393190393, 0.31055240974221426, 0.6814900102676368, 0.9877573951006651, 0.005844718314205118, 0.922620344300986, 0.9362345776018832, 0.9889986954551426, 0.9997357884505514, 0.9811371828207257, 0.9797285713977799, 0.9941119372148951, 0.955230578165932, 0.9855730464377027, 0.9991293798251042, 0.9744907329894691, 0.9697257503524189, 0.9921932028113338, 0.9748925886981563, 0.06142963280296783, 0.9368019002452594, 0.9998151910136982, 0.9966738451692828, 0.33567170389962914, 0.6599647059721523], \"Term\": [\"ability\", \"ability\", \"abstract\", \"accept\", \"achieve\", \"action\", \"action\", \"adopt\", \"adopt\", \"advance\", \"advantage\", \"agent\", \"ai\", \"algorithmic\", \"allow\", \"allow\", \"allow\", \"also\", \"also\", \"alter\", \"alternative\", \"always\", \"ambiguous\", \"amount\", \"analysis\", \"analysis\", \"analytic\", \"analyze\", \"analyze\", \"analyze\", \"annotate\", \"annotate\", \"annotation\", \"answer\", \"application\", \"application\", \"application\", \"arabic\", \"architecture\", \"area\", \"argument\", \"art\", \"article\", \"article\", \"ask\", \"ask\", \"assumption\", \"automatic\", \"automatically\", \"axiom\", \"base\", \"base\", \"behavior\", \"bias\", \"bidirectional\", \"bleu_score\", \"bound\", \"build\", \"build\", \"careful\", \"carefully\", \"causal\", \"century\", \"challenge\", \"challenge\", \"change\", \"character\", \"characteristic\", \"chemical\", \"chess\", \"claim\", \"classical\", \"classification\", \"classifie\", \"cnl\", \"code\", \"coherent\", \"comment\", \"community\", \"community\", \"comparable\", \"compare\", \"complement\", \"complex\", \"complex\", \"complex\", \"component\", \"component\", \"compositional\", \"comprehension\", \"comprehensive\", \"computation\", \"computational\", \"computational\", \"computational\", \"computationally\", \"compute\", \"concept\", \"confidence\", \"constraint\", \"construct\", \"contain\", \"contain\", \"content\", \"context_free\", \"convey\", \"correctness\", \"crawl\", \"curate\", \"current\", \"current\", \"currently\", \"danish\", \"database\", \"dataset\", \"datum\", \"decrease\", \"deductive\", \"define\", \"demonstrate\", \"demonstrate\", \"dependency\", \"describe\", \"description\", \"design\", \"design\", \"determine\", \"develop\", \"develop\", \"development\", \"development\", \"development\", \"dialogue\", \"dictionary\", \"different\", \"different\", \"direction\", \"disadvantage\", \"discriminator\", \"discuss\", \"discussion\", \"distance\", \"distinct\", \"distinct\", \"distribution\", \"documentation\", \"domain\", \"drug_discovery\", \"due\", \"dynamic\", \"easily\", \"embedding\", \"enable\", \"enable\", \"enable\", \"encode\", \"encourage\", \"end\", \"end\", \"end\", \"engine\", \"engineering\", \"entity\", \"entry\", \"environment\", \"especially\", \"essentially\", \"evaluate\", \"evaluation\", \"event\", \"experiment\", \"experimentally\", \"explanation\", \"explicit\", \"exponential\", \"expression\", \"external\", \"extract\", \"extract\", \"extraction\", \"extraction\", \"fast\", \"fasttext\", \"feature\", \"feature\", \"field\", \"field\", \"final\", \"finally\", \"finally\", \"fine_tune\", \"form\", \"formalization\", \"formulation\", \"framework\", \"framework\", \"freely_available\", \"frequent\", \"function\", \"future\", \"fuzzy\", \"game\", \"gender\", \"gender_bia\", \"general_purpose\", \"generalise\", \"generate\", \"generate\", \"generate\", \"generation\", \"generative\", \"generic\", \"give\", \"give\", \"gpt\", \"gram\", \"grammar\", \"graph\", \"growth\", \"guide\", \"handle\", \"harness\", \"hierarchical\", \"human\", \"human\", \"hybrid\", \"hypothesis\", \"identification\", \"image\", \"impact\", \"impact\", \"implement\", \"implicit\", \"impose\", \"improve\", \"incremental\", \"incrementally\", \"indexing\", \"infinite\", \"informal\", \"information\", \"information\", \"input\", \"input\", \"input\", \"instruction\", \"intent\", \"interaction\", \"interaction\", \"introduce\", \"knowledge\", \"knowledge\", \"knowledge\", \"knowledge\", \"knowledge_base\", \"labor_intensive\", \"language\", \"language\", \"large\", \"law\", \"layer\", \"learn\", \"learn\", \"learning\", \"leave\", \"legal\", \"level\", \"level\", \"likely\", \"linguistic\", \"linguistic\", \"linguistically\", \"list\", \"literature\", \"literature\", \"logic\", \"long\", \"long_short\", \"lstms\", \"machine\", \"machine\", \"machine\", \"maintain\", \"man\", \"manual\", \"many\", \"match\", \"match\", \"matching\", \"mean\", \"meaning\", \"measure\", \"measure\", \"measure\", \"memory\", \"method\", \"mining\", \"mlm\", \"model\", \"molecular\", \"molecule\", \"morpheme\", \"morphological\", \"music\", \"musical\", \"name\", \"natural\", \"natural\", \"natural\", \"natural\", \"nearly\", \"neglect\", \"network\", \"note\", \"novel\", \"novel\", \"object\", \"observational\", \"offer\", \"offer\", \"ontology\", \"open_source\", \"optimal\", \"orient\", \"outline\", \"output\", \"output\", \"overview\", \"page\", \"paper\", \"paper\", \"paper\", \"paradigm\", \"parallelism\", \"parse\", \"parser\", \"parsing\", \"pattern\", \"perfect\", \"perform\", \"performance\", \"perspective\", \"phoneme\", \"phrase\", \"platform\", \"pos_tagger\", \"possess\", \"potential\", \"potential\", \"powerful\", \"pre_traine\", \"precision\", \"present\", \"present\", \"present\", \"presentation\", \"previously\", \"probability\", \"probe\", \"procedure\", \"process\", \"process\", \"processing\", \"processing\", \"processing\", \"proficiency\", \"program\", \"programming\", \"progress\", \"progress\", \"project\", \"projection\", \"propose\", \"protein\", \"prototype\", \"publicly_available\", \"put\", \"quantifie\", \"query\", \"question\", \"question_answere\", \"question_answere\", \"quite\", \"rapid\", \"rare\", \"read\", \"reading\", \"reasonable\", \"reasoning\", \"recent_advance\", \"recognition\", \"recognition\", \"recommendation\", \"recover\", \"regular\", \"relation\", \"relation\", \"relation\", \"relative\", \"rely\", \"removal\", \"represent\", \"represent\", \"representation\", \"representation\", \"reproduce\", \"requirement\", \"research\", \"response\", \"restriction\", \"result\", \"retrieval\", \"review\", \"rewrite\", \"rigorously\", \"rnn\", \"room\", \"rule\", \"scaling\", \"science\", \"scientific\", \"search\", \"search\", \"selectively\", \"self\", \"semantic\", \"sentence\", \"sentence\", \"sequence\", \"serial\", \"service\", \"service\", \"show\", \"significantly\", \"single\", \"social\", \"social_media\", \"source\", \"source\", \"speak\", \"speech\", \"spoken\", \"stack\", \"state\", \"statement\", \"stopword\", \"story\", \"strict\", \"structure\", \"structure\", \"structure\", \"student\", \"study\", \"study\", \"style\", \"sub\", \"summarize\", \"support\", \"surprisal\", \"survey\", \"syntactic\", \"syntactic\", \"syntactically\", \"synthesis\", \"synthesize\", \"synthesize\", \"system\", \"tagging\", \"task\", \"technical\", \"technology\", \"template\", \"temporal\", \"term_memory\", \"text\", \"text\", \"theorem\", \"think\", \"time_consuming\", \"tool\", \"tool\", \"top\", \"train\", \"training\", \"transformer\", \"tree\", \"trust\", \"try\", \"turkish\", \"type\", \"type\", \"uncertain\", \"uncertainty\", \"unify\", \"unit\", \"unstructured\", \"update\", \"usage\", \"use\", \"use\", \"user\", \"usually\", \"usually\", \"utterance\", \"utterance\", \"uzbek\", \"validity\", \"variant\", \"various\", \"vec\", \"verify\", \"version\", \"viable\", \"video\", \"visual\", \"volume\", \"weakness\", \"web\", \"widespread\", \"word\", \"word\", \"work\", \"write\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 14, 7, 10, 17, 19, 12, 1, 4, 3, 11, 13, 6, 16, 18, 15, 8, 9, 20, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1603220906057176486822838415\", ldavis_el1603220906057176486822838415_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1603220906057176486822838415\", ldavis_el1603220906057176486822838415_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1603220906057176486822838415\", ldavis_el1603220906057176486822838415_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "4      0.355568 -0.203874       1        1  65.477835\n",
       "13     0.367186 -0.144356       2        1  16.477064\n",
       "6      0.240069  0.277841       3        1   5.038401\n",
       "9      0.259242 -0.063718       4        1   4.520656\n",
       "16     0.131282  0.260235       5        1   2.633079\n",
       "18     0.039472  0.104491       6        1   1.296712\n",
       "11    -0.011035  0.048299       7        1   0.895201\n",
       "0     -0.035160  0.034249       8        1   0.824981\n",
       "3     -0.070329  0.001714       9        1   0.565587\n",
       "2     -0.061420 -0.004237      10        1   0.446334\n",
       "10    -0.101067 -0.019357      11        1   0.309515\n",
       "12    -0.112420 -0.026010      12        1   0.303143\n",
       "5     -0.105240 -0.021845      13        1   0.289564\n",
       "15    -0.113197 -0.026111      14        1   0.277411\n",
       "17    -0.122498 -0.031233      15        1   0.260939\n",
       "14    -0.122537 -0.031297      16        1   0.205270\n",
       "7     -0.131543 -0.035970      17        1   0.143101\n",
       "8     -0.135502 -0.039507      18        1   0.013787\n",
       "19    -0.135469 -0.039607      19        1   0.013290\n",
       "1     -0.135402 -0.039709      20        1   0.008130, topic_info=            Term         Freq        Total Category  logprob  loglift\n",
       "214       speech   906.000000   906.000000  Default  30.0000  30.0000\n",
       "570       system  2213.000000  2213.000000  Default  29.0000  29.0000\n",
       "93         model  9450.000000  9450.000000  Default  28.0000  28.0000\n",
       "38      research  1183.000000  1183.000000  Default  27.0000  27.0000\n",
       "800    embedding   742.000000   742.000000  Default  26.0000  26.0000\n",
       "..           ...          ...          ...      ...      ...      ...\n",
       "25         large     0.002259  1700.254035  Topic20  -9.2906  -4.1139\n",
       "26          many     0.002259   922.193253  Topic20  -9.2906  -3.5021\n",
       "27       natural     0.002259  4808.037492  Topic20  -9.2906  -5.1534\n",
       "28   performance     0.002259  2290.742656  Topic20  -9.2906  -4.4120\n",
       "29      platform     0.002259   161.662497  Topic20  -9.2906  -1.7609\n",
       "\n",
       "[836 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "47        1  0.409375   ability\n",
       "47        3  0.589101   ability\n",
       "1506      5  0.989895  abstract\n",
       "1664      8  0.926186    accept\n",
       "233       1  0.999737   achieve\n",
       "...     ...       ...       ...\n",
       "277       2  0.936802      word\n",
       "118       1  0.999815      work\n",
       "607       2  0.996674     write\n",
       "220       1  0.335672      year\n",
       "220       4  0.659965      year\n",
       "\n",
       "[525 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 14, 7, 10, 17, 19, 12, 1, 4, 3, 11, 13, 6, 16, 18, 15, 8, 9, 20, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3505dde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dglover\\AppData\\Local\\Temp\\ipykernel_16032\\2695525547.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=texts)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "799bb914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>3548</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6922</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>[self_supervise, learning, speech, representation, successfully, apply, various, downstream, tas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549</th>\n",
       "      <td>3549</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6967</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>[large, language, model, llm, revolutionize, natural, language, processing, demand, massive, res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>3550</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7468</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>[text, summarization, essential, task, natural, language, processing, researcher, develop, vario...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>3551</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>[sentiment_analysis, vital, tool, uncover, insight, financial, article, news, social_media, shap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552</th>\n",
       "      <td>3552</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6051</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>[recent, research, demonstrate, task, fine_tune, multi_modal, large, language, model, llm, use, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>3553</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5646</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>[large, document, write, juridical, language, difficult, interpret, long, sentence, lead, intric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3554</th>\n",
       "      <td>3554</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8430</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>[promise, performance, various, natural, language, processing, task, current, system, vulnerable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>3555</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7402</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>[recent, advancement, speech, emotion, recognition, ser, model, state, art, deep, learning, appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>3556</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6258</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>[recent_advance, large, language, model, lead, renew, interest, natural, language, processing, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>3557</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7214</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>[pre_traine, model, czech, natural, language, processing, often, evaluate, purely, linguistic, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "3548         3548               4              0.6922   \n",
       "3549         3549               4              0.6967   \n",
       "3550         3550               4              0.7468   \n",
       "3551         3551               4              0.7304   \n",
       "3552         3552               4              0.6051   \n",
       "3553         3553               4              0.5646   \n",
       "3554         3554               4              0.8430   \n",
       "3555         3555               4              0.7402   \n",
       "3556         3556               4              0.6258   \n",
       "3557         3557               4              0.7214   \n",
       "\n",
       "                                                                                 Keywords  \\\n",
       "3548  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "3549  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "3550  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "3551  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "3552  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "3553  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "3554  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "3555  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "3556  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "3557  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "\n",
       "                                                                                                     Text  \n",
       "3548  [self_supervise, learning, speech, representation, successfully, apply, various, downstream, tas...  \n",
       "3549  [large, language, model, llm, revolutionize, natural, language, processing, demand, massive, res...  \n",
       "3550  [text, summarization, essential, task, natural, language, processing, researcher, develop, vario...  \n",
       "3551  [sentiment_analysis, vital, tool, uncover, insight, financial, article, news, social_media, shap...  \n",
       "3552  [recent, research, demonstrate, task, fine_tune, multi_modal, large, language, model, llm, use, ...  \n",
       "3553  [large, document, write, juridical, language, difficult, interpret, long, sentence, lead, intric...  \n",
       "3554  [promise, performance, various, natural, language, processing, task, current, system, vulnerable...  \n",
       "3555  [recent, advancement, speech, emotion, recognition, ser, model, state, art, deep, learning, appr...  \n",
       "3556  [recent_advance, large, language, model, lead, renew, interest, natural, language, processing, h...  \n",
       "3557  [pre_traine, model, czech, natural, language, processing, often, evaluate, purely, linguistic, t...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb65b874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     3529\n",
       "13      29\n",
       "Name: Dominant_Topic, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic['Dominant_Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c5a2f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>[deep, large, pre_traine, model, state, art, various, natural, language, processing, task, huge,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.6178</td>\n",
       "      <td>system, natural, process, semantic, sentence, information, word, use, analysis, user</td>\n",
       "      <td>[write, specification, computer, program, easy, take, account, disparate, conceptual, world, app...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0          4              0.9070   \n",
       "1         13              0.6178   \n",
       "\n",
       "                                                                               Keywords  \\\n",
       "0   language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "1  system, natural, process, semantic, sentence, information, word, use, analysis, user   \n",
       "\n",
       "                                                                                                  Text  \n",
       "0  [deep, large, pre_traine, model, state, art, various, natural, language, processing, task, huge,...  \n",
       "1  [write, specification, computer, program, easy, take, account, disparate, conceptual, world, app...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f08b1e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Representative Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>[deep, large, pre_traine, model, state, art, various, natural, language, processing, task, huge,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.6178</td>\n",
       "      <td>system, natural, process, semantic, sentence, information, word, use, analysis, user</td>\n",
       "      <td>[write, specification, computer, program, easy, take, account, disparate, conceptual, world, app...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0          4              0.9070   \n",
       "1         13              0.6178   \n",
       "\n",
       "                                                                               Keywords  \\\n",
       "0   language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "1  system, natural, process, semantic, sentence, information, word, use, analysis, user   \n",
       "\n",
       "                                                                                   Representative Text  \n",
       "0  [deep, large, pre_traine, model, state, art, various, natural, language, processing, task, huge,...  \n",
       "1  [write, specification, computer, program, easy, take, account, disparate, conceptual, world, app...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0fc05f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>3529.0</td>\n",
       "      <td>0.9918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3554</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, processing, text, use, method, dataset, performance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3558 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dominant_Topic  \\\n",
       "0                  4   \n",
       "1                  4   \n",
       "2                  4   \n",
       "3                  4   \n",
       "4                  4   \n",
       "...              ...   \n",
       "3553               4   \n",
       "3554               4   \n",
       "3555               4   \n",
       "3556               4   \n",
       "3557               4   \n",
       "\n",
       "                                                                           Topic_Keywords  \\\n",
       "0     language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "1     language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "2     language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "3     language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "4     language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "...                                                                                   ...   \n",
       "3553  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "3554  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "3555  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "3556  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "3557  language, model, task, natural, processing, text, use, method, dataset, performance   \n",
       "\n",
       "      Num_Documents  Perc_Documents  \n",
       "0               NaN             NaN  \n",
       "1               NaN             NaN  \n",
       "2               NaN             NaN  \n",
       "3               NaN             NaN  \n",
       "4            3529.0          0.9918  \n",
       "...             ...             ...  \n",
       "3553            NaN             NaN  \n",
       "3554            NaN             NaN  \n",
       "3555            NaN             NaN  \n",
       "3556            NaN             NaN  \n",
       "3557            NaN             NaN  \n",
       "\n",
       "[3558 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a37af7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7c8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7e6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c35821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6d17dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0416e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f58d346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb40b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
