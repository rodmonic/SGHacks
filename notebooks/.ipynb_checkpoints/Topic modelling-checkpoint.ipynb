{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ee0acd1",
   "metadata": {},
   "source": [
    "# Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5248f29",
   "metadata": {},
   "source": [
    "## 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8175cf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dglover\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331e80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf2b9be",
   "metadata": {},
   "source": [
    "## 1.0 Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf3b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['use', 'show', 'however', 'approach', 'well', 'provide',' present', 'include', 'word', 'nlp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab0ab002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>PDF URL</th>\n",
       "      <th>Author</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Journal Ref</th>\n",
       "      <th>Primary Category</th>\n",
       "      <th>Category</th>\n",
       "      <th>Entry ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural Language Processing using Hadoop and K...</td>\n",
       "      <td>http://arxiv.org/pdf/1608.04434v1</td>\n",
       "      <td>[arxiv.Result.Author('Emre Erturk'), arxiv.Res...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-15 23:09:21+00:00</td>\n",
       "      <td>Natural language processing, as a data analyti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1608.04434v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Integrating AI Planning with Natural Language ...</td>\n",
       "      <td>http://arxiv.org/pdf/2202.07138v2</td>\n",
       "      <td>[arxiv.Result.Author('Kebing Jin'), arxiv.Resu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-15 02:19:09+00:00</td>\n",
       "      <td>Natural language processing (NLP) aims at inve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>['cs.AI', 'cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2202.07138v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simple Natural Language Processing Tools for D...</td>\n",
       "      <td>http://arxiv.org/pdf/1906.11608v2</td>\n",
       "      <td>[arxiv.Result.Author('Leon Derczynski')]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-27 13:15:12+00:00</td>\n",
       "      <td>This technical note describes a set of baselin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1906.11608v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Towards the Study of Morphological Processing ...</td>\n",
       "      <td>http://arxiv.org/pdf/2006.16212v1</td>\n",
       "      <td>[arxiv.Result.Author('Mirinso Shadang'), arxiv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-29 17:24:09+00:00</td>\n",
       "      <td>There is no or little work on natural language...</td>\n",
       "      <td>In proceeding of Regional International Confer...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2006.16212v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natural Language Understanding with Distribute...</td>\n",
       "      <td>http://arxiv.org/pdf/1511.07916v1</td>\n",
       "      <td>[arxiv.Result.Author('Kyunghyun Cho')]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-24 23:23:13+00:00</td>\n",
       "      <td>This is a lecture note for the course DS-GA 30...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL', 'stat.ML']</td>\n",
       "      <td>http://arxiv.org/abs/1511.07916v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Natural Language Processing using Hadoop and K...   \n",
       "1  Integrating AI Planning with Natural Language ...   \n",
       "2  Simple Natural Language Processing Tools for D...   \n",
       "3  Towards the Study of Morphological Processing ...   \n",
       "4  Natural Language Understanding with Distribute...   \n",
       "\n",
       "                             PDF URL  \\\n",
       "0  http://arxiv.org/pdf/1608.04434v1   \n",
       "1  http://arxiv.org/pdf/2202.07138v2   \n",
       "2  http://arxiv.org/pdf/1906.11608v2   \n",
       "3  http://arxiv.org/pdf/2006.16212v1   \n",
       "4  http://arxiv.org/pdf/1511.07916v1   \n",
       "\n",
       "                                              Author  DOI  \\\n",
       "0  [arxiv.Result.Author('Emre Erturk'), arxiv.Res...  NaN   \n",
       "1  [arxiv.Result.Author('Kebing Jin'), arxiv.Resu...  NaN   \n",
       "2           [arxiv.Result.Author('Leon Derczynski')]  NaN   \n",
       "3  [arxiv.Result.Author('Mirinso Shadang'), arxiv...  NaN   \n",
       "4             [arxiv.Result.Author('Kyunghyun Cho')]  NaN   \n",
       "\n",
       "              Published Date  \\\n",
       "0  2016-08-15 23:09:21+00:00   \n",
       "1  2022-02-15 02:19:09+00:00   \n",
       "2  2019-06-27 13:15:12+00:00   \n",
       "3  2020-06-29 17:24:09+00:00   \n",
       "4  2015-11-24 23:23:13+00:00   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Natural language processing, as a data analyti...   \n",
       "1  Natural language processing (NLP) aims at inve...   \n",
       "2  This technical note describes a set of baselin...   \n",
       "3  There is no or little work on natural language...   \n",
       "4  This is a lecture note for the course DS-GA 30...   \n",
       "\n",
       "                                         Journal Ref Primary Category  \\\n",
       "0                                                NaN            cs.CL   \n",
       "1                                                NaN            cs.AI   \n",
       "2                                                NaN            cs.CL   \n",
       "3  In proceeding of Regional International Confer...            cs.CL   \n",
       "4                                                NaN            cs.CL   \n",
       "\n",
       "               Category                           Entry ID  \n",
       "0             ['cs.CL']  http://arxiv.org/abs/1608.04434v1  \n",
       "1    ['cs.AI', 'cs.CL']  http://arxiv.org/abs/2202.07138v2  \n",
       "2             ['cs.CL']  http://arxiv.org/abs/1906.11608v2  \n",
       "3             ['cs.CL']  http://arxiv.org/abs/2006.16212v1  \n",
       "4  ['cs.CL', 'stat.ML']  http://arxiv.org/abs/1511.07916v1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_csv('..\\\\data\\\\arxiv_papers_full_v2.csv', index_col=0)\n",
    "#print(df.target_names.unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abeeb872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3558, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c8893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Summary'] = df['Summary'].map(lambda x: x.lower().replace('natural langauge processing', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "285190c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data = df['Summary'].values.tolist()\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "725e7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeeead64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39a9519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1a7c002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dglover\\Anaconda3\\lib\\site-packages\\spacy\\language.py:1895: UserWarning: [W123] Argument disable with value ['parser', 'ner'] is used instead of ['senter'] as specified in the config. Be aware that this might affect other components in your pipeline.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "#nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b461d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d6f5689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f520adbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.067*\"information\" + 0.057*\"user\" + 0.052*\"document\" + 0.043*\"graph\" + '\n",
      "  '0.037*\"extraction\" + 0.032*\"query\" + 0.031*\"retrieval\" + 0.024*\"knowledge\" '\n",
      "  '+ 0.022*\"search\" + 0.017*\"name\"'),\n",
      " (1,\n",
      "  '0.252*\"embedding\" + 0.041*\"contextualize\" + 0.037*\"loss\" + 0.028*\"vector\" + '\n",
      "  '0.024*\"analogy\" + 0.021*\"align\" + 0.020*\"spanish\" + 0.016*\"space\" + '\n",
      "  '0.016*\"vec\" + 0.014*\"filter\"'),\n",
      " (2,\n",
      "  '0.117*\"entity\" + 0.036*\"alignment\" + 0.033*\"core\" + 0.033*\"protein\" + '\n",
      "  '0.032*\"discourse\" + 0.021*\"verify\" + 0.020*\"claim\" + 0.018*\"specification\" '\n",
      "  '+ 0.015*\"informal\" + 0.014*\"discovery\"'),\n",
      " (3,\n",
      "  '0.136*\"semantic\" + 0.064*\"image\" + 0.058*\"concept\" + 0.039*\"visual\" + '\n",
      "  '0.023*\"parse\" + 0.020*\"event\" + 0.019*\"parser\" + 0.015*\"meaning\" + '\n",
      "  '0.014*\"story\" + 0.012*\"video\"'),\n",
      " (4,\n",
      "  '0.042*\"language\" + 0.039*\"model\" + 0.022*\"task\" + 0.015*\"natural\" + '\n",
      "  '0.013*\"text\" + 0.013*\"use\" + 0.012*\"processing\" + 0.010*\"base\" + '\n",
      "  '0.010*\"method\" + 0.010*\"dataset\"'),\n",
      " (5,\n",
      "  '0.095*\"question\" + 0.062*\"answer\" + 0.036*\"explanation\" + '\n",
      "  '0.028*\"question_answere\" + 0.028*\"rank\" + 0.023*\"causal\" + 0.018*\"mention\" '\n",
      "  '+ 0.017*\"latency\" + 0.017*\"rationale\" + 0.015*\"ask\"'),\n",
      " (6,\n",
      "  '0.025*\"process\" + 0.024*\"human\" + 0.021*\"natural\" + 0.019*\"generation\" + '\n",
      "  '0.019*\"generate\" + 0.013*\"network\" + 0.012*\"structure\" + 0.012*\"framework\" '\n",
      "  '+ 0.011*\"system\" + 0.011*\"attention\"'),\n",
      " (7,\n",
      "  '0.036*\"tree\" + 0.033*\"program\" + 0.031*\"programming\" + 0.031*\"grammar\" + '\n",
      "  '0.018*\"compositional\" + 0.018*\"transformation\" + 0.017*\"rule\" + '\n",
      "  '0.017*\"vital\" + 0.017*\"class\" + 0.015*\"logic\"'),\n",
      " (8,\n",
      "  '0.222*\"llm\" + 0.068*\"prompt\" + 0.054*\"clinical\" + 0.035*\"chatgpt\" + '\n",
      "  '0.027*\"compression\" + 0.023*\"associate\" + 0.016*\"large\" + 0.016*\"financial\" '\n",
      "  '+ 0.015*\"clinical_note\" + 0.014*\"health\"'),\n",
      " (9,\n",
      "  '0.036*\"research\" + 0.018*\"field\" + 0.014*\"bias\" + 0.013*\"tool\" + '\n",
      "  '0.012*\"potential\" + 0.012*\"processing\" + 0.012*\"application\" + '\n",
      "  '0.011*\"study\" + 0.011*\"significantly\" + 0.010*\"challenge\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "762c9417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -7.618650871450112\n",
      "\n",
      "Coherence Score:  0.40444599079931204\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ff13d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dglover\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1603220905914333283587114792\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1603220905914333283587114792_data = {\"mdsDat\": {\"x\": [-0.3190666690032167, -0.24950401635625669, -0.2287690350087643, 0.0416759577396755, 0.10523192487953381, 0.13572249545061393, 0.11590029310355382, 0.12504586708472618, 0.14112362500462214, 0.13263955710551203], \"y\": [0.004827790844032246, -0.27673947970266644, 0.31093061959325213, -0.07347824574533258, -0.056029702840258176, 0.03181878057490407, -0.040708339574262245, 0.056268982812427655, 0.026851034227618954, 0.016258559810284786], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [67.48618183436247, 14.03624888029899, 8.6582134790839, 2.798375043358624, 2.0908943870086323, 1.2012542198839657, 1.1996986585884533, 1.1541630952504336, 0.7746140770022275, 0.6003563251623074]}, \"tinfo\": {\"Term\": [\"information\", \"large\", \"llm\", \"semantic\", \"model\", \"knowledge\", \"embedding\", \"research\", \"process\", \"human\", \"processing\", \"natural\", \"user\", \"language\", \"task\", \"generate\", \"document\", \"image\", \"generation\", \"question\", \"sentence\", \"extraction\", \"system\", \"concept\", \"structure\", \"study\", \"entity\", \"question_answere\", \"graph\", \"field\", \"task\", \"text\", \"model\", \"dataset\", \"performance\", \"datum\", \"result\", \"training\", \"domain\", \"learning\", \"state\", \"achieve\", \"improve\", \"train\", \"different\", \"art\", \"classification\", \"transformer\", \"speech\", \"pre_traine\", \"experiment\", \"many\", \"set\", \"evaluate\", \"word\", \"compare\", \"perform\", \"show\", \"find\", \"well\", \"method\", \"use\", \"language\", \"new\", \"large\", \"propose\", \"base\", \"work\", \"processing\", \"natural\", \"also\", \"paper\", \"representation\", \"system\", \"learn\", \"human\", \"network\", \"generation\", \"reasoning\", \"dialogue\", \"gpt\", \"single\", \"self\", \"vision\", \"response\", \"object\", \"interaction\", \"instruction\", \"mechanism\", \"style\", \"pattern\", \"action\", \"behavior\", \"condition\", \"utterance\", \"agent\", \"version\", \"hierarchical\", \"procedure\", \"reason\", \"description\", \"control\", \"environment\", \"function\", \"weight\", \"process\", \"complex\", \"structure\", \"generate\", \"sequence\", \"attention\", \"framework\", \"scenario\", \"input\", \"enable\", \"design\", \"allow\", \"ability\", \"novel\", \"natural\", \"describe\", \"system\", \"level\", \"learn\", \"relation\", \"context\", \"sentence\", \"representation\", \"research\", \"bias\", \"significantly\", \"future\", \"discuss\", \"area\", \"legal\", \"survey\", \"researcher\", \"review\", \"social\", \"ai\", \"comprehensive\", \"technology\", \"privacy\", \"direction\", \"scientific\", \"recommendation\", \"handle\", \"record\", \"gender\", \"concern\", \"note\", \"science\", \"risk\", \"patient\", \"unstructured\", \"previously\", \"engineering\", \"maintain\", \"platform\", \"community\", \"impact\", \"insight\", \"game\", \"tool\", \"article\", \"potential\", \"field\", \"literature\", \"development\", \"automate\", \"topic\", \"application\", \"analysis\", \"identify\", \"study\", \"challenge\", \"current\", \"processing\", \"machine\", \"paper\", \"document\", \"graph\", \"query\", \"retrieval\", \"search\", \"name\", \"chinese\", \"segmentation\", \"cluster\", \"database\", \"fast\", \"precision\", \"external\", \"interface\", \"link\", \"estimate\", \"final\", \"material\", \"store\", \"demand\", \"comment\", \"right\", \"drug\", \"acquire\", \"matching\", \"healthcare\", \"uncertainty\", \"commerce\", \"persian\", \"idiom\", \"user\", \"extraction\", \"information\", \"relevant\", \"knowledge\", \"relation\", \"character\", \"system\", \"image\", \"concept\", \"visual\", \"event\", \"parser\", \"meaning\", \"story\", \"video\", \"dialog\", \"argument\", \"business\", \"read\", \"caption\", \"operation\", \"rapid\", \"region\", \"semantic\", \"connect\", \"visualization\", \"promising\", \"bind\", \"induction\", \"freely\", \"unified\", \"ambiguity\", \"professional\", \"possibility\", \"stream\", \"relatedness\", \"verb\", \"parse\", \"ground\", \"frame\", \"syntactic\", \"textual\", \"computer_vision\", \"sentence\", \"lexical\", \"question\", \"answer\", \"explanation\", \"rank\", \"causal\", \"mention\", \"latency\", \"rationale\", \"ask\", \"ontology\", \"criterion\", \"dependent\", \"complete\", \"reading_comprehension\", \"recall\", \"fusion\", \"clinical_trial\", \"simplify\", \"prone\", \"scene\", \"thereby\", \"passage\", \"refine\", \"cultural\", \"rationalization\", \"raise\", \"without_require\", \"trial\", \"extractive\", \"expertise\", \"question_answere\", \"candidate\", \"tree\", \"programming\", \"grammar\", \"compositional\", \"transformation\", \"vital\", \"logic\", \"minimal\", \"desire\", \"noun\", \"modification\", \"quantum\", \"computing\", \"polarity\", \"negation\", \"clustering\", \"formalism\", \"compact\", \"substitution\", \"evolutionary\", \"computational_linguistic\", \"diagram\", \"execute\", \"possibly\", \"procedural\", \"stack\", \"expressiveness\", \"snippet\", \"pass\", \"session\", \"program\", \"formal\", \"grammatical\", \"class\", \"rule\", \"parallel\", \"dependency\", \"syntactic\", \"structure\", \"type\", \"parse\", \"llm\", \"prompt\", \"clinical\", \"chatgpt\", \"compression\", \"associate\", \"financial\", \"clinical_note\", \"health\", \"random\", \"bangla\", \"experimental\", \"academic\", \"symptom\", \"explainable\", \"simply\", \"table\", \"tabular\", \"library\", \"dual\", \"severity\", \"assistant\", \"encompass\", \"log\", \"ehr\", \"gaussian\", \"convolutional\", \"status\", \"hyperparameter\", \"frozen\", \"large\", \"disease\", \"utilization\", \"entity\", \"alignment\", \"core\", \"protein\", \"discourse\", \"verify\", \"claim\", \"specification\", \"informal\", \"discovery\", \"molecular\", \"molecule\", \"think\", \"path\", \"variance\", \"confidence\", \"trigger\", \"consistency\", \"smile\", \"complement\", \"rigorous\", \"specify\", \"imbalance\", \"time_consuming\", \"electronic\", \"chemical\", \"verification\", \"methodological\", \"correctness\", \"trace\", \"embedding\", \"contextualize\", \"loss\", \"analogy\", \"align\", \"spanish\", \"vec\", \"filter\", \"emph\", \"vector_space\", \"intuitive\", \"extrinsic\", \"enforce\", \"usefulness\", \"cosine\", \"mikolov\", \"procruste\", \"glove\", \"hyperbolic\", \"skip_gram\", \"euclidean\", \"masking\", \"differently\", \"concreteness\", \"correspondence\", \"activate\", \"clwe\", \"intrinsically\", \"window\", \"anchor\", \"vector\", \"space\"], \"Freq\": [1327.0, 1387.0, 771.0, 869.0, 7892.0, 1079.0, 456.0, 933.0, 1072.0, 1020.0, 2820.0, 3949.0, 500.0, 8691.0, 4514.0, 955.0, 441.0, 403.0, 804.0, 345.0, 1080.0, 415.0, 1705.0, 364.0, 559.0, 1048.0, 274.0, 318.0, 361.0, 576.0, 4514.06518235482, 2646.3614602016482, 7889.471590135424, 1944.7411398836807, 1912.3751059454637, 1813.7508061360531, 1584.7942319078563, 1314.2253886304588, 1253.2577153616344, 1219.6592159792365, 1064.5425951930497, 1028.5139888844726, 1026.8677996287165, 1018.4531758754924, 1005.4594849863302, 949.2392262141009, 894.946019523052, 882.2594986916148, 878.436433278155, 872.7752682956102, 778.3000353934556, 769.5311629923284, 736.9926652740115, 696.2944306017566, 648.8101128751127, 633.437368123894, 641.9405185527194, 575.3845929721684, 534.8063022457443, 529.5624570273914, 1986.3084595251737, 2552.768276624218, 8483.666043463143, 792.4300473094698, 1329.4471506869456, 1733.5249139985854, 2105.493659353764, 1332.0734262913948, 2511.048791408843, 2975.9471724533537, 987.4625938131327, 1436.0866396181393, 1017.7165733710773, 1129.861749649313, 930.649759901817, 1020.2102972545689, 532.2345484544624, 802.9746237868687, 406.6746680272241, 306.77840346478786, 290.68212949283395, 286.18765424132505, 230.58665985576658, 212.2890857645701, 211.04926513573486, 192.40832097658384, 191.67149045761022, 187.70423370950027, 187.13584071440349, 182.7819728093045, 179.79538538401366, 166.38462512821954, 164.6582979635174, 156.81416365748706, 152.690908333279, 140.7913030956828, 138.05992075958906, 136.92095992172213, 136.7490977508303, 134.38820711249969, 210.0260632715395, 129.80088259493695, 122.2671905726305, 121.49637928887852, 118.72201172818241, 1065.1336358848741, 292.0091605292759, 518.1638941462562, 794.6370647643636, 417.078627567587, 460.1969410384225, 504.0364772978701, 205.49834532572962, 399.70684971945167, 271.45301204979245, 334.558057547286, 262.6741459274549, 303.7389505114375, 360.63269009952893, 879.243717181919, 235.525276397741, 477.40705192919347, 311.33855714784346, 385.9959408028581, 225.79772400660391, 256.97494283807504, 264.6928178877756, 266.45497591391944, 933.0363484861583, 373.4504672263957, 276.0576594383237, 255.75503074208933, 243.54211594459778, 233.54099421971736, 226.21859696262112, 220.40854266012482, 218.69080331073707, 216.04274625595883, 204.25082243764098, 175.9271719340286, 162.74960552616605, 155.49429778778344, 142.23920085757103, 140.56635782381903, 119.24682393622501, 116.82185227890658, 109.52518116914187, 105.60243539950656, 105.48641885212555, 104.99786486686403, 102.8689563661418, 99.08042605603946, 93.99860140541436, 90.05613913588928, 89.89159013265272, 87.63329817175475, 76.32882353482529, 76.00317955804347, 128.59879447107664, 208.8907801721709, 194.75817758984422, 180.99031811477658, 141.363904813203, 342.2468965430697, 153.8449955750205, 313.3113789449713, 459.4928842429427, 152.25614191703053, 226.31683952241676, 166.93057188456723, 198.64146607829616, 302.69698180418425, 255.24781649800354, 196.60457195729353, 280.5250735174142, 257.3579190514787, 192.17611739060837, 308.3552530514945, 178.2289276077378, 201.48258457472915, 440.42358624081965, 360.9015029515327, 265.9208871965853, 262.8402085207384, 183.58718137136415, 146.17706130484842, 136.36762477224153, 123.03050312716168, 122.72244310744013, 116.68698902411116, 116.59419589033656, 102.03532675938952, 91.18938370248642, 84.59436128150558, 83.44938159287985, 68.10800202818245, 62.13033568508938, 61.97920153672749, 58.19520913801373, 58.15781799408029, 57.67991059633806, 53.45251785411135, 52.36339925532047, 50.645419611277724, 49.0385814050323, 48.52754425304199, 47.90293282568075, 47.15034237015399, 46.53803639219723, 44.35307749983555, 479.1217446931513, 309.6719080277257, 565.5878370294189, 93.61719864366587, 202.49158497625666, 74.75495375956471, 54.50647017816914, 56.033801682937025, 403.01298473316984, 364.1949549745613, 248.5653599452786, 129.01769329387227, 121.24539487606701, 93.9072899905819, 91.09366701882391, 74.99510138375922, 66.26801554862284, 66.14553293154707, 65.02704053032465, 60.97702801549603, 60.446180096888746, 55.19146003726891, 46.535762780339574, 43.51852594438496, 854.008757529375, 40.85001977688734, 37.90557003044639, 35.8104124522074, 35.50131213455021, 35.20084036778478, 34.19487975056758, 33.78291702058068, 33.35091775753423, 33.04004071482084, 32.47738179479475, 32.07839853976463, 30.92594019831762, 30.108239139819588, 143.06570125425398, 67.59619668915151, 42.52451864078845, 64.5637198914112, 71.41892912748375, 50.8613641154782, 47.298704938054286, 38.536820506066306, 345.0146351821806, 223.75739125929607, 131.70948879421823, 100.36215998242866, 82.359238943768, 66.2662684569058, 61.46891854354391, 61.367226729232506, 53.724116320831016, 53.47446503906595, 51.86423010523084, 46.975153407264465, 44.95947180159456, 44.74104630088205, 43.29225293351586, 41.42052524414293, 35.82443002535456, 35.10555318655814, 34.24616538628574, 33.694965837415815, 30.319977370162324, 29.51437310581656, 29.438941401905925, 29.069827673069486, 28.079678335246673, 26.020126006331886, 25.776530215066547, 25.678810263508517, 24.69027460020552, 24.041959806617452, 101.26106764865504, 27.738630415229828, 128.52318890237575, 112.67984246398404, 110.98931345959967, 66.7212700106176, 64.59403850871881, 61.470982120309344, 54.42029147208178, 53.820798713221, 48.69159165220557, 41.62448908096782, 40.66056617354336, 37.28959150492662, 36.346114529468714, 33.701352313902056, 30.22430238725642, 30.014510370179796, 30.000766478114077, 29.7611584582256, 28.26156020802423, 27.002088107302058, 26.50497472753892, 24.413330990224008, 23.38460823918002, 22.68653123224979, 21.64808177570715, 20.58073986552574, 20.404035805981632, 18.29590108042679, 17.69050366291844, 17.561600422596786, 120.09557559574615, 50.15552980154903, 41.934979920450075, 60.06913204542875, 61.638371622892876, 37.19439023934727, 37.15061165340868, 34.84334021216574, 40.343480957451845, 35.976967382942696, 31.12757721674289, 771.0524722950106, 237.94218406044928, 187.52789135371916, 122.26391634667773, 94.06918662887331, 78.96926915295775, 54.52928409710479, 53.86446642936155, 47.1049899621435, 46.22442497025203, 43.357029583312794, 39.393541981122134, 32.5172955721747, 31.943991280706957, 25.98112915692534, 24.740608746477474, 24.219261188146433, 24.152581978017928, 21.950484920102202, 21.828804788728647, 21.177622041141046, 20.727232711204568, 19.46991828693414, 18.8239289469168, 17.922239134515937, 17.507839520237763, 17.491741413319286, 17.20474940607411, 16.693791899659896, 16.67556723071358, 56.156948847012885, 20.845972231311325, 17.423440578265442, 273.2364348570179, 83.34382434077389, 77.3096291735802, 76.83381381571088, 74.88422907672052, 48.36173724506954, 47.744371206392096, 41.782133140964646, 34.07284337941213, 33.044389485710035, 32.25673902075103, 31.853671502029997, 27.328698556822733, 26.835489148903832, 26.319915341676772, 26.312955114830405, 25.398578122621206, 25.10757590425083, 24.872457529707784, 24.755295883482727, 24.417301272122153, 23.127867112302113, 22.055616360469685, 21.883239955894414, 21.25685864211946, 20.301915084326914, 19.611597005089333, 18.763496405157223, 18.528421477723082, 17.343537354591085, 455.315371751086, 73.5157543960576, 66.90344611430852, 43.26659320002632, 37.5473053244231, 36.02974105824345, 28.988840091317634, 25.31449964631118, 18.86943107233745, 18.235408202178164, 16.232718973204786, 16.132226312927664, 15.889201666649903, 15.543578100473882, 12.617244359640171, 12.124753380985158, 10.660226112667521, 9.810714026265526, 9.207782477683926, 8.427126223892438, 8.303842689625313, 8.083240195629296, 7.795229817283505, 7.607024323790989, 6.417076871870468, 6.390041068168406, 6.044228090155953, 5.905596725240257, 5.6844466205793545, 5.050075653556222, 50.319023875893414, 29.19003418580715], \"Total\": [1327.0, 1387.0, 771.0, 869.0, 7892.0, 1079.0, 456.0, 933.0, 1072.0, 1020.0, 2820.0, 3949.0, 500.0, 8691.0, 4514.0, 955.0, 441.0, 403.0, 804.0, 345.0, 1080.0, 415.0, 1705.0, 364.0, 559.0, 1048.0, 274.0, 318.0, 361.0, 576.0, 4514.833026873083, 2647.1293164226195, 7892.331584599764, 1945.5089996003937, 1913.142960122632, 1814.518649966347, 1585.5620853349676, 1314.9932220780045, 1254.0255548681107, 1220.427078670685, 1065.310440697986, 1029.281848106787, 1027.6356635735194, 1019.2210172754047, 1006.2273328183453, 950.0070564086735, 895.7138578639602, 883.0273404902626, 879.2042626856291, 873.5431073568217, 779.0679225120621, 770.29901491395, 737.7605266985447, 697.0623001154299, 649.5781403904622, 634.2052250928044, 642.7481230998303, 576.1524505290837, 535.5741588678522, 530.330306968165, 1990.9606097807427, 2574.2162942624773, 8691.306886696155, 796.0828533062834, 1387.5965103825242, 1843.6691288950224, 2277.262506331644, 1395.8404069181272, 2820.4969550497317, 3949.55991393807, 1041.1818374299744, 1658.2227498278546, 1284.8326395664787, 1705.9193886001867, 1317.3067935869237, 1020.9731910703238, 532.9974385024483, 804.3411914494835, 407.4375732544195, 307.541250363454, 291.4451144826018, 286.9506045780604, 231.34960165247, 213.05206714586822, 211.81215217382913, 193.17116884300196, 192.43434859420466, 188.46714735055977, 187.89872545636715, 183.5449233199106, 180.55825321779412, 167.14748197145843, 165.42123258887182, 157.5770948998302, 153.45377400629692, 141.5541191708926, 138.82299055028292, 137.6839038499693, 137.51201665566535, 135.15115358235775, 211.22416292204719, 130.5637265513821, 123.03005804587274, 122.25925642168053, 119.48491012125096, 1072.7896266564085, 300.15554365421775, 559.1776175329047, 955.5200865651362, 495.2513807999007, 586.6101797246114, 671.7066440505685, 229.17587884544287, 535.4906225555194, 328.24418621810423, 442.0397413578452, 335.24452691844033, 437.9738773193336, 650.8947866798836, 3949.55991393807, 316.12477356694893, 1705.9193886001867, 720.5895427039453, 1317.3067935869237, 301.2182486868254, 497.10684309242856, 1080.644788033131, 1284.8326395664787, 933.8606106882202, 374.2221796517853, 276.82963894723486, 256.5267687603275, 244.31386215231848, 234.3127654329779, 226.99036702311827, 221.18023973725468, 219.46260297418138, 216.81449246251657, 205.02253968328418, 176.69892626099877, 163.5214153333578, 156.26604399359556, 143.01099699122364, 141.33813076305344, 120.01864809956092, 117.59372500188556, 110.29715558501185, 106.37428386549145, 106.25816417649004, 105.76969428075972, 103.64089196689417, 99.85223561641735, 94.77037594216407, 90.82795802642488, 90.66349600573231, 88.40518208720898, 77.10063202886222, 76.7751864156984, 130.03356171706778, 216.71807729487628, 201.716173708633, 188.94590852948716, 146.1900840166025, 377.6357454294152, 161.56944805339805, 361.57419825874615, 576.0210879647851, 168.45989072559615, 279.4595103607414, 205.51094215314083, 266.81975138916937, 805.4325487867325, 701.5822810914304, 369.720620568953, 1048.833087925119, 927.5919132610437, 409.11414395755287, 2820.4969550497317, 506.7403970415018, 1658.2227498278546, 441.19587018184, 361.67376033428746, 266.69308116956125, 263.6124550390398, 184.35942718957168, 146.94940837833875, 137.13986171261047, 123.80275759316253, 123.49470893073638, 117.45924670313039, 117.36657742371256, 102.80770098204732, 91.9616839985044, 85.37064722566575, 84.22163233259336, 68.88032078980392, 62.90273995919443, 62.75143885817703, 58.967556106219114, 58.93024088284879, 58.45215344047672, 54.22502352151386, 53.13597669932677, 51.41779148406432, 49.810817261660524, 49.29987855809625, 48.67521879501936, 47.92265694890328, 47.31061876109267, 45.12565182143903, 500.2672460475365, 415.2754669891206, 1327.3649761067388, 181.5722634772382, 1079.5085704201663, 301.2182486868254, 124.53564252015738, 1705.9193886001867, 403.78901902595976, 364.97108150626735, 249.3413816839063, 129.79370604703823, 122.02148919908983, 94.68336650555864, 91.86988209866497, 75.77112920715501, 67.04405407450874, 66.92168194213913, 65.80312767837653, 61.75323436898159, 61.222177915283105, 55.967604438504864, 47.312161775283286, 44.29462429280948, 869.9094035544821, 41.62621985230141, 38.681597763443555, 36.586966847072205, 36.27760875110406, 35.977000649774986, 34.971600566269046, 34.5590049717973, 34.126927777249115, 33.816206173259765, 33.253657355837, 32.85451320273816, 31.70206394055467, 30.884360590458368, 174.87663462283805, 97.78526536655721, 51.487951873878075, 190.65811733328007, 301.2772822846962, 121.38965942903023, 1080.644788033131, 152.82274612529292, 345.8012990242149, 224.54401027599738, 132.4961290140338, 101.14884613916003, 83.14590283998976, 67.05310915353265, 62.255882072433415, 62.15423609574994, 54.510830014451244, 54.26117485020535, 52.651027501598016, 47.761994298089725, 45.74620428854697, 45.52772949935127, 44.079102057799126, 42.20728964971015, 36.61126136998577, 35.89238834998349, 35.03302629815999, 34.481715501744915, 31.10692582411619, 30.301088352826945, 30.226181680786166, 29.856527287493524, 28.86631000328723, 26.807051955185802, 26.563636133184374, 26.465563408891413, 25.477108074857174, 24.828825669071303, 318.3430150021299, 108.97038726900391, 129.30006559750046, 113.45671503367844, 111.76614735392056, 67.49819501934115, 65.37094073295037, 62.24822867139657, 55.1972010571888, 54.597803994332516, 49.46867565552166, 42.40151693877243, 41.43751737853401, 38.066438828956514, 37.12308637718282, 34.47827210661411, 31.00115976347728, 30.79152589059955, 30.777667593715186, 30.538191913808756, 29.03847644970568, 27.779144050997754, 27.281940942423255, 25.190186580010995, 24.161509207438165, 23.46359260859588, 22.425099050705942, 21.357747510396116, 21.18108210702838, 19.072797967630663, 18.467381112691946, 18.338454396456157, 185.32862903725854, 86.8102495694953, 69.1123839260844, 183.0301625864356, 257.5689250525637, 146.2216070428186, 167.12294041710913, 190.65811733328007, 559.1776175329047, 399.2228841853343, 174.87663462283805, 771.8575478134641, 238.74725223285608, 188.3329060594942, 123.0689847823711, 94.87430432990834, 79.77445609949127, 55.33435899386214, 54.66955354654671, 47.91005189373945, 47.02969646377968, 44.16221367084776, 40.19871928707515, 33.32248286790411, 32.74902644476666, 26.786372460350663, 25.545838536436023, 25.02438393084343, 24.95771255012985, 22.75576769625786, 22.63397638456124, 21.98302932220168, 21.532327292985418, 20.27506337617019, 19.629037287248686, 18.72736013036014, 18.313107259312275, 18.29711510016409, 18.009809350863094, 17.498884202914724, 17.480812521264234, 1387.5965103825242, 47.639507287485536, 28.10473824663438, 274.0355059960775, 84.14293143881311, 78.10877506545505, 77.63281144229526, 75.68325967437285, 49.160889478440495, 48.54344976389574, 42.581176099725, 34.871920953539274, 33.843569031551695, 33.055760560641616, 32.65271262099522, 28.12792197281356, 27.634539288612498, 27.119058755980376, 27.112025835808193, 26.19759180865809, 25.906598801822877, 25.671471657556644, 25.554498133262047, 25.216456135431287, 23.926924497495936, 22.855029625155797, 22.68241127762662, 22.056075863694957, 21.10095790740714, 20.410805634094867, 19.56280722439934, 19.327709495598867, 18.14259688354662, 456.1233875247103, 74.32385466237665, 67.71151889496821, 44.07467236692779, 38.355471803750646, 36.83781996943854, 29.796873503814357, 26.1225809598693, 19.677739955525958, 19.043456290386196, 17.041041338020655, 16.940337047145476, 16.697671308597776, 16.351737629151522, 13.42542723582033, 12.933108560169822, 11.468454675944942, 10.618763152329699, 10.023181780283581, 9.235077975428315, 9.116458593951416, 8.891596546558638, 8.603459991545265, 8.415144510947044, 7.2251483887185834, 7.1982737335482465, 6.852258197037998, 6.713605984681157, 6.492543881619788, 5.858096089719698, 197.840956897402, 276.03700664106316], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.8071, -4.3411, -3.2487, -4.6491, -4.6659, -4.7189, -4.8538, -5.041, -5.0885, -5.1157, -5.2517, -5.2862, -5.2878, -5.296, -5.3088, -5.3664, -5.4253, -5.4395, -5.4439, -5.4504, -5.5649, -5.5762, -5.6195, -5.6763, -5.7469, -5.7709, -5.7575, -5.867, -5.9401, -5.95, -4.628, -4.3771, -3.1761, -5.5469, -5.0295, -4.7641, -4.5697, -5.0275, -4.3936, -4.2237, -5.3269, -4.9524, -5.2967, -5.1922, -5.3861, -3.724, -4.3747, -3.9634, -4.6437, -4.9256, -4.9795, -4.9951, -5.2111, -5.2938, -5.2997, -5.3921, -5.396, -5.4169, -5.4199, -5.4435, -5.4599, -5.5374, -5.5479, -5.5967, -5.6233, -5.7045, -5.7241, -5.7323, -5.7336, -5.751, -5.3045, -5.7857, -5.8455, -5.8519, -5.875, -3.6809, -4.975, -4.4015, -3.9739, -4.6185, -4.5201, -4.4291, -5.3263, -4.661, -5.048, -4.8389, -5.0808, -4.9356, -4.7639, -3.8727, -5.1899, -4.4834, -4.9109, -4.6959, -5.2321, -5.1028, -5.0732, -5.0665, -3.3302, -4.2458, -4.548, -4.6244, -4.6733, -4.7153, -4.7471, -4.7731, -4.781, -4.7931, -4.8493, -4.9985, -5.0764, -5.122, -5.2111, -5.2229, -5.3874, -5.408, -5.4725, -5.5089, -5.51, -5.5147, -5.5352, -5.5727, -5.6253, -5.6682, -5.67, -5.6955, -5.8336, -5.8378, -5.3119, -4.8268, -4.8969, -4.9702, -5.2173, -4.3331, -5.1327, -4.4214, -4.0385, -5.1431, -4.7467, -5.051, -4.8771, -4.4559, -4.6264, -4.8874, -4.532, -4.6181, -4.9102, -4.4374, -4.9855, -4.8629, -2.9514, -3.1505, -3.4559, -3.4676, -3.8265, -4.0543, -4.1238, -4.2267, -4.2292, -4.2797, -4.2804, -4.4138, -4.5262, -4.6013, -4.6149, -4.8181, -4.9099, -4.9123, -4.9753, -4.976, -4.9842, -5.0604, -5.0809, -5.1143, -5.1465, -5.157, -5.17, -5.1858, -5.1989, -5.247, -2.8672, -3.3036, -2.7013, -4.4999, -3.7284, -4.7249, -5.0408, -5.0132, -2.7487, -2.85, -3.232, -3.8877, -3.9499, -4.2054, -4.2358, -4.4303, -4.554, -4.5558, -4.5729, -4.6372, -4.6459, -4.7369, -4.9075, -4.9745, -1.9978, -5.0378, -5.1126, -5.1695, -5.1781, -5.1866, -5.2156, -5.2277, -5.2406, -5.25, -5.2672, -5.2795, -5.3161, -5.3429, -3.7844, -4.5341, -4.9976, -4.58, -4.4791, -4.8186, -4.8912, -5.0961, -2.3499, -2.7829, -3.3129, -3.5847, -3.7824, -3.9998, -4.0749, -4.0766, -4.2096, -4.2143, -4.2448, -4.3439, -4.3877, -4.3926, -4.4255, -4.4697, -4.6148, -4.6351, -4.6599, -4.6761, -4.7817, -4.8086, -4.8112, -4.8238, -4.8584, -4.9346, -4.944, -4.9478, -4.9871, -5.0137, -3.5758, -4.8706, -3.3361, -3.4676, -3.4827, -3.9917, -4.0241, -4.0736, -4.1954, -4.2065, -4.3067, -4.4635, -4.4869, -4.5735, -4.5991, -4.6746, -4.7835, -4.7905, -4.791, -4.799, -4.8507, -4.8963, -4.9148, -4.997, -5.0401, -5.0704, -5.1173, -5.1678, -5.1764, -5.2855, -5.3191, -5.3265, -3.4039, -4.277, -4.4561, -4.0967, -4.0709, -4.576, -4.5772, -4.6413, -4.4947, -4.6093, -4.7541, -1.5057, -2.6815, -2.9196, -3.3473, -3.6095, -3.7844, -4.1547, -4.167, -4.3011, -4.32, -4.384, -4.4799, -4.6717, -4.6895, -4.8961, -4.945, -4.9663, -4.9691, -5.0647, -5.0703, -5.1005, -5.122, -5.1846, -5.2184, -5.2674, -5.2908, -5.2918, -5.3083, -5.3384, -5.3395, -4.1253, -5.1163, -5.2957, -2.1444, -3.3317, -3.4069, -3.4131, -3.4388, -3.876, -3.8889, -4.0222, -4.2262, -4.2569, -4.281, -4.2936, -4.4468, -4.465, -4.4844, -4.4847, -4.52, -4.5315, -4.541, -4.5457, -4.5594, -4.6137, -4.6611, -4.669, -4.698, -4.744, -4.7786, -4.8228, -4.8354, -4.9015, -1.3789, -3.2024, -3.2966, -3.7325, -3.8743, -3.9155, -4.133, -4.2685, -4.5623, -4.5965, -4.7128, -4.7191, -4.7342, -4.7562, -4.9648, -5.0046, -5.1334, -5.2164, -5.2798, -5.3684, -5.3832, -5.4101, -5.4464, -5.4708, -5.6409, -5.6451, -5.7008, -5.724, -5.7621, -5.8805, -3.5815, -4.126], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3931, 0.393, 0.3929, 0.3929, 0.3928, 0.3928, 0.3928, 0.3927, 0.3926, 0.3926, 0.3925, 0.3925, 0.3925, 0.3925, 0.3925, 0.3924, 0.3924, 0.3924, 0.3924, 0.3924, 0.3923, 0.3923, 0.3922, 0.3921, 0.3921, 0.392, 0.392, 0.3919, 0.3918, 0.3918, 0.3909, 0.3849, 0.3691, 0.3886, 0.3504, 0.3316, 0.3148, 0.3465, 0.277, 0.1102, 0.3403, 0.2494, 0.1602, -0.0188, 0.0458, 1.9628, 1.9621, 1.9618, 1.9617, 1.961, 1.9609, 1.9609, 1.9602, 1.9599, 1.9599, 1.9596, 1.9596, 1.9595, 1.9595, 1.9594, 1.9593, 1.959, 1.9589, 1.9587, 1.9585, 1.9581, 1.958, 1.958, 1.958, 1.9579, 1.9578, 1.9577, 1.9573, 1.9573, 1.9571, 1.9564, 1.936, 1.8874, 1.7792, 1.7917, 1.7208, 1.6764, 1.8545, 1.6711, 1.7736, 1.6849, 1.7196, 1.5975, 1.373, 0.4612, 1.6692, 0.69, 1.1243, 0.736, 1.6753, 1.3037, 0.5568, 0.3903, 2.4458, 2.4446, 2.4439, 2.4436, 2.4435, 2.4434, 2.4433, 2.4432, 2.4431, 2.4431, 2.4429, 2.4423, 2.4419, 2.4417, 2.4413, 2.4412, 2.4402, 2.4401, 2.4396, 2.4394, 2.4394, 2.4393, 2.4392, 2.4389, 2.4385, 2.4381, 2.4381, 2.4379, 2.4366, 2.4366, 2.4356, 2.4099, 2.4116, 2.4036, 2.4131, 2.3483, 2.3977, 2.3034, 2.2206, 2.3455, 2.2357, 2.2387, 2.1516, 1.468, 1.4356, 1.8151, 1.1279, 1.1645, 1.6911, 0.2332, 1.4017, 0.3389, 3.5744, 3.574, 3.5732, 3.5732, 3.5719, 3.5709, 3.5705, 3.5699, 3.5699, 3.5695, 3.5695, 3.5686, 3.5677, 3.567, 3.5669, 3.5649, 3.5638, 3.5637, 3.5629, 3.5629, 3.5628, 3.5618, 3.5615, 3.561, 3.5605, 3.5603, 3.5601, 3.5599, 3.5597, 3.5589, 3.5329, 3.2827, 2.723, 2.9137, 1.9026, 2.1825, 2.7499, 0.1602, 3.8657, 3.8654, 3.8645, 3.8616, 3.8612, 3.8593, 3.8591, 3.8573, 3.8559, 3.8559, 3.8557, 3.8549, 3.8548, 3.8536, 3.851, 3.8499, 3.8491, 3.8488, 3.8473, 3.8461, 3.8459, 3.8458, 3.8451, 3.8449, 3.8446, 3.8444, 3.844, 3.8437, 3.8428, 3.8421, 3.6668, 3.4984, 3.6763, 2.7847, 2.4281, 2.9977, 0.7387, 2.4899, 4.4195, 4.4183, 4.4158, 4.414, 4.4123, 4.41, 4.4091, 4.4091, 4.4073, 4.4072, 4.4067, 4.4052, 4.4045, 4.4044, 4.4038, 4.403, 4.4001, 4.3996, 4.3991, 4.3987, 4.3962, 4.3955, 4.3954, 4.3951, 4.3942, 4.392, 4.3917, 4.3916, 4.3904, 4.3896, 3.2764, 3.0536, 4.4171, 4.4162, 4.4161, 4.4115, 4.4111, 4.4105, 4.4089, 4.4088, 4.4073, 4.4046, 4.4042, 4.4025, 4.4019, 4.4003, 4.3977, 4.3975, 4.3975, 4.3973, 4.396, 4.3947, 4.3942, 4.3918, 4.3904, 4.3894, 4.3878, 4.386, 4.3857, 4.3815, 4.3801, 4.3798, 3.9893, 3.8745, 3.9235, 3.3089, 2.9931, 3.0541, 2.9194, 2.7235, 1.7941, 2.0165, 2.6971, 4.4608, 4.4584, 4.4575, 4.4552, 4.4533, 4.4517, 4.4471, 4.447, 4.4448, 4.4445, 4.4434, 4.4416, 4.4373, 4.4369, 4.4313, 4.4298, 4.4291, 4.429, 4.4258, 4.4256, 4.4245, 4.4237, 4.4213, 4.4199, 4.4179, 4.4168, 4.4168, 4.4161, 4.4147, 4.4146, 1.2546, 3.6353, 3.9837, 4.8576, 4.851, 4.8503, 4.8502, 4.8499, 4.8442, 4.844, 4.8416, 4.8374, 4.8367, 4.8361, 4.8358, 4.8317, 4.8312, 4.8306, 4.8306, 4.8296, 4.8292, 4.8289, 4.8288, 4.8284, 4.8266, 4.825, 4.8247, 4.8237, 4.822, 4.8206, 4.8188, 4.8183, 4.8155, 5.1136, 5.1045, 5.1034, 5.0969, 5.0941, 5.0932, 5.0879, 5.084, 5.0735, 5.072, 5.0668, 5.0665, 5.0658, 5.0647, 5.0533, 5.0509, 5.0423, 5.0363, 5.0306, 5.0238, 5.022, 5.0201, 5.0167, 5.0144, 4.9968, 4.9963, 4.9899, 4.9872, 4.9825, 4.967, 3.7463, 2.8687]}, \"token.table\": {\"Topic\": [1, 2, 8, 1, 4, 2, 10, 2, 3, 10, 9, 1, 2, 1, 2, 3, 5, 10, 1, 3, 10, 6, 1, 2, 3, 3, 5, 1, 1, 3, 6, 8, 8, 1, 2, 2, 3, 8, 1, 2, 2, 3, 5, 5, 2, 6, 5, 6, 1, 2, 3, 1, 4, 8, 9, 4, 9, 1, 7, 1, 8, 8, 6, 4, 7, 10, 4, 4, 1, 3, 7, 1, 9, 6, 1, 2, 7, 3, 8, 7, 1, 2, 3, 5, 7, 5, 3, 10, 2, 9, 5, 9, 1, 2, 10, 2, 8, 9, 9, 10, 10, 6, 6, 1, 3, 4, 1, 1, 4, 1, 7, 6, 1, 2, 2, 5, 1, 2, 7, 1, 3, 7, 5, 2, 1, 10, 3, 9, 9, 3, 3, 8, 4, 1, 4, 8, 8, 9, 10, 10, 1, 2, 8, 10, 3, 9, 2, 4, 10, 1, 5, 7, 7, 1, 8, 6, 8, 6, 7, 4, 1, 4, 6, 10, 4, 1, 3, 10, 4, 8, 1, 5, 7, 9, 7, 1, 5, 1, 2, 5, 8, 2, 6, 3, 1, 3, 8, 3, 1, 2, 1, 2, 10, 2, 7, 1, 7, 4, 1, 5, 3, 8, 4, 2, 2, 10, 8, 1, 3, 4, 5, 9, 1, 3, 1, 5, 9, 1, 2, 4, 1, 2, 1, 3, 2, 2, 4, 10, 10, 1, 2, 3, 4, 1, 2, 3, 1, 3, 8, 6, 1, 2, 1, 3, 1, 2, 1, 5, 8, 4, 1, 3, 8, 8, 7, 10, 1, 2, 3, 3, 1, 10, 4, 4, 5, 2, 6, 1, 2, 9, 10, 7, 1, 2, 7, 9, 9, 4, 1, 2, 3, 7, 2, 1, 2, 3, 7, 1, 2, 2, 6, 5, 1, 2, 3, 1, 7, 5, 7, 5, 7, 6, 9, 3, 2, 1, 1, 4, 1, 3, 7, 5, 7, 1, 2, 3, 1, 4, 3, 3, 7, 2, 1, 2, 1, 2, 3, 10, 5, 2, 7, 7, 5, 8, 6, 1, 2, 9, 7, 4, 6, 1, 6, 6, 8, 6, 5, 6, 6, 5, 6, 2, 2, 6, 3, 3, 6, 5, 5, 2, 4, 1, 4, 1, 2, 3, 3, 2, 1, 4, 3, 4, 9, 3, 2, 7, 2, 3, 6, 3, 3, 4, 4, 2, 1, 2, 5, 1, 2, 5, 1, 2, 7, 1, 8, 1, 3, 6, 8, 2, 10, 9, 7, 3, 1, 2, 5, 10, 10, 9, 9, 1, 7, 1, 8, 4, 5, 5, 2, 7, 1, 2, 3, 2, 7, 3, 8, 1, 5, 7, 1, 2, 3, 4, 8, 8, 1, 3, 1, 1, 2, 5, 6, 9, 9, 1, 3, 1, 3, 9, 1, 1, 7, 1, 7, 6, 9, 1, 2, 3, 7, 4, 5, 3, 1, 2, 10, 2, 4, 2, 8, 2, 9, 10, 1, 10, 10, 5, 9, 9, 2, 5, 2, 5, 5, 7, 2, 1, 10, 6, 1, 1, 3], \"Freq\": [0.3059543204269658, 0.6941053239537134, 0.9903223637571521, 0.9997261701376494, 0.9918745735278459, 0.9931349132040507, 0.8335331806064034, 0.9960854606412151, 0.9960445358905781, 0.9907321749144568, 0.9864167860654555, 0.2147686068489239, 0.7845019944620415, 0.9479612153399493, 0.0038417881067475145, 0.047061904307657054, 0.9669783408396818, 0.9756170083811175, 0.635705906520574, 0.36346413937835514, 0.8535196288047305, 0.9975772665887248, 0.5996777765283631, 0.023589809014573287, 0.3761953753376687, 0.9986651797122537, 0.9862274540120491, 0.998939948496298, 0.04332502267190099, 0.9531504987818218, 0.9906288344111469, 0.9752777632560492, 0.9902919288033076, 0.2147934085616306, 0.7841664122091275, 0.1849049963076102, 0.8126087995623922, 0.9736830748678036, 0.92435544613206, 0.07509015738174929, 0.9974535760477694, 0.9967340801314274, 0.9923476557396961, 0.9877949923246514, 0.7433212089082852, 0.2569505413510122, 0.9800370069001089, 0.9862181682939327, 0.6867243999147876, 0.0355759893205463, 0.2770614925872848, 0.5540582487365545, 0.4416406330508768, 0.9913139384040468, 0.9478242688204849, 0.9916883268046518, 0.9888048796173541, 0.6665568028569376, 0.32781482107718246, 0.9992030291172869, 0.9982323531959463, 0.9877527160345907, 0.983304006824335, 0.9959940880462025, 0.9742940348779143, 0.8756237473061945, 0.992264554616672, 0.980746957542712, 0.03230002816274292, 0.9643865551447528, 0.9823764316064372, 0.9980996291971135, 0.9783013491256827, 0.9836881704143093, 0.023321241762784405, 0.9728289421047208, 0.9926191356791334, 0.9968113330459205, 0.9907846035226977, 0.9896656567427415, 0.42013463288293396, 0.008237933978096744, 0.1482828116057414, 0.42013463288293396, 0.9697469556875769, 0.9973392919179799, 0.9927229223267242, 0.9506669778032933, 0.9963376980633064, 0.9589840374694728, 0.984956120096339, 0.9650051012578662, 0.48078195526984935, 0.5169914749136036, 0.9956426551899416, 0.9956823647250889, 0.9291082177128319, 0.9858047311006235, 0.9830445767164758, 0.830432771369576, 0.9683118288641683, 0.9876350465985064, 0.9713118917265268, 0.5279700132352569, 0.4693066784313395, 0.9960901613451421, 0.9997383720144711, 0.9997141666378813, 0.9842145413133797, 0.7718868497528762, 0.22139390264229783, 0.984046011702652, 0.2530646336170727, 0.7465406691703644, 0.9942044371007924, 0.004734306843337107, 0.2420596837544978, 0.7578504117547361, 0.9905258095287347, 0.18607346707533984, 0.8087039145966692, 0.9527519744154879, 0.9844273427536402, 0.9982400723063511, 0.9987802628905859, 0.9298584532108835, 0.9976076465619862, 0.990972116194353, 0.9750744659712085, 0.9987153321978808, 0.5457655101909495, 0.4408106043849977, 0.9972894801092604, 0.9991821898173211, 0.9786213264554303, 0.9719900571693766, 0.9611605626582164, 0.9521185966977338, 0.9975370972955219, 0.9655580388267285, 0.17060469720792068, 0.8256048739883304, 0.9371117439924352, 0.9582174486667168, 0.9857247340274694, 0.9962212706987964, 0.9916275903447215, 0.9872195602501574, 0.8775337393961112, 0.9984760327516579, 0.9938848649043847, 0.9719521937188785, 0.9519272907389166, 0.9986292305443425, 0.9701801622456026, 0.9666184103864505, 0.9706428161739834, 0.996255520687844, 0.9442388211772962, 0.9895425577622085, 0.2528442163012504, 0.7464924481275013, 0.9812730678279761, 0.9444912433248235, 0.9968766455343658, 0.20138151610013907, 0.7968458266376193, 0.9570264147484562, 0.9856486385206743, 0.9939574795851664, 0.9989279563654342, 0.21886816469511117, 0.5759688544608188, 0.1958294105166784, 0.9747327314083415, 0.15537615517502695, 0.83514683406577, 0.24862043792353444, 0.7503275491824033, 0.9722174407079847, 0.972494841376546, 0.9897001138520156, 0.9713961815665072, 0.997946534925485, 0.027361636918860573, 0.9644977013898353, 0.9829025596323606, 0.9881593646357348, 0.16744807592183783, 0.8320076272366318, 0.0012432534981801995, 0.9983325590387002, 0.9417292632434366, 0.9984727330791184, 0.9931450857700725, 0.39066804624879475, 0.6077058497203474, 0.9981371047386332, 0.30679468821342554, 0.6954012932837645, 0.9973058635697744, 0.9810049904400465, 0.9939172556430769, 0.9950327973652277, 0.9990468005635843, 0.8979184651428488, 0.9714905135019051, 0.4652161400554664, 0.5328347650635284, 0.9750551676041556, 0.9980459621515635, 0.9625889951061497, 0.029744764089500542, 0.9667048329087676, 0.9993814309914966, 0.9728437437215574, 0.9749964748227964, 0.40531429537789554, 0.1687553943580829, 0.4264087196726559, 0.2521052550943659, 0.7469785336129359, 0.03704764000702122, 0.9579461201815487, 0.9975213327249505, 0.9977428738820396, 0.9956583762954732, 0.8937074969383911, 0.9389097580734128, 0.7531204682178337, 0.033348507817763856, 0.025937728302705222, 0.18712218275523054, 0.9761477888885179, 0.023471729011463657, 0.00046022998061693443, 0.9577712181141399, 0.0007206705930128968, 0.040357553208722224, 0.9798270937520053, 0.7067450077175716, 0.2930220977217859, 0.9996500580180914, 0.995636964528026, 0.5675908069179931, 0.43159105367113904, 0.745962252939338, 0.2551976128476683, 0.9667878620336705, 0.9854950290233143, 0.09497809793823478, 0.9022919304132304, 0.9988889817610862, 0.9679537372086344, 0.9783104752730415, 0.9894919076313752, 0.3927060111288147, 0.25456821826943266, 0.3512646732710001, 0.9899031646565967, 0.9996118196853939, 0.8997259331448504, 0.9837220646792195, 0.9880251533375141, 0.9927826129258034, 0.9952169688528524, 0.9842944023502128, 0.997508433990922, 0.002009080430998836, 0.9712307534423081, 0.9278511770137364, 0.9890507685181885, 0.999577870675598, 0.0002534105388960826, 0.9894415156550701, 0.9680612231352295, 0.9800104625740793, 0.9935392160552673, 0.7535016722996506, 0.22255644151592502, 0.023800120025593802, 0.9677057319430754, 0.9981286242101823, 0.9948713211328111, 0.003768451973987921, 0.9938162249018574, 0.9905305996633984, 0.4455405173534211, 0.5546211267744311, 0.9939371447094477, 0.9767573250360506, 0.9827113479625873, 0.8659873953297744, 0.012061105784537248, 0.12121411313459934, 0.7386049311328795, 0.2530405782584865, 0.8177193042879205, 0.17726782120926948, 0.9916286122567872, 0.9746915326087718, 0.990063447579141, 0.9770381810246435, 0.9908843263196119, 0.9969081822190607, 0.9988360555668023, 0.9994025746395038, 0.9934344811117094, 0.0076903223044512145, 0.9920515772742067, 0.9861283040769796, 0.962300166191586, 0.980242044927679, 0.12169009904991383, 0.011062736277264893, 0.8656591136959779, 0.9993782706860741, 0.9921435750986362, 0.9954167608997255, 0.9929306346190588, 0.981043604322784, 0.9962765679093526, 0.0065250444505294885, 0.9927389056877007, 0.8902686441495291, 0.00035454744888471887, 0.10920061425649341, 0.9591527638917626, 0.9758634611736788, 0.35072832695984807, 0.6474984497720272, 0.9959745438289583, 0.983956941565404, 0.9968701116939881, 0.9705127872948206, 0.9405158294532213, 0.0591212372609003, 0.9918486599861757, 0.9719848017896202, 0.9974012030363825, 0.9976827761304655, 0.6785133953655457, 0.3172678376477783, 0.969894042935606, 0.978105398477902, 0.9886420242740145, 0.9934020817572033, 0.9814294862546165, 0.9699888900525016, 0.9878025114525834, 0.9884086137140051, 0.9914824731284572, 0.9989260360773201, 0.9755189646017711, 0.9949510486050507, 0.9964814440869494, 0.9594331267595864, 0.9933485316217637, 0.9778543144108495, 0.750286547993879, 0.24898889867053506, 0.4791480721443243, 0.5177002158800745, 0.7923210919855586, 0.2070308550767766, 0.9990784377471645, 0.9978921102369509, 0.996165696040128, 0.9996454977448272, 0.9976766839831256, 0.9962433670680138, 0.9774085202373802, 0.9517594332487481, 0.9918711313054809, 0.7570789060062472, 0.2407122675507042, 0.894509496517532, 0.10035960204830846, 0.9860298278454116, 0.9914650321932579, 0.991512584788358, 0.9980503997270392, 0.9935158343095998, 0.9984888599333093, 0.010345904945073207, 0.008046814957279162, 0.9817114247880576, 0.7106868126369517, 0.2452239652979065, 0.04349255233585511, 0.15749577492145306, 0.8419966428493068, 0.9815440064282864, 0.9989691415154074, 0.9552823540471342, 0.9979997472404649, 0.9970030703706803, 0.9751371142738707, 0.9786329763394733, 0.9966872187655497, 0.8662623121629861, 0.9738436632494737, 0.9437524599457636, 0.9950125499134691, 0.09419026932793963, 0.735408641291221, 0.0652086479962659, 0.10505837732731728, 0.9772565268483961, 0.9863513375402341, 0.9612601904773452, 0.9986302811112965, 0.9832497546746454, 0.9997085913306335, 0.9439300366155903, 0.9835917211071756, 0.9905313680741339, 0.9739909948607322, 0.926360397409001, 0.07153362142154449, 0.7312889046219333, 0.0009534405536139938, 0.2679167955655323, 0.9970311174504085, 0.9642379154600514, 0.9946639006330009, 0.9771282836138673, 0.4772941287410668, 0.3409243776721906, 0.1835746649004103, 0.6623994120421103, 0.2796146190655634, 0.02462015513784835, 0.03282687351713113, 0.9590645694345808, 0.9616265894478031, 0.999815491100529, 0.9918981503515412, 0.9995733807126032, 0.7567779364942233, 0.0033192014758518565, 0.2356633047854818, 0.964415454282595, 0.9599002736887663, 0.9699145179375293, 0.09268190425194253, 0.9056346072618384, 0.2548536967220944, 0.7458218477602468, 0.9370213155878014, 0.998802009324073, 0.9992446941464573, 0.9943256020367564, 0.9988365700096078, 0.9976793082345794, 0.982408709699526, 0.954286187165406, 0.7339258634882723, 0.1628163178386952, 0.012524332141438093, 0.09017519141835427, 0.9861280788924065, 0.9838246219110334, 0.9926817734263153, 0.9917581540021462, 0.008157822653366655, 0.9784892812538496, 0.039978631737364545, 0.9574882301098808, 0.35581188880837655, 0.6048802109742402, 0.9970429270362663, 0.9587353393770129, 0.9732564725721191, 0.7430210726095127, 0.25272825598963017, 0.9452065699379912, 0.9713654233550301, 0.9798731298774095, 0.9763859138685925, 0.9940716552278506, 0.9898229152023487, 0.9950619247212095, 0.998630866318295, 0.9823792758610477, 0.9799475631991736, 0.995941662250414, 0.9993771674674726, 0.9241369961296424, 0.9787816648911156, 0.9991099756064533, 0.9542638208482012, 0.04513409963471222], \"Term\": [\"ability\", \"ability\", \"academic\", \"achieve\", \"acquire\", \"action\", \"activate\", \"agent\", \"ai\", \"align\", \"alignment\", \"allow\", \"allow\", \"also\", \"also\", \"also\", \"ambiguity\", \"analogy\", \"analysis\", \"analysis\", \"anchor\", \"answer\", \"application\", \"application\", \"application\", \"area\", \"argument\", \"art\", \"article\", \"article\", \"ask\", \"assistant\", \"associate\", \"attention\", \"attention\", \"automate\", \"automate\", \"bangla\", \"base\", \"base\", \"behavior\", \"bias\", \"bind\", \"business\", \"candidate\", \"candidate\", \"caption\", \"causal\", \"challenge\", \"challenge\", \"challenge\", \"character\", \"character\", \"chatgpt\", \"chemical\", \"chinese\", \"claim\", \"class\", \"class\", \"classification\", \"clinical\", \"clinical_note\", \"clinical_trial\", \"cluster\", \"clustering\", \"clwe\", \"comment\", \"commerce\", \"community\", \"community\", \"compact\", \"compare\", \"complement\", \"complete\", \"complex\", \"complex\", \"compositional\", \"comprehensive\", \"compression\", \"computational_linguistic\", \"computer_vision\", \"computer_vision\", \"computer_vision\", \"computer_vision\", \"computing\", \"concept\", \"concern\", \"concreteness\", \"condition\", \"confidence\", \"connect\", \"consistency\", \"context\", \"context\", \"contextualize\", \"control\", \"convolutional\", \"core\", \"correctness\", \"correspondence\", \"cosine\", \"criterion\", \"cultural\", \"current\", \"current\", \"database\", \"dataset\", \"datum\", \"demand\", \"dependency\", \"dependency\", \"dependent\", \"describe\", \"describe\", \"description\", \"description\", \"design\", \"design\", \"desire\", \"development\", \"development\", \"diagram\", \"dialog\", \"dialogue\", \"different\", \"differently\", \"direction\", \"discourse\", \"discovery\", \"discuss\", \"disease\", \"disease\", \"document\", \"domain\", \"drug\", \"dual\", \"ehr\", \"electronic\", \"embedding\", \"emph\", \"enable\", \"enable\", \"encompass\", \"enforce\", \"engineering\", \"entity\", \"environment\", \"estimate\", \"euclidean\", \"evaluate\", \"event\", \"evolutionary\", \"execute\", \"experiment\", \"experimental\", \"expertise\", \"explainable\", \"explanation\", \"expressiveness\", \"external\", \"extraction\", \"extraction\", \"extractive\", \"extrinsic\", \"fast\", \"field\", \"field\", \"filter\", \"final\", \"financial\", \"find\", \"formal\", \"formal\", \"formal\", \"formalism\", \"frame\", \"frame\", \"framework\", \"framework\", \"freely\", \"frozen\", \"function\", \"fusion\", \"future\", \"game\", \"game\", \"gaussian\", \"gender\", \"generate\", \"generate\", \"generation\", \"generation\", \"glove\", \"gpt\", \"grammar\", \"grammatical\", \"grammatical\", \"graph\", \"ground\", \"ground\", \"handle\", \"health\", \"healthcare\", \"hierarchical\", \"human\", \"hyperbolic\", \"hyperparameter\", \"identify\", \"identify\", \"idiom\", \"image\", \"imbalance\", \"impact\", \"impact\", \"improve\", \"induction\", \"informal\", \"information\", \"information\", \"information\", \"input\", \"input\", \"insight\", \"insight\", \"instruction\", \"interaction\", \"interface\", \"intrinsically\", \"intuitive\", \"knowledge\", \"knowledge\", \"knowledge\", \"knowledge\", \"language\", \"language\", \"language\", \"large\", \"large\", \"large\", \"latency\", \"learn\", \"learn\", \"learning\", \"legal\", \"level\", \"level\", \"lexical\", \"lexical\", \"library\", \"link\", \"literature\", \"literature\", \"llm\", \"log\", \"logic\", \"loss\", \"machine\", \"machine\", \"machine\", \"maintain\", \"many\", \"masking\", \"matching\", \"material\", \"meaning\", \"mechanism\", \"mention\", \"method\", \"method\", \"methodological\", \"mikolov\", \"minimal\", \"model\", \"model\", \"modification\", \"molecular\", \"molecule\", \"name\", \"natural\", \"natural\", \"natural\", \"negation\", \"network\", \"new\", \"new\", \"note\", \"noun\", \"novel\", \"novel\", \"object\", \"ontology\", \"operation\", \"paper\", \"paper\", \"paper\", \"parallel\", \"parallel\", \"parse\", \"parse\", \"parser\", \"pass\", \"passage\", \"path\", \"patient\", \"pattern\", \"perform\", \"performance\", \"persian\", \"platform\", \"platform\", \"polarity\", \"possibility\", \"possibly\", \"potential\", \"potential\", \"potential\", \"pre_traine\", \"precision\", \"previously\", \"privacy\", \"procedural\", \"procedure\", \"process\", \"process\", \"processing\", \"processing\", \"processing\", \"procruste\", \"professional\", \"program\", \"program\", \"programming\", \"promising\", \"prompt\", \"prone\", \"propose\", \"propose\", \"protein\", \"quantum\", \"query\", \"question\", \"question_answere\", \"question_answere\", \"raise\", \"random\", \"rank\", \"rapid\", \"rationale\", \"rationalization\", \"read\", \"reading_comprehension\", \"reason\", \"reasoning\", \"recall\", \"recommendation\", \"record\", \"refine\", \"region\", \"relatedness\", \"relation\", \"relation\", \"relevant\", \"relevant\", \"representation\", \"representation\", \"research\", \"researcher\", \"response\", \"result\", \"retrieval\", \"review\", \"right\", \"rigorous\", \"risk\", \"rule\", \"rule\", \"scenario\", \"scenario\", \"scene\", \"science\", \"scientific\", \"search\", \"segmentation\", \"self\", \"semantic\", \"semantic\", \"semantic\", \"sentence\", \"sentence\", \"sentence\", \"sequence\", \"sequence\", \"session\", \"set\", \"severity\", \"show\", \"significantly\", \"simplify\", \"simply\", \"single\", \"skip_gram\", \"smile\", \"snippet\", \"social\", \"space\", \"space\", \"space\", \"space\", \"spanish\", \"specification\", \"specify\", \"speech\", \"stack\", \"state\", \"status\", \"store\", \"story\", \"stream\", \"structure\", \"structure\", \"study\", \"study\", \"study\", \"style\", \"substitution\", \"survey\", \"symptom\", \"syntactic\", \"syntactic\", \"syntactic\", \"system\", \"system\", \"system\", \"system\", \"table\", \"tabular\", \"task\", \"technology\", \"text\", \"textual\", \"textual\", \"textual\", \"thereby\", \"think\", \"time_consuming\", \"tool\", \"tool\", \"topic\", \"topic\", \"trace\", \"train\", \"training\", \"transformation\", \"transformer\", \"tree\", \"trial\", \"trigger\", \"type\", \"type\", \"type\", \"type\", \"uncertainty\", \"unified\", \"unstructured\", \"use\", \"use\", \"usefulness\", \"user\", \"user\", \"utilization\", \"utilization\", \"utterance\", \"variance\", \"vec\", \"vector\", \"vector\", \"vector_space\", \"verb\", \"verification\", \"verify\", \"version\", \"video\", \"vision\", \"visual\", \"visualization\", \"vital\", \"weight\", \"well\", \"window\", \"without_require\", \"word\", \"work\", \"work\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 7, 10, 1, 4, 6, 8, 9, 3, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1603220905914333283587114792\", ldavis_el1603220905914333283587114792_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1603220905914333283587114792\", ldavis_el1603220905914333283587114792_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1603220905914333283587114792\", ldavis_el1603220905914333283587114792_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "4     -0.319067  0.004828       1        1  67.486182\n",
       "6     -0.249504 -0.276739       2        1  14.036249\n",
       "9     -0.228769  0.310931       3        1   8.658213\n",
       "0      0.041676 -0.073478       4        1   2.798375\n",
       "3      0.105232 -0.056030       5        1   2.090894\n",
       "5      0.135722  0.031819       6        1   1.201254\n",
       "7      0.115900 -0.040708       7        1   1.199699\n",
       "8      0.125046  0.056269       8        1   1.154163\n",
       "2      0.141124  0.026851       9        1   0.774614\n",
       "1      0.132640  0.016259      10        1   0.600356, topic_info=               Term         Freq        Total Category  logprob  loglift\n",
       "254     information  1327.000000  1327.000000  Default  30.0000  30.0000\n",
       "25            large  1387.000000  1387.000000  Default  29.0000  29.0000\n",
       "1892            llm   771.000000   771.000000  Default  28.0000  28.0000\n",
       "270        semantic   869.000000   869.000000  Default  27.0000  27.0000\n",
       "93            model  7892.000000  7892.000000  Default  26.0000  26.0000\n",
       "...             ...          ...          ...      ...      ...      ...\n",
       "3873  intrinsically     5.905597     6.713606  Topic10  -5.7240   4.9872\n",
       "4169         window     5.684447     6.492544  Topic10  -5.7621   4.9825\n",
       "4737         anchor     5.050076     5.858096  Topic10  -5.8805   4.9670\n",
       "377          vector    50.319024   197.840957  Topic10  -3.5815   3.7463\n",
       "1845          space    29.190034   276.037007  Topic10  -4.1260   2.8687\n",
       "\n",
       "[424 rows x 6 columns], token_table=      Topic      Freq             Term\n",
       "term                                  \n",
       "47        1  0.305954          ability\n",
       "47        2  0.694105          ability\n",
       "3214      8  0.990322         academic\n",
       "233       1  0.999726          achieve\n",
       "1123      4  0.991875          acquire\n",
       "...     ...       ...              ...\n",
       "4169     10  0.924137           window\n",
       "2896      6  0.978782  without_require\n",
       "277       1  0.999110             word\n",
       "118       1  0.954264             work\n",
       "118       3  0.045134             work\n",
       "\n",
       "[493 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 7, 10, 1, 4, 6, 8, 9, 3, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17f24203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dglover\\AppData\\Local\\Temp\\ipykernel_16032\\1000666203.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7104</td>\n",
       "      <td>language, model, task, natural, text, use, pro...</td>\n",
       "      <td>[natural, language, processing, datum, analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4938</td>\n",
       "      <td>language, model, task, natural, text, use, pro...</td>\n",
       "      <td>[natural, language, processing, aim, investiga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5932</td>\n",
       "      <td>language, model, task, natural, text, use, pro...</td>\n",
       "      <td>[technical, note, describe, set, baseline, too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>language, model, task, natural, text, use, pro...</td>\n",
       "      <td>[little, work, natural, language, processing, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6418</td>\n",
       "      <td>language, model, task, natural, text, use, pro...</td>\n",
       "      <td>[note, course, d, natural, language, understan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5429</td>\n",
       "      <td>language, model, task, natural, text, use, pro...</td>\n",
       "      <td>[past, year, neural_network, emerge, powerful,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7419</td>\n",
       "      <td>language, model, task, natural, text, use, pro...</td>\n",
       "      <td>[computer, scientist, work, natural, language,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8983</td>\n",
       "      <td>language, model, task, natural, text, use, pro...</td>\n",
       "      <td>[fourth, large, language, family, world, dravi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>language, model, task, natural, text, use, pro...</td>\n",
       "      <td>[model, base, language, specification, applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6736</td>\n",
       "      <td>language, model, task, natural, text, use, pro...</td>\n",
       "      <td>[natural, language, process, lead, application...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0               4              0.7104   \n",
       "1            1               4              0.4938   \n",
       "2            2               4              0.5932   \n",
       "3            3               4              0.7835   \n",
       "4            4               4              0.6418   \n",
       "5            5               4              0.5429   \n",
       "6            6               4              0.7419   \n",
       "7            7               4              0.8983   \n",
       "8            8               4              0.6667   \n",
       "9            9               4              0.6736   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  language, model, task, natural, text, use, pro...   \n",
       "1  language, model, task, natural, text, use, pro...   \n",
       "2  language, model, task, natural, text, use, pro...   \n",
       "3  language, model, task, natural, text, use, pro...   \n",
       "4  language, model, task, natural, text, use, pro...   \n",
       "5  language, model, task, natural, text, use, pro...   \n",
       "6  language, model, task, natural, text, use, pro...   \n",
       "7  language, model, task, natural, text, use, pro...   \n",
       "8  language, model, task, natural, text, use, pro...   \n",
       "9  language, model, task, natural, text, use, pro...   \n",
       "\n",
       "                                                Text  \n",
       "0  [natural, language, processing, datum, analyti...  \n",
       "1  [natural, language, processing, aim, investiga...  \n",
       "2  [technical, note, describe, set, baseline, too...  \n",
       "3  [little, work, natural, language, processing, ...  \n",
       "4  [note, course, d, natural, language, understan...  \n",
       "5  [past, year, neural_network, emerge, powerful,...  \n",
       "6  [computer, scientist, work, natural, language,...  \n",
       "7  [fourth, large, language, family, world, dravi...  \n",
       "8  [model, base, language, specification, applica...  \n",
       "9  [natural, language, process, lead, application...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=texts)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eaf0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "412c1ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>language, model, task, natural, text, use, pro...</td>\n",
       "      <td>[deep, large, pre_traine, model, state, art, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>process, human, natural, generation, generate,...</td>\n",
       "      <td>[letter, introduce, erra, embody, learn, archi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.4952</td>\n",
       "      <td>research, field, bias, tool, potential, proces...</td>\n",
       "      <td>[deep, neural_network, often, learn, unintende...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0          4              0.9310   \n",
       "1          6              0.5739   \n",
       "2          9              0.4952   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  language, model, task, natural, text, use, pro...   \n",
       "1  process, human, natural, generation, generate,...   \n",
       "2  research, field, bias, tool, potential, proces...   \n",
       "\n",
       "                                                Text  \n",
       "0  [deep, large, pre_traine, model, state, art, v...  \n",
       "1  [letter, introduce, erra, embody, learn, archi...  \n",
       "2  [deep, neural_network, often, learn, unintende...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6892b369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Representative Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>language, model, task, natural, text, use, processing, base, method, dataset</td>\n",
       "      <td>[deep, large, pre_traine, model, state, art, various, natural, language, processing, task, huge,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>process, human, natural, generation, generate, network, structure, framework, system, attention</td>\n",
       "      <td>[letter, introduce, erra, embody, learn, architecture, enable, robot, jointly, obtain, fundament...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.4952</td>\n",
       "      <td>research, field, bias, tool, potential, processing, application, study, significantly, challenge</td>\n",
       "      <td>[deep, neural_network, often, learn, unintended, bias, training, harmful, effect, deploy, real_w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0          4              0.9310   \n",
       "1          6              0.5739   \n",
       "2          9              0.4952   \n",
       "\n",
       "                                                                                           Keywords  \\\n",
       "0                      language, model, task, natural, text, use, processing, base, method, dataset   \n",
       "1   process, human, natural, generation, generate, network, structure, framework, system, attention   \n",
       "2  research, field, bias, tool, potential, processing, application, study, significantly, challenge   \n",
       "\n",
       "                                                                                   Representative Text  \n",
       "0  [deep, large, pre_traine, model, state, art, various, natural, language, processing, task, huge,...  \n",
       "1  [letter, introduce, erra, embody, learn, architecture, enable, robot, jointly, obtain, fundament...  \n",
       "2  [deep, neural_network, often, learn, unintended, bias, training, harmful, effect, deploy, real_w...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a051c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, text, use, processing, base, method, dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, text, use, processing, base, method, dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, text, use, processing, base, method, dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, text, use, processing, base, method, dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, text, use, processing, base, method, dataset</td>\n",
       "      <td>3537.0</td>\n",
       "      <td>0.9941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, text, use, processing, base, method, dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3554</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, text, use, processing, base, method, dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, text, use, processing, base, method, dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, text, use, processing, base, method, dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>4</td>\n",
       "      <td>language, model, task, natural, text, use, processing, base, method, dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3558 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dominant_Topic  \\\n",
       "0                  4   \n",
       "1                  4   \n",
       "2                  4   \n",
       "3                  4   \n",
       "4                  4   \n",
       "...              ...   \n",
       "3553               4   \n",
       "3554               4   \n",
       "3555               4   \n",
       "3556               4   \n",
       "3557               4   \n",
       "\n",
       "                                                                    Topic_Keywords  \\\n",
       "0     language, model, task, natural, text, use, processing, base, method, dataset   \n",
       "1     language, model, task, natural, text, use, processing, base, method, dataset   \n",
       "2     language, model, task, natural, text, use, processing, base, method, dataset   \n",
       "3     language, model, task, natural, text, use, processing, base, method, dataset   \n",
       "4     language, model, task, natural, text, use, processing, base, method, dataset   \n",
       "...                                                                            ...   \n",
       "3553  language, model, task, natural, text, use, processing, base, method, dataset   \n",
       "3554  language, model, task, natural, text, use, processing, base, method, dataset   \n",
       "3555  language, model, task, natural, text, use, processing, base, method, dataset   \n",
       "3556  language, model, task, natural, text, use, processing, base, method, dataset   \n",
       "3557  language, model, task, natural, text, use, processing, base, method, dataset   \n",
       "\n",
       "      Num_Documents  Perc_Documents  \n",
       "0               NaN             NaN  \n",
       "1               NaN             NaN  \n",
       "2               NaN             NaN  \n",
       "3               NaN             NaN  \n",
       "4            3537.0          0.9941  \n",
       "...             ...             ...  \n",
       "3553            NaN             NaN  \n",
       "3554            NaN             NaN  \n",
       "3555            NaN             NaN  \n",
       "3556            NaN             NaN  \n",
       "3557            NaN             NaN  \n",
       "\n",
       "[3558 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032781fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c4de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4253ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d24bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16639bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4470cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "267a49ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input C:\\Users\\dglover\\AppData\\Local\\Temp\\57838c_corpus.txt --output C:\\Users\\dglover\\AppData\\Local\\Temp\\57838c_corpus.mallet' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\u001b[39;00m\n\u001b[0;32m      2\u001b[0m mallet_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mallet-2.0.8/bin/mallet\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# update this path\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m ldamallet \u001b[38;5;241m=\u001b[39m \u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrappers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLdaMallet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmallet_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid2word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid2word\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py:131\u001b[0m, in \u001b[0;36mLdaMallet.__init__\u001b[1;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold, random_seed)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_seed \u001b[38;5;241m=\u001b[39m random_seed\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py:272\u001b[0m, in \u001b[0;36mLdaMallet.train\u001b[1;34m(self, corpus)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, corpus):\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;124;03m\"\"\"Train Mallet LDA.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    270\u001b[0m \n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 272\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmallet_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m train-topics --input \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m --num-topics \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m  --alpha \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m --optimize-interval \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\\\n\u001b[0;32m    274\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--num-threads \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m --output-state \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m --output-doc-topics \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m --output-topic-keys \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\\\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--num-iterations \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m --inferencer-filename \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m --doc-topics-threshold \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m  --random-seed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    277\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m cmd \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfcorpusmallet(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_topics, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_interval,\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfstate(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfdoctopics(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mftopickeys(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations,\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinferencer(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic_threshold, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_seed)\n\u001b[0;32m    281\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py:261\u001b[0m, in \u001b[0;36mLdaMallet.convert_input\u001b[1;34m(self, corpus, infer, serialize_corpus)\u001b[0m\n\u001b[0;32m    259\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m cmd \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfcorpustxt(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfcorpusmallet())\n\u001b[0;32m    260\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverting temporary corpus to MALLET format with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, cmd)\n\u001b[1;32m--> 261\u001b[0m \u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1932\u001b[0m, in \u001b[0;36mcheck_output\u001b[1;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m   1930\u001b[0m         error \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(retcode, cmd)\n\u001b[0;32m   1931\u001b[0m         error\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m-> 1932\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m   1933\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m   1934\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input C:\\Users\\dglover\\AppData\\Local\\Temp\\57838c_corpus.txt --output C:\\Users\\dglover\\AppData\\Local\\Temp\\57838c_corpus.mallet' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = '/mallet-2.0.8/bin/mallet' # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25744757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c9193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50bc126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
