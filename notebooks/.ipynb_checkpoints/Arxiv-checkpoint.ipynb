{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\n",
      "  Downloading arxiv-2.0.0-py3-none-any.whl (11 kB)\n",
      "Collecting requests==2.31.0\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting feedparser==6.0.10\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "     ---------------------------------------- 81.1/81.1 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dglover\\anaconda3\\lib\\site-packages (from requests==2.31.0->arxiv) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dglover\\anaconda3\\lib\\site-packages (from requests==2.31.0->arxiv) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dglover\\anaconda3\\lib\\site-packages (from requests==2.31.0->arxiv) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dglover\\anaconda3\\lib\\site-packages (from requests==2.31.0->arxiv) (2.1.1)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6048 sha256=84bdd9227a27b7b18e627889b40988e20c9d549fb3595d63560d089e76d6f665\n",
      "  Stored in directory: c:\\users\\dglover\\appdata\\local\\pip\\cache\\wheels\\83\\63\\2f\\117884c3b19d46b64d3d61690333aa80c88dc14050e269c546\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, requests, feedparser, arxiv\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "Successfully installed arxiv-2.0.0 feedparser-6.0.10 requests-2.31.0 sgmllib3k-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.24 requires PyYAML==6.0, but you have pyyaml 5.4.1 which is incompatible.\n",
      "conda-repo-cli 1.0.24 requires requests==2.28.1, but you have requests 2.31.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder = '..\\\\data\\\\PDFs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialogueLLM: Context and Emotion Knowledge-Tuned LLaMA Models for Emotion Recognition in Conversations\n",
      "VECHR: A Dataset for Explainable and Robust Classification of Vulnerability Type in the European Court of Human Rights\n",
      "Utilizing Weak Supervision To Generate Indonesian Conservation Dataset\n",
      "Can Large Language Models Explain Themselves? A Study of LLM-Generated Self-Explanations\n",
      "ViSoBERT: A Pre-Trained Language Model for Vietnamese Social Media Text Processing\n"
     ]
    }
   ],
   "source": [
    "search = arxiv.Search(\n",
    "  query=\"NLP\",\n",
    "  max_results=5,\n",
    "  sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    ")\n",
    "\n",
    "# Initialize an empty list to store dictionaries\n",
    "paper_list = []\n",
    "\n",
    "for result in arxiv.Client().results(search):\n",
    "    print(result.title)\n",
    "    # Create a dictionary for each paper\n",
    "    paper_info = {\n",
    "        'Title': result.title,\n",
    "        'PDF URL': result.pdf_url,\n",
    "        'Author' : result.authors,\n",
    "        'DOI' : result.doi,\n",
    "        'Published Date': result.published,\n",
    "        'Summary' : result.summary,\n",
    "        'Journal Ref' : result.journal_ref,\n",
    "        'Primary Category' : result.primary_category,\n",
    "        'Category' : result.categories,\n",
    "        'Entry ID' : result.entry_id\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    }\n",
    "    name = result.pdf_url.split('/')[-1] + '.pdf' #.replace('.','_')\n",
    "    result.download_source(dirpath=pdf_folder, filename = name)\n",
    "    paper_list.append(paper_info)\n",
    "\n",
    "# Print the list of dictionaries\n",
    "#for paper in paper_list:\n",
    "#    print(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(paper_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>PDF URL</th>\n",
       "      <th>Author</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Journal Ref</th>\n",
       "      <th>Primary Category</th>\n",
       "      <th>Category</th>\n",
       "      <th>Entry ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DialogueLLM: Context and Emotion Knowledge-Tun...</td>\n",
       "      <td>http://arxiv.org/pdf/2310.11374v1</td>\n",
       "      <td>[Yazhou Zhang, Mengyao Wang, Prayag Tiwari, Qi...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-17 16:15:34+00:00</td>\n",
       "      <td>Large language models (LLMs) and their variant...</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>[cs.CL]</td>\n",
       "      <td>http://arxiv.org/abs/2310.11374v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VECHR: A Dataset for Explainable and Robust Cl...</td>\n",
       "      <td>http://arxiv.org/pdf/2310.11368v1</td>\n",
       "      <td>[Shanshan Xu, Leon Staufer, Santosh T. Y. S. S...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-17 16:05:52+00:00</td>\n",
       "      <td>Recognizing vulnerability is crucial for under...</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>[cs.CL]</td>\n",
       "      <td>http://arxiv.org/abs/2310.11368v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Utilizing Weak Supervision To Generate Indones...</td>\n",
       "      <td>http://arxiv.org/pdf/2310.11258v1</td>\n",
       "      <td>[Mega Fransiska, Diah Pitaloka, Saripudin, Sat...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-17 13:23:18+00:00</td>\n",
       "      <td>Weak supervision has emerged as a promising ap...</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>[cs.CL]</td>\n",
       "      <td>http://arxiv.org/abs/2310.11258v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can Large Language Models Explain Themselves? ...</td>\n",
       "      <td>http://arxiv.org/pdf/2310.11207v1</td>\n",
       "      <td>[Shiyuan Huang, Siddarth Mamidanna, Shreedhar ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-17 12:34:32+00:00</td>\n",
       "      <td>Large language models (LLMs) such as ChatGPT h...</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>[cs.CL, cs.LG]</td>\n",
       "      <td>http://arxiv.org/abs/2310.11207v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ViSoBERT: A Pre-Trained Language Model for Vie...</td>\n",
       "      <td>http://arxiv.org/pdf/2310.11166v1</td>\n",
       "      <td>[Quoc-Nam Nguyen, Thang Chau Phan, Duc-Vu Nguy...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-17 11:34:50+00:00</td>\n",
       "      <td>English and Chinese, known as resource-rich la...</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>[cs.CL]</td>\n",
       "      <td>http://arxiv.org/abs/2310.11166v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  DialogueLLM: Context and Emotion Knowledge-Tun...   \n",
       "1  VECHR: A Dataset for Explainable and Robust Cl...   \n",
       "2  Utilizing Weak Supervision To Generate Indones...   \n",
       "3  Can Large Language Models Explain Themselves? ...   \n",
       "4  ViSoBERT: A Pre-Trained Language Model for Vie...   \n",
       "\n",
       "                             PDF URL  \\\n",
       "0  http://arxiv.org/pdf/2310.11374v1   \n",
       "1  http://arxiv.org/pdf/2310.11368v1   \n",
       "2  http://arxiv.org/pdf/2310.11258v1   \n",
       "3  http://arxiv.org/pdf/2310.11207v1   \n",
       "4  http://arxiv.org/pdf/2310.11166v1   \n",
       "\n",
       "                                              Author   DOI  \\\n",
       "0  [Yazhou Zhang, Mengyao Wang, Prayag Tiwari, Qi...  None   \n",
       "1  [Shanshan Xu, Leon Staufer, Santosh T. Y. S. S...  None   \n",
       "2  [Mega Fransiska, Diah Pitaloka, Saripudin, Sat...  None   \n",
       "3  [Shiyuan Huang, Siddarth Mamidanna, Shreedhar ...  None   \n",
       "4  [Quoc-Nam Nguyen, Thang Chau Phan, Duc-Vu Nguy...  None   \n",
       "\n",
       "             Published Date  \\\n",
       "0 2023-10-17 16:15:34+00:00   \n",
       "1 2023-10-17 16:05:52+00:00   \n",
       "2 2023-10-17 13:23:18+00:00   \n",
       "3 2023-10-17 12:34:32+00:00   \n",
       "4 2023-10-17 11:34:50+00:00   \n",
       "\n",
       "                                             Summary Journal Ref  \\\n",
       "0  Large language models (LLMs) and their variant...        None   \n",
       "1  Recognizing vulnerability is crucial for under...        None   \n",
       "2  Weak supervision has emerged as a promising ap...        None   \n",
       "3  Large language models (LLMs) such as ChatGPT h...        None   \n",
       "4  English and Chinese, known as resource-rich la...        None   \n",
       "\n",
       "  Primary Category        Category                           Entry ID  \n",
       "0            cs.CL         [cs.CL]  http://arxiv.org/abs/2310.11374v1  \n",
       "1            cs.CL         [cs.CL]  http://arxiv.org/abs/2310.11368v1  \n",
       "2            cs.CL         [cs.CL]  http://arxiv.org/abs/2310.11258v1  \n",
       "3            cs.CL  [cs.CL, cs.LG]  http://arxiv.org/abs/2310.11207v1  \n",
       "4            cs.CL         [cs.CL]  http://arxiv.org/abs/2310.11166v1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('..\\\\data\\\\arxiv_papers_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hdawson\\\\OneDrive - TP Group Plc\\\\Documents\\\\TP group\\\\_Internal Projects\\\\Hackathon\\\\SGHacks\\\\data\\\\PDFs'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = arxiv.Search(\n",
    "  query=\"NLP\",\n",
    "  max_results=5,\n",
    "  sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    ")\n",
    "\n",
    "for result in arxiv.Client().results(search):\n",
    "    title =  result.title\n",
    "    print(title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
