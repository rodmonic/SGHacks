{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\n",
      "  Downloading arxiv-2.0.0-py3-none-any.whl (11 kB)\n",
      "Collecting requests==2.31.0\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting feedparser==6.0.10\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "     ---------------------------------------- 81.1/81.1 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dglover\\anaconda3\\lib\\site-packages (from requests==2.31.0->arxiv) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dglover\\anaconda3\\lib\\site-packages (from requests==2.31.0->arxiv) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dglover\\anaconda3\\lib\\site-packages (from requests==2.31.0->arxiv) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dglover\\anaconda3\\lib\\site-packages (from requests==2.31.0->arxiv) (2.1.1)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6048 sha256=84bdd9227a27b7b18e627889b40988e20c9d549fb3595d63560d089e76d6f665\n",
      "  Stored in directory: c:\\users\\dglover\\appdata\\local\\pip\\cache\\wheels\\83\\63\\2f\\117884c3b19d46b64d3d61690333aa80c88dc14050e269c546\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, requests, feedparser, arxiv\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "Successfully installed arxiv-2.0.0 feedparser-6.0.10 requests-2.31.0 sgmllib3k-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.24 requires PyYAML==6.0, but you have pyyaml 5.4.1 which is incompatible.\n",
      "conda-repo-cli 1.0.24 requires requests==2.28.1, but you have requests 2.31.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder = '..\\\\data\\\\PDFs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = arxiv.Search(\n",
    "  query=\"NLP\",\n",
    "  max_results=5,\n",
    "  sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    ")\n",
    "\n",
    "# Initialize an empty list to store dictionaries\n",
    "paper_list = []\n",
    "\n",
    "for result in arxiv.Client().results(search):\n",
    "    print(result.title)\n",
    "    # Create a dictionary for each paper\n",
    "    paper_info = {\n",
    "        'Title': result.title,\n",
    "        'PDF URL': result.pdf_url,\n",
    "        'Author' : result.authors,\n",
    "        'DOI' : result.doi,\n",
    "        'Published Date': result.published,\n",
    "        'Summary' : result.summary,\n",
    "        'Journal Ref' : result.journal_ref,\n",
    "        'Primary Category' : result.primary_category,\n",
    "        'Category' : result.categories,\n",
    "        'Entry ID' : result.entry_id\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    }\n",
    "    result.download_source(dirpath=pdf_folder, filename = result.title)\n",
    "    paper_list.append(paper_info)\n",
    "\n",
    "# Print the list of dictionaries\n",
    "for paper in paper_list:\n",
    "    print(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(paper_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('..\\\\data\\\\arxiv_papers_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hdawson\\\\OneDrive - TP Group Plc\\\\Documents\\\\TP group\\\\_Internal Projects\\\\Hackathon\\\\SGHacks\\\\data\\\\PDFs'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = arxiv.Search(\n",
    "  query=\"NLP\",\n",
    "  max_results=5,\n",
    "  sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    ")\n",
    "\n",
    "for result in arxiv.Client().results(search):\n",
    "    title =  result.title\n",
    "    print(title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
