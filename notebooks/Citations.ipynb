{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import scholarly\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import time \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(input_string):\n",
    "    # Make a translation table that maps all punctuation characters to None\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "    # Apply the translation table to the input string\n",
    "    result = input_string.translate(translator)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing using Hadoop and KOSHIK\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../data/arxiv_papers_full_v2_w_citations.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dmccaskill\\source\\repos\\SGHacks\\SGHacks\\notebooks\\Citations.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m papers\u001b[39m.\u001b[39;49mto_csv(\u001b[39m\"\u001b[39;49m\u001b[39m../data/arxiv_papers_full_v2_w_citations.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)  \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../data/arxiv_papers_full_v2_w_citations.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "papers = pd.read_csv(\"../data/arxiv_papers_full_v2.csv\")\n",
    "try:\n",
    "    for index, paper in papers.iterrows():\n",
    "\n",
    "        title = paper[\"Title\"]\n",
    "        print(title)\n",
    "        title_with_first_word_removed = remove_punctuation(title).partition(' ')[2]\n",
    "        search_query = scholarly.search_pubs(title_with_first_word_removed)\n",
    "        scholarly_result = next(search_query, None)\n",
    "        if scholarly_result and title.lower() == scholarly_result[\"bib\"][\"title\"].lower():\n",
    "            paper[\"Citations\"] = scholarly_result[\"num_citations\"]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        time.sleep(3)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "papers.to_csv(\"../data/arxiv_papers_full_v2_w_citations.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>PDF URL</th>\n",
       "      <th>Author</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Journal Ref</th>\n",
       "      <th>Primary Category</th>\n",
       "      <th>Category</th>\n",
       "      <th>Entry ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Natural Language Processing using Hadoop and K...</td>\n",
       "      <td>http://arxiv.org/pdf/1608.04434v1</td>\n",
       "      <td>[arxiv.Result.Author('Emre Erturk'), arxiv.Res...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-15 23:09:21+00:00</td>\n",
       "      <td>Natural language processing, as a data analyti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1608.04434v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Integrating AI Planning with Natural Language ...</td>\n",
       "      <td>http://arxiv.org/pdf/2202.07138v2</td>\n",
       "      <td>[arxiv.Result.Author('Kebing Jin'), arxiv.Resu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-15 02:19:09+00:00</td>\n",
       "      <td>Natural language processing (NLP) aims at inve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>['cs.AI', 'cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2202.07138v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Simple Natural Language Processing Tools for D...</td>\n",
       "      <td>http://arxiv.org/pdf/1906.11608v2</td>\n",
       "      <td>[arxiv.Result.Author('Leon Derczynski')]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-27 13:15:12+00:00</td>\n",
       "      <td>This technical note describes a set of baselin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1906.11608v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Towards the Study of Morphological Processing ...</td>\n",
       "      <td>http://arxiv.org/pdf/2006.16212v1</td>\n",
       "      <td>[arxiv.Result.Author('Mirinso Shadang'), arxiv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-29 17:24:09+00:00</td>\n",
       "      <td>There is no or little work on natural language...</td>\n",
       "      <td>In proceeding of Regional International Confer...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2006.16212v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Natural Language Understanding with Distribute...</td>\n",
       "      <td>http://arxiv.org/pdf/1511.07916v1</td>\n",
       "      <td>[arxiv.Result.Author('Kyunghyun Cho')]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-24 23:23:13+00:00</td>\n",
       "      <td>This is a lecture note for the course DS-GA 30...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL', 'stat.ML']</td>\n",
       "      <td>http://arxiv.org/abs/1511.07916v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0  Natural Language Processing using Hadoop and K...   \n",
       "1           1  Integrating AI Planning with Natural Language ...   \n",
       "2           2  Simple Natural Language Processing Tools for D...   \n",
       "3           3  Towards the Study of Morphological Processing ...   \n",
       "4           4  Natural Language Understanding with Distribute...   \n",
       "\n",
       "                             PDF URL  \\\n",
       "0  http://arxiv.org/pdf/1608.04434v1   \n",
       "1  http://arxiv.org/pdf/2202.07138v2   \n",
       "2  http://arxiv.org/pdf/1906.11608v2   \n",
       "3  http://arxiv.org/pdf/2006.16212v1   \n",
       "4  http://arxiv.org/pdf/1511.07916v1   \n",
       "\n",
       "                                              Author  DOI  \\\n",
       "0  [arxiv.Result.Author('Emre Erturk'), arxiv.Res...  NaN   \n",
       "1  [arxiv.Result.Author('Kebing Jin'), arxiv.Resu...  NaN   \n",
       "2           [arxiv.Result.Author('Leon Derczynski')]  NaN   \n",
       "3  [arxiv.Result.Author('Mirinso Shadang'), arxiv...  NaN   \n",
       "4             [arxiv.Result.Author('Kyunghyun Cho')]  NaN   \n",
       "\n",
       "              Published Date  \\\n",
       "0  2016-08-15 23:09:21+00:00   \n",
       "1  2022-02-15 02:19:09+00:00   \n",
       "2  2019-06-27 13:15:12+00:00   \n",
       "3  2020-06-29 17:24:09+00:00   \n",
       "4  2015-11-24 23:23:13+00:00   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Natural language processing, as a data analyti...   \n",
       "1  Natural language processing (NLP) aims at inve...   \n",
       "2  This technical note describes a set of baselin...   \n",
       "3  There is no or little work on natural language...   \n",
       "4  This is a lecture note for the course DS-GA 30...   \n",
       "\n",
       "                                         Journal Ref Primary Category  \\\n",
       "0                                                NaN            cs.CL   \n",
       "1                                                NaN            cs.AI   \n",
       "2                                                NaN            cs.CL   \n",
       "3  In proceeding of Regional International Confer...            cs.CL   \n",
       "4                                                NaN            cs.CL   \n",
       "\n",
       "               Category                           Entry ID  \n",
       "0             ['cs.CL']  http://arxiv.org/abs/1608.04434v1  \n",
       "1    ['cs.AI', 'cs.CL']  http://arxiv.org/abs/2202.07138v2  \n",
       "2             ['cs.CL']  http://arxiv.org/abs/1906.11608v2  \n",
       "3             ['cs.CL']  http://arxiv.org/abs/2006.16212v1  \n",
       "4  ['cs.CL', 'stat.ML']  http://arxiv.org/abs/1511.07916v1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dmccaskill\\source\\repos\\SGHacks\\SGHacks\\notebooks\\Citations.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     results \u001b[39m=\u001b[39m sch\u001b[39m.\u001b[39;49msearch_paper(title)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dmccaskill\\source\\repos\\SGHacks\\SGHacks\\venv\\lib\\site-packages\\semanticscholar\\SemanticScholar.py:349\u001b[0m, in \u001b[0;36mSemanticScholar.search_paper\u001b[1;34m(self, query, year, publication_types, open_access_pdf, venue, fields_of_study, fields, limit)\u001b[0m\n\u001b[0;32m    347\u001b[0m     query \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m&fieldsOfStudy=\u001b[39m\u001b[39m{\u001b[39;00mfields_of_study\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 349\u001b[0m results \u001b[39m=\u001b[39m PaginatedResults(\n\u001b[0;32m    350\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_requester,\n\u001b[0;32m    351\u001b[0m         Paper,\n\u001b[0;32m    352\u001b[0m         url,\n\u001b[0;32m    353\u001b[0m         query,\n\u001b[0;32m    354\u001b[0m         fields,\n\u001b[0;32m    355\u001b[0m         limit,\n\u001b[0;32m    356\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauth_header\n\u001b[0;32m    357\u001b[0m     )\n\u001b[0;32m    359\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\dmccaskill\\source\\repos\\SGHacks\\SGHacks\\venv\\lib\\site-packages\\semanticscholar\\PaginatedResults.py:38\u001b[0m, in \u001b[0;36mPaginatedResults.__init__\u001b[1;34m(self, requester, data_type, url, query, fields, limit, headers)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 38\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_next_page()\n",
      "File \u001b[1;32mc:\\Users\\dmccaskill\\source\\repos\\SGHacks\\SGHacks\\venv\\lib\\site-packages\\semanticscholar\\PaginatedResults.py:101\u001b[0m, in \u001b[0;36mPaginatedResults.__get_next_page\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requester\u001b[39m.\u001b[39mget_data(\n\u001b[0;32m     96\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url,\n\u001b[0;32m     97\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parameters,\n\u001b[0;32m     98\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_headers\n\u001b[0;32m     99\u001b[0m     )\n\u001b[1;32m--> 101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data \u001b[39m=\u001b[39m results[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m    102\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_total \u001b[39m=\u001b[39m results[\u001b[39m'\u001b[39m\u001b[39mtotal\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtotal\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m results \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dmccaskill\\source\\repos\\SGHacks\\SGHacks\\notebooks\\Citations.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mwaiting\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m60\u001b[39m) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     results \u001b[39m=\u001b[39m sch\u001b[39m.\u001b[39msearch_paper(title)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mif\u001b[39;00m results:\n",
      "\u001b[1;32mc:\\Users\\dmccaskill\\source\\repos\\SGHacks\\SGHacks\\notebooks\\Citations.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mwaiting\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m60\u001b[39m) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     results \u001b[39m=\u001b[39m sch\u001b[39m.\u001b[39msearch_paper(title)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mif\u001b[39;00m results:\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2067\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2064\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2066\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[1;32m-> 2067\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2069\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2071\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2072\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2103\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2100\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2102\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2103\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   2105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2107\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from semanticscholar import SemanticScholar\n",
    "import csv\n",
    "sch = SemanticScholar()\n",
    "\n",
    "papers = pd.read_csv(\"../data/arxiv_papers_full_v2.csv\")\n",
    "citations = []\n",
    "\n",
    "already_existing = pd.read_csv(\"../data/citations.csv\")\n",
    "\n",
    "already_exisiting_list = list(already_existing[\"PDF URL\"])\n",
    "\n",
    "with open('../data/citations.csv', mode='a') as citations_file:\n",
    "    citations_writer = csv.writer(citations_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for index, paper in papers.iterrows():\n",
    "        if paper[\"PDF URL\"] not in already_exisiting_list:\n",
    "            title = paper[\"Title\"]\n",
    "\n",
    "            try:\n",
    "                results = sch.search_paper(title)\n",
    "            except:\n",
    "                print('waiting')\n",
    "                time.sleep(60) \n",
    "                results = sch.search_paper(title)\n",
    "\n",
    "            if results:\n",
    "                if title.lower() == results[0].title.lower():\n",
    "                    citations_num = results[0][\"citationCount\"]\n",
    "                else:\n",
    "                    citations_num = 0\n",
    "            else:\n",
    "                citations_num = 0\n",
    "            \n",
    "            citations_writer.writerow([paper[\"PDF URL\"], citations_num])\n",
    "\n",
    "            print(f'{index} of {len(papers)} - {title} - {citations_num}')\n",
    "            time.sleep(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3558 entries, 0 to 3557\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Unnamed: 0        3558 non-null   int64 \n",
      " 1   Title             3558 non-null   object\n",
      " 2   PDF URL           3558 non-null   object\n",
      " 3   Author            3558 non-null   object\n",
      " 4   DOI               403 non-null    object\n",
      " 5   Published Date    3558 non-null   object\n",
      " 6   Summary           3558 non-null   object\n",
      " 7   Journal Ref       515 non-null    object\n",
      " 8   Primary Category  3558 non-null   object\n",
      " 9   Category          3558 non-null   object\n",
      " 10  Entry ID          3558 non-null   object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 305.9+ KB\n"
     ]
    }
   ],
   "source": [
    "from semanticscholar import SemanticScholar\n",
    "import pandas as pd\n",
    "\n",
    "papers = pd.read_csv(\"../data/arxiv_papers_full_v2.csv\")\n",
    "\n",
    "papers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def get_full_text(filename):\n",
    "\n",
    "    text = \"\"\n",
    "    reader = PdfReader(filename)\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "265it [04:08,  2.07it/s]c:\\Users\\dmccaskill\\source\\repos\\SGHacks\\SGHacks\\venv\\lib\\site-packages\\PyPDF2\\_cmap.py:142: PdfReadWarning: Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "  warnings.warn(\n",
      "536it [07:44,  1.42it/s]Illegal character in Name Object (b'/ABCDEE+\\xb7s\\xb2\\xd3\\xa9\\xfa\\xc5\\xe9')\n",
      "Illegal character in Name Object (b'/ABCDEE+\\xb7s\\xb2\\xd3\\xa9\\xfa\\xc5\\xe9')\n",
      "760it [10:30,  1.82it/s]FloatObject (b'0.000000000000-5684342') invalid; use 0.0 instead\n",
      "FloatObject (b'0.000000000000-2842171') invalid; use 0.0 instead\n",
      "FloatObject (b'0.000000000000-5684342') invalid; use 0.0 instead\n",
      "1485it [22:27,  2.16s/it]unknown widths : \n",
      "[0, IndirectObject(162, 0, 2448874668432)]\n",
      "1564it [22:55,  2.74it/s]FloatObject (b'0.00-3183727') invalid; use 0.0 instead\n",
      "1619it [23:26,  1.55it/s]FloatObject (b'0.00-5414185') invalid; use 0.0 instead\n",
      "1677it [24:16,  1.88it/s]FloatObject (b'0.00-891601') invalid; use 0.0 instead\n",
      "2111it [31:33,  2.27it/s]FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "2148it [32:03,  1.01s/it]unknown widths : \n",
      "[0, IndirectObject(511, 0, 2448892323344)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(513, 0, 2448892323344)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(515, 0, 2448892323344)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(517, 0, 2448892323344)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(519, 0, 2448892323344)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(521, 0, 2448892323344)]\n",
      "2330it [34:40,  1.98s/it]FloatObject (b'0.00-60') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-60') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-60') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-60') invalid; use 0.0 instead\n",
      "2418it [35:35,  1.79it/s]XRef object at 427639 can not be read, some object may be missing\n",
      "2425it [35:41,  1.21it/s]FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-40') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-40') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-40') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-40') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-40') invalid; use 0.0 instead\n",
      "3063it [45:15,  1.73it/s] impossible to decode XFormObject /times-minus\n",
      " impossible to decode XFormObject /times-minus\n",
      " impossible to decode XFormObject /times-minus\n",
      " impossible to decode XFormObject /times-minus\n",
      "3108it [45:49,  1.06s/it]incorrect startxref pointer(1)\n",
      "3558it [52:02,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pdf_folder = '../PDF/'\n",
    "\n",
    "papers_full_text = []\n",
    "\n",
    "for index, paper in tqdm(papers.iterrows()):\n",
    "    filename = paper[\"PDF URL\"].split(\"/\")[4]\n",
    "    try:\n",
    "        full_text = get_full_text(pdf_folder + filename + \".pdf\")\n",
    "    except:\n",
    "        full_text = \"ERROR\"\n",
    "    papers_full_text.append(full_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3558"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3558 entries, 0 to 3557\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Unnamed: 0        3558 non-null   int64 \n",
      " 1   Title             3558 non-null   object\n",
      " 2   PDF URL           3558 non-null   object\n",
      " 3   Author            3558 non-null   object\n",
      " 4   DOI               403 non-null    object\n",
      " 5   Published Date    3558 non-null   object\n",
      " 6   Summary           3558 non-null   object\n",
      " 7   Journal Ref       515 non-null    object\n",
      " 8   Primary Category  3558 non-null   object\n",
      " 9   Category          3558 non-null   object\n",
      " 10  Entry ID          3558 non-null   object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 305.9+ KB\n"
     ]
    }
   ],
   "source": [
    "papers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3558 entries, 0 to 3557\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Unnamed: 0        3558 non-null   int64 \n",
      " 1   Title             3558 non-null   object\n",
      " 2   PDF URL           3558 non-null   object\n",
      " 3   Author            3558 non-null   object\n",
      " 4   DOI               403 non-null    object\n",
      " 5   Published Date    3558 non-null   object\n",
      " 6   Summary           3558 non-null   object\n",
      " 7   Journal Ref       515 non-null    object\n",
      " 8   Primary Category  3558 non-null   object\n",
      " 9   Category          3558 non-null   object\n",
      " 10  Entry ID          3558 non-null   object\n",
      " 11  Full Text         3558 non-null   object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 333.7+ KB\n"
     ]
    }
   ],
   "source": [
    "papers[\"Full Text\"] = papers_full_text\n",
    "papers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers.to_csv(\"../data/arxiv_papers_full_v2_w_full_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3558 entries, 0 to 3557\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Unnamed: 0        3558 non-null   int64 \n",
      " 1   Title             3558 non-null   object\n",
      " 2   PDF URL           3558 non-null   object\n",
      " 3   Author            3558 non-null   object\n",
      " 4   DOI               403 non-null    object\n",
      " 5   Published Date    3558 non-null   object\n",
      " 6   Summary           3558 non-null   object\n",
      " 7   Journal Ref       515 non-null    object\n",
      " 8   Primary Category  3558 non-null   object\n",
      " 9   Category          3558 non-null   object\n",
      " 10  Entry ID          3558 non-null   object\n",
      " 11  Full Text         3558 non-null   string\n",
      "dtypes: int64(1), object(10), string(1)\n",
      "memory usage: 333.7+ KB\n"
     ]
    }
   ],
   "source": [
    "papers = papers.astype({\"Full Text\": \"string\"})\n",
    "papers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3558 entries, 0 to 3557\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ID                3558 non-null   int64 \n",
      " 1   Title             3558 non-null   object\n",
      " 2   PDF URL           3558 non-null   object\n",
      " 3   Author            3558 non-null   object\n",
      " 4   DOI               403 non-null    object\n",
      " 5   Published Date    3558 non-null   object\n",
      " 6   Summary           3558 non-null   object\n",
      " 7   Journal Ref       515 non-null    object\n",
      " 8   Primary Category  3558 non-null   object\n",
      " 9   Category          3558 non-null   object\n",
      " 10  Entry ID          3558 non-null   object\n",
      " 11  Full Text         3558 non-null   string\n",
      "dtypes: int64(1), object(10), string(1)\n",
      "memory usage: 361.4+ KB\n"
     ]
    }
   ],
   "source": [
    "papers.rename(columns={\"Unnamed: 0\": \"ID\"}, inplace=True )\n",
    "papers.rename(index={\"ID\": 0}, inplace=True )\n",
    "papers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>PDF URL</th>\n",
       "      <th>Author</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Journal Ref</th>\n",
       "      <th>Primary Category</th>\n",
       "      <th>Category</th>\n",
       "      <th>Entry ID</th>\n",
       "      <th>Full Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural Language Processing using Hadoop and K...</td>\n",
       "      <td>http://arxiv.org/pdf/1608.04434v1</td>\n",
       "      <td>[arxiv.Result.Author('Emre Erturk'), arxiv.Res...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-15 23:09:21+00:00</td>\n",
       "      <td>Natural language processing, as a data analyti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1608.04434v1</td>\n",
       "      <td>Natural Language Processing using Hadoop  and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Integrating AI Planning with Natural Language ...</td>\n",
       "      <td>http://arxiv.org/pdf/2202.07138v2</td>\n",
       "      <td>[arxiv.Result.Author('Kebing Jin'), arxiv.Resu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-15 02:19:09+00:00</td>\n",
       "      <td>Natural language processing (NLP) aims at inve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>['cs.AI', 'cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2202.07138v2</td>\n",
       "      <td>Integrating AI Planning with Natural Language ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Simple Natural Language Processing Tools for D...</td>\n",
       "      <td>http://arxiv.org/pdf/1906.11608v2</td>\n",
       "      <td>[arxiv.Result.Author('Leon Derczynski')]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-27 13:15:12+00:00</td>\n",
       "      <td>This technical note describes a set of baselin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1906.11608v2</td>\n",
       "      <td>arXiv:1906.11608v2  [cs.CL]  26 Jul 2019SIMPLE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Towards the Study of Morphological Processing ...</td>\n",
       "      <td>http://arxiv.org/pdf/2006.16212v1</td>\n",
       "      <td>[arxiv.Result.Author('Mirinso Shadang'), arxiv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-29 17:24:09+00:00</td>\n",
       "      <td>There is no or little work on natural language...</td>\n",
       "      <td>In proceeding of Regional International Confer...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2006.16212v1</td>\n",
       "      <td>arXiv:2006.16212v1  [cs.CL]  29 Jun 2020Toward...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Natural Language Understanding with Distribute...</td>\n",
       "      <td>http://arxiv.org/pdf/1511.07916v1</td>\n",
       "      <td>[arxiv.Result.Author('Kyunghyun Cho')]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-24 23:23:13+00:00</td>\n",
       "      <td>This is a lecture note for the course DS-GA 30...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL', 'stat.ML']</td>\n",
       "      <td>http://arxiv.org/abs/1511.07916v1</td>\n",
       "      <td>Natural Language Understanding with\\nDistribut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  ID                                              Title  \\\n",
       "0         ID   0  Natural Language Processing using Hadoop and K...   \n",
       "1          1   1  Integrating AI Planning with Natural Language ...   \n",
       "2          2   2  Simple Natural Language Processing Tools for D...   \n",
       "3          3   3  Towards the Study of Morphological Processing ...   \n",
       "4          4   4  Natural Language Understanding with Distribute...   \n",
       "\n",
       "                             PDF URL  \\\n",
       "0  http://arxiv.org/pdf/1608.04434v1   \n",
       "1  http://arxiv.org/pdf/2202.07138v2   \n",
       "2  http://arxiv.org/pdf/1906.11608v2   \n",
       "3  http://arxiv.org/pdf/2006.16212v1   \n",
       "4  http://arxiv.org/pdf/1511.07916v1   \n",
       "\n",
       "                                              Author  DOI  \\\n",
       "0  [arxiv.Result.Author('Emre Erturk'), arxiv.Res...  NaN   \n",
       "1  [arxiv.Result.Author('Kebing Jin'), arxiv.Resu...  NaN   \n",
       "2           [arxiv.Result.Author('Leon Derczynski')]  NaN   \n",
       "3  [arxiv.Result.Author('Mirinso Shadang'), arxiv...  NaN   \n",
       "4             [arxiv.Result.Author('Kyunghyun Cho')]  NaN   \n",
       "\n",
       "              Published Date  \\\n",
       "0  2016-08-15 23:09:21+00:00   \n",
       "1  2022-02-15 02:19:09+00:00   \n",
       "2  2019-06-27 13:15:12+00:00   \n",
       "3  2020-06-29 17:24:09+00:00   \n",
       "4  2015-11-24 23:23:13+00:00   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Natural language processing, as a data analyti...   \n",
       "1  Natural language processing (NLP) aims at inve...   \n",
       "2  This technical note describes a set of baselin...   \n",
       "3  There is no or little work on natural language...   \n",
       "4  This is a lecture note for the course DS-GA 30...   \n",
       "\n",
       "                                         Journal Ref Primary Category  \\\n",
       "0                                                NaN            cs.CL   \n",
       "1                                                NaN            cs.AI   \n",
       "2                                                NaN            cs.CL   \n",
       "3  In proceeding of Regional International Confer...            cs.CL   \n",
       "4                                                NaN            cs.CL   \n",
       "\n",
       "               Category                           Entry ID  \\\n",
       "0             ['cs.CL']  http://arxiv.org/abs/1608.04434v1   \n",
       "1    ['cs.AI', 'cs.CL']  http://arxiv.org/abs/2202.07138v2   \n",
       "2             ['cs.CL']  http://arxiv.org/abs/1906.11608v2   \n",
       "3             ['cs.CL']  http://arxiv.org/abs/2006.16212v1   \n",
       "4  ['cs.CL', 'stat.ML']  http://arxiv.org/abs/1511.07916v1   \n",
       "\n",
       "                                           Full Text  \n",
       "0  Natural Language Processing using Hadoop  and ...  \n",
       "1  Integrating AI Planning with Natural Language ...  \n",
       "2  arXiv:1906.11608v2  [cs.CL]  26 Jul 2019SIMPLE...  \n",
       "3  arXiv:2006.16212v1  [cs.CL]  29 Jun 2020Toward...  \n",
       "4  Natural Language Understanding with\\nDistribut...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "papers = pd.read_csv(\"../data/arxiv_papers_full_v2_w_full_text.csv\")\n",
    "papers.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def process_text(text):\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.lower()\n",
    "    text = remove_punctuation(text)\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "import string\n",
    "\n",
    "def remove_punctuation(input_string):\n",
    "    # Make a translation table that maps all punctuation characters to None\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "    # Apply the translation table to the input string\n",
    "    result = input_string.translate(translator)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3558/3558 [00:00<?, ?it/s]\n",
      "100%|| 3558/3558 [00:00<?, ?it/s]\n",
      "100%|| 3558/3558 [00:00<00:00, 504098.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "papers[\"Full Text\"] = tqdm(papers.apply(lambda x : process_text(x[\"Full Text\"]), axis=1))\n",
    "papers[\"Summary\"] = tqdm(papers.apply(lambda x : process_text(x[\"Summary\"]), axis=1))\n",
    "papers[\"Title\"] = tqdm(papers.apply(lambda x : process_text(x[\"Title\"]), axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>PDF URL</th>\n",
       "      <th>Author</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Journal Ref</th>\n",
       "      <th>Primary Category</th>\n",
       "      <th>Category</th>\n",
       "      <th>Entry ID</th>\n",
       "      <th>Full Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>natural language processing using hadoop and k...</td>\n",
       "      <td>http://arxiv.org/pdf/1608.04434v1</td>\n",
       "      <td>[arxiv.Result.Author('Emre Erturk'), arxiv.Res...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-15 23:09:21+00:00</td>\n",
       "      <td>natural language processing as a data analytic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1608.04434v1</td>\n",
       "      <td>natural language processing using hadoop and k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>integrating ai planning with natural language ...</td>\n",
       "      <td>http://arxiv.org/pdf/2202.07138v2</td>\n",
       "      <td>[arxiv.Result.Author('Kebing Jin'), arxiv.Resu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-15 02:19:09+00:00</td>\n",
       "      <td>natural language processing nlp aims at invest...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>['cs.AI', 'cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2202.07138v2</td>\n",
       "      <td>integrating ai planning with natural language ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>simple natural language processing tools for d...</td>\n",
       "      <td>http://arxiv.org/pdf/1906.11608v2</td>\n",
       "      <td>[arxiv.Result.Author('Leon Derczynski')]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-27 13:15:12+00:00</td>\n",
       "      <td>this technical note describes a set of baselin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1906.11608v2</td>\n",
       "      <td>arxiv190611608v2 cscl 26 jul 2019simple natura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>towards the study of morphological processing ...</td>\n",
       "      <td>http://arxiv.org/pdf/2006.16212v1</td>\n",
       "      <td>[arxiv.Result.Author('Mirinso Shadang'), arxiv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-29 17:24:09+00:00</td>\n",
       "      <td>there is no or little work on natural language...</td>\n",
       "      <td>In proceeding of Regional International Confer...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2006.16212v1</td>\n",
       "      <td>arxiv200616212v1 cscl 29 jun 2020towards the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>natural language understanding with distribute...</td>\n",
       "      <td>http://arxiv.org/pdf/1511.07916v1</td>\n",
       "      <td>[arxiv.Result.Author('Kyunghyun Cho')]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-24 23:23:13+00:00</td>\n",
       "      <td>this is a lecture note for the course dsga 300...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL', 'stat.ML']</td>\n",
       "      <td>http://arxiv.org/abs/1511.07916v1</td>\n",
       "      <td>natural language understanding withdistributed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  ID                                              Title  \\\n",
       "0         ID   0  natural language processing using hadoop and k...   \n",
       "1          1   1  integrating ai planning with natural language ...   \n",
       "2          2   2  simple natural language processing tools for d...   \n",
       "3          3   3  towards the study of morphological processing ...   \n",
       "4          4   4  natural language understanding with distribute...   \n",
       "\n",
       "                             PDF URL  \\\n",
       "0  http://arxiv.org/pdf/1608.04434v1   \n",
       "1  http://arxiv.org/pdf/2202.07138v2   \n",
       "2  http://arxiv.org/pdf/1906.11608v2   \n",
       "3  http://arxiv.org/pdf/2006.16212v1   \n",
       "4  http://arxiv.org/pdf/1511.07916v1   \n",
       "\n",
       "                                              Author  DOI  \\\n",
       "0  [arxiv.Result.Author('Emre Erturk'), arxiv.Res...  NaN   \n",
       "1  [arxiv.Result.Author('Kebing Jin'), arxiv.Resu...  NaN   \n",
       "2           [arxiv.Result.Author('Leon Derczynski')]  NaN   \n",
       "3  [arxiv.Result.Author('Mirinso Shadang'), arxiv...  NaN   \n",
       "4             [arxiv.Result.Author('Kyunghyun Cho')]  NaN   \n",
       "\n",
       "              Published Date  \\\n",
       "0  2016-08-15 23:09:21+00:00   \n",
       "1  2022-02-15 02:19:09+00:00   \n",
       "2  2019-06-27 13:15:12+00:00   \n",
       "3  2020-06-29 17:24:09+00:00   \n",
       "4  2015-11-24 23:23:13+00:00   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  natural language processing as a data analytic...   \n",
       "1  natural language processing nlp aims at invest...   \n",
       "2  this technical note describes a set of baselin...   \n",
       "3  there is no or little work on natural language...   \n",
       "4  this is a lecture note for the course dsga 300...   \n",
       "\n",
       "                                         Journal Ref Primary Category  \\\n",
       "0                                                NaN            cs.CL   \n",
       "1                                                NaN            cs.AI   \n",
       "2                                                NaN            cs.CL   \n",
       "3  In proceeding of Regional International Confer...            cs.CL   \n",
       "4                                                NaN            cs.CL   \n",
       "\n",
       "               Category                           Entry ID  \\\n",
       "0             ['cs.CL']  http://arxiv.org/abs/1608.04434v1   \n",
       "1    ['cs.AI', 'cs.CL']  http://arxiv.org/abs/2202.07138v2   \n",
       "2             ['cs.CL']  http://arxiv.org/abs/1906.11608v2   \n",
       "3             ['cs.CL']  http://arxiv.org/abs/2006.16212v1   \n",
       "4  ['cs.CL', 'stat.ML']  http://arxiv.org/abs/1511.07916v1   \n",
       "\n",
       "                                           Full Text  \n",
       "0  natural language processing using hadoop and k...  \n",
       "1  integrating ai planning with natural language ...  \n",
       "2  arxiv190611608v2 cscl 26 jul 2019simple natura...  \n",
       "3  arxiv200616212v1 cscl 29 jun 2020towards the s...  \n",
       "4  natural language understanding withdistributed...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_id_string(df, title):\n",
    "    subset = df[df[\"Full Text\"].str.contains(title)]\n",
    "    return subset.Index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dmccaskill\\source\\repos\\SGHacks\\SGHacks\\notebooks\\Citations.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m papers[\u001b[39m\"\u001b[39m\u001b[39mCitations\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m tqdm(papers\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x : return_id_string(x, x[\u001b[39m\"\u001b[39;49m\u001b[39mTitle\u001b[39;49m\u001b[39m\"\u001b[39;49m]), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:9565\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9554\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9556\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9557\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9558\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9563\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9564\u001b[0m )\n\u001b[1;32m-> 9565\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:746\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    744\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 746\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 873\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    875\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:889\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    887\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    888\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    890\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    891\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    892\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    893\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\dmccaskill\\source\\repos\\SGHacks\\SGHacks\\notebooks\\Citations.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m papers[\u001b[39m\"\u001b[39m\u001b[39mCitations\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m tqdm(papers\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x : return_id_string(x, x[\u001b[39m\"\u001b[39;49m\u001b[39mTitle\u001b[39;49m\u001b[39m\"\u001b[39;49m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "\u001b[1;32mc:\\Users\\dmccaskill\\source\\repos\\SGHacks\\SGHacks\\notebooks\\Citations.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreturn_id_string\u001b[39m(df, title):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     subset \u001b[39m=\u001b[39m df[df[\u001b[39m\"\u001b[39;49m\u001b[39mFull Text\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39mcontains(title)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dmccaskill/source/repos/SGHacks/SGHacks/notebooks/Citations.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m subset\u001b[39m.\u001b[39mIndex\u001b[39m.\u001b[39mtolist()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'str'"
     ]
    }
   ],
   "source": [
    "papers[\"Citations\"] = tqdm(papers.apply(lambda x : return_id_string(x, x[\"Title\"]), axis=1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
