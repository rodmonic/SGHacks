{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87fc752e",
   "metadata": {},
   "source": [
    "# Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd90fd",
   "metadata": {},
   "source": [
    "## 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36bd3d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dglover\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "217c8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd49c49d",
   "metadata": {},
   "source": [
    "## 1.0 Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa4a4912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['use', 'show', 'however', 'approach', 'well', 'provide',' present', 'include', 'word', 'nlp', 'natural', 'language', 'processing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feb04083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDF URL</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://arxiv.org/pdf/1608.04434v1</th>\n",
       "      <td>Hadoop is one of the platform s that can proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://arxiv.org/pdf/2202.07138v2</th>\n",
       "      <td>Integrating AI Planning with Natural Language ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://arxiv.org/pdf/1906.11608v2</th>\n",
       "      <td>The tools are machine learning based using nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://arxiv.org/pdf/2006.16212v1</th>\n",
       "      <td>The name Tangkhul also known as Hao or Ihao re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://arxiv.org/pdf/1511.07916v1</th>\n",
       "      <td>This is a lecture note for the course DS GA at...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             Summary\n",
       "PDF URL                                                                             \n",
       "http://arxiv.org/pdf/1608.04434v1  Hadoop is one of the platform s that can proce...\n",
       "http://arxiv.org/pdf/2202.07138v2  Integrating AI Planning with Natural Language ...\n",
       "http://arxiv.org/pdf/1906.11608v2  The tools are machine learning based using nat...\n",
       "http://arxiv.org/pdf/2006.16212v1  The name Tangkhul also known as Hao or Ihao re...\n",
       "http://arxiv.org/pdf/1511.07916v1  This is a lecture note for the course DS GA at..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_csv('..\\\\data\\\\summaries_full.csv', index_col=0)\n",
    "#print(df.target_names.unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1f6db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "827f680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "df2 = pd.read_csv('..\\\\data\\\\arxiv_papers_full_v2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05f61cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>PDF URL</th>\n",
       "      <th>Author</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Journal Ref</th>\n",
       "      <th>Primary Category</th>\n",
       "      <th>Category</th>\n",
       "      <th>Entry ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural Language Processing using Hadoop and K...</td>\n",
       "      <td>http://arxiv.org/pdf/1608.04434v1</td>\n",
       "      <td>[arxiv.Result.Author('Emre Erturk'), arxiv.Res...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-15 23:09:21+00:00</td>\n",
       "      <td>Natural language processing, as a data analyti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1608.04434v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Integrating AI Planning with Natural Language ...</td>\n",
       "      <td>http://arxiv.org/pdf/2202.07138v2</td>\n",
       "      <td>[arxiv.Result.Author('Kebing Jin'), arxiv.Resu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-15 02:19:09+00:00</td>\n",
       "      <td>Natural language processing (NLP) aims at inve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>['cs.AI', 'cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2202.07138v2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Natural Language Processing using Hadoop and K...   \n",
       "1  Integrating AI Planning with Natural Language ...   \n",
       "\n",
       "                             PDF URL  \\\n",
       "0  http://arxiv.org/pdf/1608.04434v1   \n",
       "1  http://arxiv.org/pdf/2202.07138v2   \n",
       "\n",
       "                                              Author  DOI  \\\n",
       "0  [arxiv.Result.Author('Emre Erturk'), arxiv.Res...  NaN   \n",
       "1  [arxiv.Result.Author('Kebing Jin'), arxiv.Resu...  NaN   \n",
       "\n",
       "              Published Date  \\\n",
       "0  2016-08-15 23:09:21+00:00   \n",
       "1  2022-02-15 02:19:09+00:00   \n",
       "\n",
       "                                             Summary Journal Ref  \\\n",
       "0  Natural language processing, as a data analyti...         NaN   \n",
       "1  Natural language processing (NLP) aims at inve...         NaN   \n",
       "\n",
       "  Primary Category            Category                           Entry ID  \n",
       "0            cs.CL           ['cs.CL']  http://arxiv.org/abs/1608.04434v1  \n",
       "1            cs.AI  ['cs.AI', 'cs.CL']  http://arxiv.org/abs/2202.07138v2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "454d6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.rename(columns = {'Summary' : 'Abstract'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d63e95d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['Filename'] = df2['PDF URL'].map(lambda x: x.split('/')[-1] + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f9755d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df2, how = 'left', on = 'PDF URL', indicator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26ab14fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "both          3569\n",
       "left_only        0\n",
       "right_only       0\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "796e6d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PDF URL                0\n",
       "Summary                1\n",
       "Title                  0\n",
       "Author                 0\n",
       "DOI                 3166\n",
       "Published Date         0\n",
       "Abstract               0\n",
       "Journal Ref         3052\n",
       "Primary Category       0\n",
       "Category               0\n",
       "Entry ID               0\n",
       "_merge                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18bd48f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3569, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d50a2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Summary'] = df['Summary'].map(lambda x: str(x).lower().replace('natural langauge processing', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e2fa055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data = df['Summary'].values.tolist()\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bebe6739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf715a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd9a7962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30802b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dglover\\Anaconda3\\lib\\site-packages\\spacy\\language.py:1895: UserWarning: [W123] Argument disable with value ['parser', 'ner'] is used instead of ['senter'] as specified in the config. Be aware that this might affect other components in your pipeline.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "#nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b41c0fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e832d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6284bd38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.030*\"com\" + 0.026*\"publish\" + 0.026*\"network\" + 0.016*\"image\" + '\n",
      "  '0.012*\"visual\" + 0.011*\"author\" + 0.009*\"academic\" + 0.008*\"book\" + '\n",
      "  '0.008*\"detect\" + 0.007*\"computer_science\"'),\n",
      " (1,\n",
      "  '0.022*\"system\" + 0.016*\"use\" + 0.013*\"process\" + 0.012*\"semantic\" + '\n",
      "  '0.012*\"problem\" + 0.012*\"human\" + 0.011*\"information\" + 0.009*\"base\" + '\n",
      "  '0.009*\"tool\" + 0.008*\"question\"'),\n",
      " (2,\n",
      "  '0.061*\"model\" + 0.030*\"task\" + 0.021*\"text\" + 0.018*\"use\" + 0.016*\"datum\" + '\n",
      "  '0.015*\"base\" + 0.013*\"propose\" + 0.011*\"large\" + 0.010*\"learn\" + '\n",
      "  '0.010*\"performance\"'),\n",
      " (3,\n",
      "  '0.032*\"publish\" + 0.026*\"study\" + 0.022*\"paper\" + 0.016*\"research\" + '\n",
      "  '0.014*\"learning\" + 0.014*\"speech\" + 0.012*\"language\" + 0.011*\"author\" + '\n",
      "  '0.011*\"word\" + 0.011*\"work\"'),\n",
      " (4,\n",
      "  '0.037*\"call\" + 0.021*\"entity\" + 0.014*\"detail\" + 0.013*\"role\" + '\n",
      "  '0.012*\"visit_local\" + 0.012*\"key\" + 0.011*\"attack\" + 0.011*\"event\" + '\n",
      "  '0.011*\"agent\" + 0.011*\"click\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91679646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -7.8593679611346\n",
      "\n",
      "Coherence Score:  0.3311005023982874\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15c032eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dglover\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1852426938502854404868225041\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1852426938502854404868225041_data = {\"mdsDat\": {\"x\": [0.2518461755087936, 0.13755000192680575, 0.06950657657919551, -0.2430674255832586, -0.2158353284315364], \"y\": [-0.10329431439008764, -0.09297961019491517, 0.2890545853746961, 0.0482120590208953, -0.14099271981058867], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [41.29352368451733, 24.340319020329108, 22.296791975047185, 7.8948403058649905, 4.174525014241386]}, \"tinfo\": {\"Term\": [\"model\", \"publish\", \"task\", \"study\", \"system\", \"text\", \"com\", \"research\", \"datum\", \"paper\", \"network\", \"call\", \"speech\", \"process\", \"propose\", \"author\", \"semantic\", \"problem\", \"learning\", \"human\", \"large\", \"language\", \"word\", \"deep\", \"performance\", \"dataset\", \"training\", \"image\", \"article\", \"train\", \"model\", \"task\", \"large\", \"performance\", \"dataset\", \"training\", \"train\", \"improve\", \"domain\", \"llm\", \"pre_traine\", \"transformer\", \"evaluate\", \"achieve\", \"perform\", \"various\", \"input\", \"sequence\", \"demonstrate\", \"attention\", \"leverage\", \"pre\", \"plm\", \"understanding\", \"well\", \"graph\", \"code\", \"show\", \"inference\", \"extraction\", \"propose\", \"datum\", \"text\", \"high\", \"generation\", \"representation\", \"new\", \"learn\", \"state\", \"result\", \"base\", \"art\", \"use\", \"method\", \"also\", \"knowledge\", \"information\", \"process\", \"semantic\", \"human\", \"question\", \"structure\", \"user\", \"document\", \"problem\", \"predict\", \"term\", \"solve\", \"concept\", \"describe\", \"complex\", \"compare\", \"program\", \"mean\", \"dialogue\", \"memory\", \"report\", \"answer\", \"behavior\", \"rule\", \"property\", \"issue\", \"project\", \"expression\", \"common\", \"game\", \"interaction\", \"long\", \"system\", \"tool\", \"reasoning\", \"relation\", \"time\", \"query\", \"way\", \"information\", \"form\", \"use\", \"give\", \"develop\", \"base\", \"also\", \"design\", \"paper\", \"analysis\", \"speech\", \"word\", \"deep\", \"science\", \"embed\", \"arxiv_c\", \"topic\", \"bias\", \"finding\", \"university\", \"arabic\", \"survey\", \"several\", \"speak\", \"research\", \"single\", \"obtain\", \"automatic\", \"machine_translation\", \"vector\", \"scenario\", \"social\", \"area\", \"dependency\", \"tag\", \"group\", \"standard\", \"similarity\", \"speaker\", \"measure\", \"study\", \"field\", \"language\", \"article\", \"identify\", \"publish\", \"review\", \"approach\", \"technology\", \"paper\", \"learning\", \"author\", \"detection\", \"embedding\", \"machine\", \"work\", \"neural_network\", \"present\", \"analysis\", \"method\", \"recognition\", \"technique\", \"use\", \"network\", \"image\", \"visual\", \"academic\", \"book\", \"detect\", \"computer_science\", \"springer\", \"vision\", \"discourse\", \"conference\", \"self\", \"local\", \"action\", \"www\", \"springer_publishe\", \"access\", \"patient\", \"subject\", \"springer_spring\", \"note\", \"predictive\", \"publication\", \"condition\", \"rnn\", \"computation\", \"cluster\", \"practice\", \"comment\", \"publishing_house\", \"category\", \"com\", \"positive\", \"publish\", \"author\", \"software\", \"org\", \"version\", \"researcher\", \"available\", \"call\", \"entity\", \"detail\", \"role\", \"visit_local\", \"attack\", \"key\", \"click\", \"event\", \"agent\", \"story\", \"samaritans_branch\", \"confidential_support\", \"play\", \"explanation\", \"go\", \"protein\", \"intent\", \"suicide\", \"m\", \"suicide_prevention\", \"samaritan\", \"molecule\", \"breaking_new\", \"financial\", \"line\", \"external\", \"stage\", \"contribute\", \"prevention_lifeline\", \"robot\", \"com\"], \"Freq\": [4408.0, 1619.0, 2171.0, 1054.0, 1012.0, 1505.0, 480.0, 642.0, 1149.0, 1180.0, 354.0, 269.0, 533.0, 538.0, 911.0, 619.0, 519.0, 520.0, 806.0, 504.0, 782.0, 473.0, 423.0, 408.0, 699.0, 692.0, 671.0, 217.0, 427.0, 613.0, 4407.426953439156, 2170.665486988344, 781.5751345008605, 698.8206107795717, 691.270335324135, 670.3618698874773, 612.6903340937735, 607.8323221703056, 520.2990122161578, 492.649078342639, 472.4093650172602, 403.873569986119, 354.6613908773802, 325.20571552172214, 301.0729994687405, 286.0808803293361, 265.5864026963173, 253.94678915246178, 252.04183092091813, 246.3080897694558, 249.26881425388171, 233.68725261932684, 231.21178548987996, 229.35714899995608, 227.10243955756158, 227.495848823767, 206.40449289455125, 203.9750337350109, 202.23809439393216, 195.96289935949113, 904.6498949471157, 1136.7585421108538, 1479.171036956368, 245.03970660493326, 417.535335357245, 509.0446335928877, 655.9428613370872, 710.5522570483441, 384.76725401935676, 647.017550166677, 1080.68400824666, 310.60009018569883, 1296.5364836632882, 622.9929637532932, 499.88016826150414, 366.0162787030583, 314.4034604582485, 537.366333280146, 519.0133902867328, 503.5882558481715, 344.4866748411956, 305.8885372412654, 297.77348539096494, 275.61979335610005, 518.9437766715938, 269.31445804535446, 228.35869845118367, 221.34679879826388, 221.20300057733857, 208.7891793712548, 206.22297377349503, 187.74853345292047, 176.90741005923545, 174.8915438202723, 164.49163975107913, 166.78953215541148, 158.46892424085178, 156.95290869126302, 156.7936363807872, 155.12809403108534, 145.43651542167507, 141.638774131645, 136.66433914319268, 126.14280912588923, 124.55869373079142, 124.47692048901712, 119.16087815407464, 121.04517505618182, 952.753940868798, 387.33771358773004, 192.20267691503454, 176.09416948078652, 218.4052376957935, 168.8135707715925, 224.51330804652744, 446.96974945313434, 281.78475374194613, 659.6603979627872, 220.302159238736, 238.72716953923745, 401.8941619249261, 304.2427431541868, 183.51545972029274, 234.8346840794275, 187.3958745987398, 533.1656342788795, 422.68579130424314, 407.7860082113115, 251.43004218698215, 225.20517103826165, 191.64353596328758, 187.7829856832757, 183.82721678621937, 182.20987791209126, 348.55132767935226, 168.964266784823, 162.0569382776444, 164.11877571015157, 159.1414866982004, 639.0853157525922, 149.835366851749, 145.27342895172578, 140.68194482178015, 120.69613171486999, 116.98875960415843, 119.98375035961449, 111.023085758477, 111.4088725139611, 110.33443201976657, 106.42465917082565, 102.87264041198539, 102.84516966876609, 101.64070763639144, 100.39566032254666, 94.84720462049992, 1027.2687598994783, 123.80323500533845, 457.52467545837317, 405.80651956563725, 252.08484464693177, 1254.6203648457365, 186.93025973588868, 216.1217536340354, 291.3056703433367, 839.6507799407325, 558.4658353166778, 433.9088270444104, 140.72382614953216, 200.8659112807564, 279.7583692614011, 411.47040495611714, 199.49152217328492, 316.7257239407959, 243.00679269304723, 313.7442736968442, 193.94107255388147, 203.5678868173805, 197.04759579566434, 353.2821530408769, 216.5432014773729, 158.99410811610926, 117.25825566233456, 114.41862427943735, 110.68243001709898, 102.06650503147277, 88.709245667103, 83.36402622311684, 80.43216484109607, 78.78336587346577, 76.08434512527968, 73.31834370410449, 68.07254909772605, 68.27228448900824, 64.30025869655185, 62.74636613094242, 61.23960264560886, 59.661571108064585, 57.754232904199405, 57.85211094780652, 57.97670809276028, 53.820180583546396, 52.284759690691146, 49.789315645859304, 47.46621076744822, 47.0080869683918, 45.8338168017497, 44.588506430145934, 43.334996766692456, 90.15684588647129, 414.91138090059815, 49.738608401038455, 363.9192435814091, 144.8480030661251, 63.37282411942215, 55.46574155294721, 62.2019780797482, 63.98169615121444, 57.756890052399626, 268.4317305817524, 155.10815065282728, 104.34086063949995, 98.02616759586864, 90.82555788984419, 83.5542429090603, 84.4082855222771, 81.73228397669997, 82.51697881299279, 81.98651617132309, 75.39946154947623, 64.57321268708546, 59.38618630787347, 59.27884216653525, 56.45634624204551, 55.68066519138008, 54.502879706875945, 56.227899718806775, 43.57606740483501, 45.13127461878478, 42.653878400278614, 42.737367910903394, 43.51771536037818, 39.48452141636382, 40.45646271658946, 39.81463095249943, 38.26345890086553, 37.437866048535184, 37.89643560483944, 35.736218755586215, 35.757796183680696, 64.85370567733536], \"Total\": [4408.0, 1619.0, 2171.0, 1054.0, 1012.0, 1505.0, 480.0, 642.0, 1149.0, 1180.0, 354.0, 269.0, 533.0, 538.0, 911.0, 619.0, 519.0, 520.0, 806.0, 504.0, 782.0, 473.0, 423.0, 408.0, 699.0, 692.0, 671.0, 217.0, 427.0, 613.0, 4408.167832171883, 2171.4052179485025, 782.3219847286151, 699.5608223859607, 692.012761862463, 671.1003916251261, 613.4288266260945, 608.5731116944357, 521.0397163293835, 493.4039281496842, 473.15039645986235, 404.61267886162744, 355.4037508546608, 325.946503951163, 301.8138609653266, 286.8246077469319, 266.3319967058181, 254.6883258656975, 252.7837270122413, 247.04883045291726, 250.01850657541925, 234.42647444339727, 231.9610504801822, 230.10311881163966, 227.84626771965242, 228.24486417449214, 207.14577919982082, 204.71573562679066, 202.97923760148862, 196.7097408416768, 911.499636466784, 1149.8728196279233, 1505.4438164687733, 246.06668777318697, 430.7821424874255, 533.0516261111843, 749.8067029703478, 867.2811301983937, 423.7898753884583, 804.7801140005358, 1649.307858236815, 332.67920023381737, 2153.5746464243844, 937.272518241902, 925.3453318161331, 525.7946343856494, 829.1877571584192, 538.0837135056674, 519.7388395308883, 504.3083179995856, 345.20477106101987, 306.6092437967815, 298.49474440827913, 276.3402911991197, 520.3611380679325, 270.06186080649746, 229.0826746720666, 222.06824834532108, 221.9261912028285, 209.5131081414055, 206.9448348469218, 188.482080319421, 177.62972687773524, 175.61761032978126, 165.20982434348042, 167.53811006803622, 159.19119829780632, 157.6731847527591, 157.51915370108202, 155.84670213577218, 146.16668980869292, 142.36650714405081, 137.38332145032905, 126.8740682153045, 125.28196689716427, 125.22815085540195, 119.88058412284438, 121.77862452144808, 1012.3678335959952, 404.71271408511814, 200.78612453294988, 186.15723813474003, 241.2959817566073, 179.82496402559582, 281.9470685545408, 829.1877571584192, 410.22172681079445, 2153.5746464243844, 293.83296282997117, 427.6637127250095, 1649.307858236815, 925.3453318161331, 236.47846071025958, 1180.3437559885272, 430.91806471581475, 533.8859827902107, 423.40640939530914, 408.5036549074286, 252.15241271217928, 225.92178214007347, 192.36414129561857, 188.5043451749553, 184.543182317276, 182.92949585623475, 350.0273673084125, 169.6830208825074, 162.76970760613784, 164.84691344854727, 159.86629731174625, 642.1236610379118, 150.56268320322457, 146.00686318617798, 141.39871501822373, 121.41090673185447, 117.71073073596536, 120.72986129037014, 111.74256762150813, 112.13653275141783, 111.07722017069298, 107.14174093314892, 103.59030449292638, 103.56341863242297, 102.36003132883202, 101.11337017960044, 95.56402768105224, 1054.6771083546453, 124.81526917640085, 473.6114845984902, 427.87020540022354, 261.6934209220094, 1619.0817666035612, 200.16030490590978, 235.81383610931314, 334.4008961422456, 1180.3437559885272, 806.3984017662556, 619.9224047284657, 147.8896676883027, 241.47461976936603, 394.67819669406896, 731.8604895795781, 249.2387628700692, 580.104843627871, 430.91806471581475, 937.272518241902, 268.6380848738668, 464.1143931019081, 2153.5746464243844, 354.0356951397775, 217.28660589042994, 159.74051093373393, 118.01819826287733, 115.16754291527269, 111.44265695180486, 102.83696919083725, 89.45042769698779, 84.10974841685852, 81.1824299790383, 79.53698050311253, 76.8578652514828, 74.0984326372768, 68.8266898621286, 69.033540630271, 65.04386389248866, 63.498132513833355, 61.9986996378276, 60.4167969527978, 58.50007086288655, 58.60455153714844, 58.73602341914719, 54.57319927992429, 53.04066843500315, 50.53587124368061, 48.233246549742915, 47.77259500448558, 46.5985656749029, 45.34112720412957, 44.07827249928091, 93.66700080395815, 480.3647526319454, 50.92382622482848, 1619.0817666035612, 619.9224047284657, 137.0020230761848, 92.65939882488847, 206.39356792271698, 288.82818754990535, 182.32471573021803, 269.20791037684614, 155.89252745342884, 105.11151027161839, 98.80498201334038, 91.58978881039398, 84.32885748209719, 85.19456555212567, 82.49655972676105, 83.29015780152142, 82.7594901155253, 76.17580599256377, 65.33621338394353, 60.15317357421236, 60.067231712988956, 57.22742679386786, 56.45664709410544, 55.28348735315977, 57.03681225434081, 44.33521303618108, 45.928378832424166, 43.412625650949586, 43.50499248798298, 44.3237009983646, 40.242683451759, 41.24190886756311, 40.5924834714465, 39.04987226129938, 38.221506861874815, 38.69140173077914, 36.497886051232314, 36.52256152602125, 480.3647526319454], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.7946, -3.5029, -4.5244, -4.6363, -4.6472, -4.6779, -4.7678, -4.7758, -4.9313, -4.9859, -5.0278, -5.1846, -5.3145, -5.4012, -5.4783, -5.5294, -5.6038, -5.6486, -5.6561, -5.6791, -5.6672, -5.7317, -5.7424, -5.7504, -5.7603, -5.7586, -5.8559, -5.8677, -5.8762, -5.9078, -4.3781, -4.1498, -3.8865, -5.6843, -5.1513, -4.9532, -4.6996, -4.6196, -5.2331, -4.7133, -4.2003, -5.4472, -4.0182, -4.7512, -4.9713, -5.283, -5.435, -4.3704, -4.4052, -4.4354, -4.8151, -4.9339, -4.9608, -5.0381, -4.4053, -5.0612, -5.2262, -5.2574, -5.258, -5.3158, -5.3282, -5.422, -5.4815, -5.493, -5.5543, -5.5404, -5.5916, -5.6012, -5.6022, -5.6129, -5.6774, -5.7038, -5.7396, -5.8197, -5.8323, -5.833, -5.8766, -5.861, -3.7978, -4.6978, -5.3986, -5.4861, -5.2708, -5.5283, -5.2432, -4.5546, -5.016, -4.1654, -5.2621, -5.1818, -4.6609, -4.9393, -5.4448, -5.1982, -5.4239, -4.2906, -4.5228, -4.5587, -5.0423, -5.1524, -5.3138, -5.3341, -5.3554, -5.3643, -4.7156, -5.4397, -5.4815, -5.4688, -5.4996, -4.1094, -5.5599, -5.5908, -5.6229, -5.7762, -5.8074, -5.7821, -5.8597, -5.8562, -5.8659, -5.902, -5.9359, -5.9362, -5.948, -5.9603, -6.0172, -3.6348, -5.7507, -4.4436, -4.5636, -5.0397, -3.4348, -5.3387, -5.1936, -4.8951, -3.8364, -4.2442, -4.4966, -5.6226, -5.2668, -4.9355, -4.5497, -5.2737, -4.8114, -5.0763, -4.8208, -5.3019, -5.2534, -5.286, -3.6639, -4.1534, -4.4623, -4.7668, -4.7913, -4.8245, -4.9056, -5.0458, -5.108, -5.1438, -5.1645, -5.1994, -5.2364, -5.3106, -5.3077, -5.3676, -5.3921, -5.4164, -5.4425, -5.475, -5.4733, -5.4712, -5.5455, -5.5745, -5.6234, -5.6712, -5.6809, -5.7062, -5.7337, -5.7622, -5.0296, -3.5031, -5.6244, -3.6343, -4.5555, -5.3822, -5.5154, -5.4008, -5.3726, -5.475, -3.3014, -3.8499, -4.2463, -4.3088, -4.385, -4.4685, -4.4583, -4.4905, -4.481, -4.4874, -4.5712, -4.7262, -4.8099, -4.8117, -4.8605, -4.8744, -4.8957, -4.8646, -5.1195, -5.0844, -5.1409, -5.1389, -5.1208, -5.2181, -5.1938, -5.2098, -5.2495, -5.2713, -5.2591, -5.3178, -5.3172, -4.7219], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.8843, 0.8841, 0.8835, 0.8834, 0.8834, 0.8834, 0.8833, 0.8832, 0.883, 0.8829, 0.8829, 0.8826, 0.8824, 0.8822, 0.882, 0.8819, 0.8817, 0.8815, 0.8815, 0.8815, 0.8815, 0.8813, 0.8812, 0.8812, 0.8812, 0.8812, 0.8809, 0.8808, 0.8808, 0.8807, 0.8769, 0.873, 0.8669, 0.8803, 0.8532, 0.8384, 0.7507, 0.6851, 0.7879, 0.6663, 0.4617, 0.8158, 0.377, 0.476, 0.2687, 0.5222, -0.0853, 1.4117, 1.4116, 1.4116, 1.411, 1.4107, 1.4106, 1.4104, 1.4103, 1.4103, 1.4099, 1.4098, 1.4098, 1.4096, 1.4095, 1.4091, 1.409, 1.4089, 1.4087, 1.4086, 1.4085, 1.4085, 1.4084, 1.4084, 1.408, 1.4079, 1.4078, 1.4073, 1.4072, 1.407, 1.407, 1.407, 1.3523, 1.3692, 1.3693, 1.3575, 1.3134, 1.3498, 1.1853, 0.7951, 1.0375, 0.2299, 1.125, 0.83, 0.0011, 0.3007, 1.1595, -0.2016, 0.5803, 1.4994, 1.499, 1.499, 1.4979, 1.4976, 1.497, 1.4969, 1.4968, 1.4968, 1.4965, 1.4965, 1.4963, 1.4963, 1.4962, 1.496, 1.4959, 1.4957, 1.4956, 1.4948, 1.4946, 1.4945, 1.4943, 1.4942, 1.494, 1.494, 1.4938, 1.4938, 1.4937, 1.4936, 1.4932, 1.4744, 1.4926, 1.4662, 1.4478, 1.4633, 1.2457, 1.4323, 1.4135, 1.3628, 1.1602, 1.1333, 1.144, 1.4511, 1.3166, 1.1566, 0.9249, 1.2781, 0.8956, 0.9279, 0.4063, 1.1749, 0.6766, -0.8907, 2.5368, 2.5355, 2.5343, 2.5325, 2.5324, 2.5321, 2.5314, 2.5306, 2.5301, 2.5297, 2.5294, 2.5288, 2.5284, 2.5279, 2.5279, 2.5275, 2.5271, 2.5266, 2.5264, 2.5261, 2.526, 2.5259, 2.5251, 2.5246, 2.5241, 2.5229, 2.5228, 2.5224, 2.5222, 2.522, 2.5008, 2.3925, 2.5154, 1.0463, 1.0851, 1.768, 2.0258, 1.3396, 1.0317, 1.3894, 3.1733, 3.1711, 3.1688, 3.1683, 3.1678, 3.1669, 3.1669, 3.1669, 3.1668, 3.1668, 3.1659, 3.1644, 3.1633, 3.163, 3.1626, 3.1623, 3.1619, 3.1619, 3.1589, 3.1587, 3.1585, 3.1584, 3.1578, 3.1572, 3.1569, 3.1568, 3.1558, 3.1555, 3.1554, 3.1551, 3.155, 1.1738]}, \"token.table\": {\"Topic\": [4, 4, 1, 4, 5, 1, 2, 3, 2, 3, 2, 2, 3, 3, 3, 1, 3, 3, 4, 3, 5, 1, 1, 3, 4, 3, 1, 2, 3, 4, 1, 2, 3, 2, 3, 4, 5, 5, 2, 4, 5, 4, 1, 4, 5, 4, 2, 2, 2, 4, 4, 2, 4, 4, 5, 5, 1, 1, 3, 3, 1, 3, 2, 1, 2, 5, 4, 1, 3, 1, 2, 3, 2, 4, 2, 1, 3, 1, 3, 5, 1, 5, 5, 2, 5, 1, 3, 5, 3, 1, 2, 2, 1, 2, 1, 2, 5, 1, 3, 1, 2, 1, 3, 4, 4, 1, 1, 1, 2, 3, 4, 5, 1, 5, 2, 2, 5, 1, 2, 5, 2, 3, 1, 1, 3, 1, 3, 1, 5, 1, 4, 2, 5, 2, 3, 3, 2, 3, 2, 1, 3, 1, 5, 4, 1, 3, 1, 2, 4, 3, 4, 5, 1, 2, 3, 4, 1, 1, 5, 1, 2, 4, 4, 1, 1, 2, 4, 1, 2, 3, 5, 2, 3, 2, 2, 2, 2, 1, 2, 5, 4, 3, 4, 4, 1, 2, 2, 1, 2, 1, 3, 1, 2, 2, 1, 2, 3, 4, 2, 3, 1, 2, 3, 4, 1, 2, 3, 3, 4, 4, 5, 5, 2, 5, 5, 3, 3, 4, 2, 1, 3, 1, 3, 3, 3, 2, 4, 2, 3, 3, 3, 4, 4, 4, 5, 3, 1, 3, 5, 2, 1, 2, 3, 4, 4, 5, 5, 3, 1, 2, 3, 3, 1, 1, 2, 3, 2, 3, 2, 1, 2, 3, 2, 3, 4, 1, 2, 3, 1, 1, 1, 1, 3, 4, 1, 2, 3, 2, 1, 3, 3, 4, 4, 5, 4, 1, 2, 3, 1, 3, 1, 2, 3, 4, 4], \"Freq\": [0.9913725317123604, 0.9921551627723093, 0.9970961371277515, 0.9879888185268738, 0.9908229241810805, 0.5403388149359037, 0.32852599948102945, 0.1307619932144887, 0.4339572074411042, 0.5639123069956595, 0.9957305057685318, 0.08057203221609277, 0.9159767872987389, 0.9959747246427187, 0.9898647414581894, 0.934834518603566, 0.06612977302018795, 0.9488858884675869, 0.05141746193666727, 0.9981070209179008, 0.9961002971946228, 0.9957545621608714, 0.0661373095846706, 0.7000876185304156, 0.23390024121407893, 0.997180207626552, 0.3784456743763573, 0.12066383820695449, 0.1864804772289297, 0.31811375527288005, 0.6554264533460952, 0.2437386070722759, 0.10064828053233284, 0.9967041868313539, 0.9970566113011851, 0.9898622225870388, 0.969120263730706, 0.9955130947855311, 0.032028355496071644, 0.9608506648821493, 0.993980843220545, 0.9838276525607822, 0.9944687301655538, 0.8639268341946235, 0.1353138415003627, 0.9924764286826442, 0.9977493417117588, 0.9974423015779325, 0.9954343637152351, 0.9744316081134811, 0.991861203247987, 0.9958265800092878, 0.9803798016558106, 0.9932486687360288, 0.9808293809670796, 0.9821303519683773, 0.9985364982869142, 0.9888050057291652, 0.011305598130588521, 0.9987670736812803, 0.9968996144589508, 0.9903020604131287, 0.9975509496949508, 0.21989317692536886, 0.778083549120536, 0.9894254181226572, 0.9960279397143564, 0.047332583198127394, 0.9534134615622804, 0.3413897313609091, 0.5588503136661458, 0.10054629074328146, 0.9926770435820745, 0.985434902855906, 0.9987685791397155, 0.9980045353611273, 0.9959199058570547, 0.1656488787028809, 0.8323856154819765, 0.9942747258768033, 0.9988639656905987, 0.9965163014552949, 0.9785517738148697, 0.9931107417961784, 0.9731145788576661, 0.9963919385047229, 0.9934681935809582, 0.9698872117788933, 0.9949188300558962, 0.3120263789904944, 0.687433116213433, 0.9901926935196858, 0.9703280586014574, 0.0301776668943037, 0.24844047208631947, 0.7487247103971272, 0.9919115442094131, 0.9945459268974375, 0.9943015468888144, 0.9956650459969202, 0.9993886319368901, 0.01146379603060051, 0.9629588665704428, 0.02292759206120102, 0.9986809776458359, 0.9990582697733063, 0.9951756760294314, 0.37868383522214644, 0.5390817654277053, 0.0012059994752297656, 0.0422099816330418, 0.0385919832073525, 0.9987534479149165, 0.981822051174294, 0.99265448922119, 0.9974256083723402, 0.9859783831939987, 0.6960892638770323, 0.24724482050277102, 0.055154613804464306, 0.03378296456126732, 0.9670373605662771, 0.9995884242870577, 0.8198033777552108, 0.17987247106865387, 0.3063002102422271, 0.6919656571464078, 0.9959262752610994, 0.9854041088207066, 0.9991813438713409, 0.985176034118646, 0.993606229956137, 0.9797863792272861, 0.2888429129222104, 0.7094387334931485, 0.9966155698617589, 0.996483209578917, 0.9940979080231456, 0.9967881333517628, 0.6646946196273825, 0.33501462369662616, 0.9997350753836186, 0.9926968869685195, 0.9970746024934899, 0.1965986327156672, 0.7984311818452606, 0.8748921520723488, 0.12403196668098847, 0.9896842221074719, 0.9931040009749809, 0.5935717336558729, 0.3993118935503145, 0.08980434679490973, 0.19909454242267724, 0.7116570878087186, 0.983891603474563, 0.9973034341009934, 0.9991983221929897, 0.9822327135352539, 0.9958568454566284, 0.019637173286724454, 0.9818586643362226, 0.9871548476603589, 0.9981807752541182, 0.9975686452585274, 0.9960680830557622, 0.9874689606769114, 0.18444941664482806, 0.2689169065102166, 0.5464529446393503, 0.9863584962007546, 0.9973842434256595, 0.0019217422802035827, 0.9979859760136449, 0.996454833946974, 0.9972098399843417, 0.9920180869511384, 0.9928692934075342, 0.006582558851320668, 0.9948721152240486, 0.9894966890802176, 0.77513071043514, 0.2248187877278016, 0.9755373239888542, 0.05560963158917483, 0.9398027738570546, 0.9965099814312621, 0.03984339066560929, 0.956241375974623, 0.2754635480473482, 0.7221611935295345, 0.05371802944756857, 0.9454373182772069, 0.9925171849289186, 0.9548793682768588, 0.018759909003474632, 0.015007927202779705, 0.01125594540208478, 0.0046719972834373975, 0.9951354213721656, 0.5470380205626567, 0.07616985096442055, 0.1558019678817693, 0.22158502098740526, 0.803946306257226, 0.007455452608258664, 0.18762889064117638, 0.9342511747666646, 0.06494794263083765, 0.9893962203382886, 0.985692089925047, 0.9918528195953551, 0.9945670833956144, 0.9883923095005137, 0.9948541036198747, 0.993954591825342, 0.9954296978570072, 0.9888382893712201, 0.9985784407962369, 0.997297379597758, 0.9948624245924288, 0.9965037586163114, 0.9964826961836752, 0.9962627977181765, 0.9933546576088771, 0.5328388469081641, 0.45984722404403205, 0.9951895493692555, 0.9945811135535533, 0.9889888925903386, 0.9983405018697431, 0.9949644992362294, 0.983951385572449, 0.9914517904763119, 0.968041373504998, 0.9945596752225542, 0.9084690842297675, 0.08966707844345757, 0.9845645743127608, 0.9980129633756726, 0.010429732391898226, 0.0009481574901725661, 0.9737577424072253, 0.015170519842761057, 0.9931013066925174, 0.9924391242710953, 0.9904952615797252, 0.9952711864052718, 0.003951133043996217, 0.9413574477320986, 0.05531586261594704, 0.9893436402731097, 0.9998133844640544, 0.5041860443845777, 0.056020671598286415, 0.4395468079250165, 0.1285881721492424, 0.8702129789634776, 0.995273869254336, 0.9824345377891279, 0.013285118834200513, 0.003985535650260154, 0.9034547463782232, 0.037298590446807375, 0.058020029583922585, 0.042005104876504086, 0.9562338580710048, 0.9973244904541209, 0.9993009349944425, 0.9983603174147143, 0.9984857645505544, 0.9952059806171395, 0.9970648943357984, 0.0028569194680108834, 0.6022544898331853, 0.3064672037701637, 0.0914758168829125, 0.9983425356139523, 0.9971250453250529, 0.9939620565472524, 0.6976961610253284, 0.3003969582192386, 0.9868059477320219, 0.9935605396840149, 0.9953642884362557, 0.19861884107217512, 0.7980221293078464, 0.003546765019145984, 0.9962857951191297, 0.9990401434973798, 0.409914190301948, 0.025961232052456703, 0.5615824407136687, 0.0013663806343398265, 0.9850284279085955], \"Term\": [\"academic\", \"access\", \"achieve\", \"action\", \"agent\", \"also\", \"also\", \"also\", \"analysis\", \"analysis\", \"answer\", \"approach\", \"approach\", \"arabic\", \"area\", \"art\", \"art\", \"article\", \"article\", \"arxiv_c\", \"attack\", \"attention\", \"author\", \"author\", \"author\", \"automatic\", \"available\", \"available\", \"available\", \"available\", \"base\", \"base\", \"base\", \"behavior\", \"bias\", \"book\", \"breaking_new\", \"call\", \"category\", \"category\", \"click\", \"cluster\", \"code\", \"com\", \"com\", \"comment\", \"common\", \"compare\", \"complex\", \"computation\", \"computer_science\", \"concept\", \"condition\", \"conference\", \"confidential_support\", \"contribute\", \"dataset\", \"datum\", \"datum\", \"deep\", \"demonstrate\", \"dependency\", \"describe\", \"design\", \"design\", \"detail\", \"detect\", \"detection\", \"detection\", \"develop\", \"develop\", \"develop\", \"dialogue\", \"discourse\", \"document\", \"domain\", \"embed\", \"embedding\", \"embedding\", \"entity\", \"evaluate\", \"event\", \"explanation\", \"expression\", \"external\", \"extraction\", \"field\", \"financial\", \"finding\", \"form\", \"form\", \"game\", \"generation\", \"generation\", \"give\", \"give\", \"go\", \"graph\", \"group\", \"high\", \"human\", \"identify\", \"identify\", \"identify\", \"image\", \"improve\", \"inference\", \"information\", \"information\", \"information\", \"information\", \"information\", \"input\", \"intent\", \"interaction\", \"issue\", \"key\", \"knowledge\", \"knowledge\", \"knowledge\", \"language\", \"language\", \"large\", \"learn\", \"learn\", \"learning\", \"learning\", \"leverage\", \"line\", \"llm\", \"local\", \"long\", \"m\", \"machine\", \"machine\", \"machine_translation\", \"mean\", \"measure\", \"memory\", \"method\", \"method\", \"model\", \"molecule\", \"network\", \"neural_network\", \"neural_network\", \"new\", \"new\", \"note\", \"obtain\", \"org\", \"org\", \"paper\", \"paper\", \"paper\", \"patient\", \"perform\", \"performance\", \"play\", \"plm\", \"positive\", \"positive\", \"practice\", \"pre\", \"pre_traine\", \"predict\", \"predictive\", \"present\", \"present\", \"present\", \"prevention_lifeline\", \"problem\", \"problem\", \"process\", \"program\", \"project\", \"property\", \"propose\", \"propose\", \"protein\", \"publication\", \"publish\", \"publish\", \"publishing_house\", \"query\", \"query\", \"question\", \"reasoning\", \"reasoning\", \"recognition\", \"recognition\", \"relation\", \"relation\", \"report\", \"representation\", \"representation\", \"representation\", \"representation\", \"research\", \"research\", \"researcher\", \"researcher\", \"researcher\", \"researcher\", \"result\", \"result\", \"result\", \"review\", \"review\", \"rnn\", \"robot\", \"role\", \"rule\", \"samaritan\", \"samaritans_branch\", \"scenario\", \"science\", \"self\", \"semantic\", \"sequence\", \"several\", \"show\", \"similarity\", \"single\", \"social\", \"software\", \"software\", \"solve\", \"speak\", \"speaker\", \"speech\", \"springer\", \"springer_publishe\", \"springer_spring\", \"stage\", \"standard\", \"state\", \"state\", \"story\", \"structure\", \"study\", \"study\", \"study\", \"study\", \"subject\", \"suicide\", \"suicide_prevention\", \"survey\", \"system\", \"system\", \"system\", \"tag\", \"task\", \"technique\", \"technique\", \"technique\", \"technology\", \"technology\", \"term\", \"text\", \"text\", \"text\", \"time\", \"time\", \"time\", \"tool\", \"tool\", \"topic\", \"train\", \"training\", \"transformer\", \"understanding\", \"university\", \"university\", \"use\", \"use\", \"use\", \"user\", \"various\", \"vector\", \"version\", \"version\", \"vision\", \"visit_local\", \"visual\", \"way\", \"way\", \"way\", \"well\", \"word\", \"work\", \"work\", \"work\", \"work\", \"www\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 2, 4, 1, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1852426938502854404868225041\", ldavis_el1852426938502854404868225041_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1852426938502854404868225041\", ldavis_el1852426938502854404868225041_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1852426938502854404868225041\", ldavis_el1852426938502854404868225041_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2      0.251846 -0.103294       1        1  41.293524\n",
       "1      0.137550 -0.092980       2        1  24.340319\n",
       "3      0.069507  0.289055       3        1  22.296792\n",
       "0     -0.243067  0.048212       4        1   7.894840\n",
       "4     -0.215835 -0.140993       5        1   4.174525, topic_info=                     Term         Freq        Total Category  logprob  loglift\n",
       "62                  model  4408.000000  4408.000000  Default  30.0000  30.0000\n",
       "175               publish  1619.000000  1619.000000  Default  29.0000  29.0000\n",
       "155                  task  2171.000000  2171.000000  Default  28.0000  28.0000\n",
       "34                  study  1054.000000  1054.000000  Default  27.0000  27.0000\n",
       "266                system  1012.000000  1012.000000  Default  26.0000  26.0000\n",
       "...                   ...          ...          ...      ...      ...      ...\n",
       "2116                stage    37.437866    38.221507   Topic5  -5.2713   3.1555\n",
       "399            contribute    37.896436    38.691402   Topic5  -5.2591   3.1554\n",
       "453   prevention_lifeline    35.736219    36.497886   Topic5  -5.3178   3.1551\n",
       "2279                robot    35.757796    36.522562   Topic5  -5.3172   3.1550\n",
       "427                   com    64.853706   480.364753   Topic5  -4.7219   1.1738\n",
       "\n",
       "[250 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "2824      4  0.991373  academic\n",
       "83        4  0.992155    access\n",
       "814       1  0.997096   achieve\n",
       "2283      4  0.987989    action\n",
       "1985      5  0.990823     agent\n",
       "...     ...       ...       ...\n",
       "82        1  0.409914      work\n",
       "82        2  0.025961      work\n",
       "82        3  0.561582      work\n",
       "82        4  0.001366      work\n",
       "2496      4  0.985028       www\n",
       "\n",
       "[295 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 2, 4, 1, 5])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84f0b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e031b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dglover\\AppData\\Local\\Temp\\ipykernel_18524\\1533496723.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "199dffc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Perc_Contribution</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.3947</td>\n",
       "      <td>model, task, text, use, datum, base, propose, ...</td>\n",
       "      <td>[hadoop, platform, process, large, amount, dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6148</td>\n",
       "      <td>model, task, text, use, datum, base, propose, ...</td>\n",
       "      <td>[integrating, ai, plan, combination, explicit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>system, use, process, semantic, problem, human...</td>\n",
       "      <td>[tool, machine, learning, base, use, rocesse, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.4279</td>\n",
       "      <td>publish, study, paper, research, learning, spe...</td>\n",
       "      <td>[also, know, refer, ethnic, group, manipur, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>com, publish, network, image, visual, author, ...</td>\n",
       "      <td>[note, course, introduce, reader, neural_netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3844</td>\n",
       "      <td>system, use, process, semantic, problem, human...</td>\n",
       "      <td>[automate, method, security, directive, presen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3565</th>\n",
       "      <td>2</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>model, task, text, use, datum, base, propose, ...</td>\n",
       "      <td>[modifie, run, driven, augmentation, datum, fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5882</td>\n",
       "      <td>model, task, text, use, datum, base, propose, ...</td>\n",
       "      <td>[large, model, llm, revolutionise, understandi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>2</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>model, task, text, use, datum, base, propose, ...</td>\n",
       "      <td>[predictive, power, vary, clinical, note, type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>2</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>model, task, text, use, datum, base, propose, ...</td>\n",
       "      <td>[dataset, strong, baseline, classification, cz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3569 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dominant_Topic  Perc_Contribution  \\\n",
       "0                  2             0.3947   \n",
       "1                  2             0.6148   \n",
       "2                  1             0.3330   \n",
       "3                  3             0.4279   \n",
       "4                  0             0.2970   \n",
       "...              ...                ...   \n",
       "3564               1             0.3844   \n",
       "3565               2             0.4358   \n",
       "3566               2             0.5882   \n",
       "3567               2             0.4400   \n",
       "3568               2             0.4609   \n",
       "\n",
       "                                         Topic_Keywords  \\\n",
       "0     model, task, text, use, datum, base, propose, ...   \n",
       "1     model, task, text, use, datum, base, propose, ...   \n",
       "2     system, use, process, semantic, problem, human...   \n",
       "3     publish, study, paper, research, learning, spe...   \n",
       "4     com, publish, network, image, visual, author, ...   \n",
       "...                                                 ...   \n",
       "3564  system, use, process, semantic, problem, human...   \n",
       "3565  model, task, text, use, datum, base, propose, ...   \n",
       "3566  model, task, text, use, datum, base, propose, ...   \n",
       "3567  model, task, text, use, datum, base, propose, ...   \n",
       "3568  model, task, text, use, datum, base, propose, ...   \n",
       "\n",
       "                                                      0  \n",
       "0     [hadoop, platform, process, large, amount, dat...  \n",
       "1     [integrating, ai, plan, combination, explicit,...  \n",
       "2     [tool, machine, learning, base, use, rocesse, ...  \n",
       "3     [also, know, refer, ethnic, group, manipur, ba...  \n",
       "4     [note, course, introduce, reader, neural_netwo...  \n",
       "...                                                 ...  \n",
       "3564  [automate, method, security, directive, presen...  \n",
       "3565  [modifie, run, driven, augmentation, datum, fu...  \n",
       "3566  [large, model, llm, revolutionise, understandi...  \n",
       "3567  [predictive, power, vary, clinical, note, type...  \n",
       "3568  [dataset, strong, baseline, classification, cz...  \n",
       "\n",
       "[3569 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_sents_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3725cf6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF URL</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Journal Ref</th>\n",
       "      <th>Primary Category</th>\n",
       "      <th>Category</th>\n",
       "      <th>Entry ID</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/pdf/1608.04434v1</td>\n",
       "      <td>hadoop is one of the platform s that can proce...</td>\n",
       "      <td>Natural Language Processing using Hadoop and K...</td>\n",
       "      <td>[arxiv.Result.Author('Emre Erturk'), arxiv.Res...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-15 23:09:21+00:00</td>\n",
       "      <td>Natural language processing, as a data analyti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1608.04434v1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/pdf/2202.07138v2</td>\n",
       "      <td>integrating ai planning with natural language ...</td>\n",
       "      <td>Integrating AI Planning with Natural Language ...</td>\n",
       "      <td>[arxiv.Result.Author('Kebing Jin'), arxiv.Resu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-15 02:19:09+00:00</td>\n",
       "      <td>Natural language processing (NLP) aims at inve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>['cs.AI', 'cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2202.07138v2</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://arxiv.org/pdf/1906.11608v2</td>\n",
       "      <td>the tools are machine learning based using nat...</td>\n",
       "      <td>Simple Natural Language Processing Tools for D...</td>\n",
       "      <td>[arxiv.Result.Author('Leon Derczynski')]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-27 13:15:12+00:00</td>\n",
       "      <td>This technical note describes a set of baselin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1906.11608v2</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://arxiv.org/pdf/2006.16212v1</td>\n",
       "      <td>the name tangkhul also known as hao or ihao re...</td>\n",
       "      <td>Towards the Study of Morphological Processing ...</td>\n",
       "      <td>[arxiv.Result.Author('Mirinso Shadang'), arxiv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-29 17:24:09+00:00</td>\n",
       "      <td>There is no or little work on natural language...</td>\n",
       "      <td>In proceeding of Regional International Confer...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2006.16212v1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://arxiv.org/pdf/1511.07916v1</td>\n",
       "      <td>this is a lecture note for the course ds ga at...</td>\n",
       "      <td>Natural Language Understanding with Distribute...</td>\n",
       "      <td>[arxiv.Result.Author('Kyunghyun Cho')]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-24 23:23:13+00:00</td>\n",
       "      <td>This is a lecture note for the course DS-GA 30...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL', 'stat.ML']</td>\n",
       "      <td>http://arxiv.org/abs/1511.07916v1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>http://arxiv.org/pdf/2307.01211v1</td>\n",
       "      <td>an automated method for the ontologicalreprese...</td>\n",
       "      <td>An automated method for the ontological repres...</td>\n",
       "      <td>[arxiv.Result.Author('Giampaolo Bella'), arxiv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-30 09:04:47+00:00</td>\n",
       "      <td>Large documents written in juridical language ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>['cs.AI', 'cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2307.01211v1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3565</th>\n",
       "      <td>http://arxiv.org/pdf/2307.01488v1</td>\n",
       "      <td>scat modifies ran driven augmentations of the ...</td>\n",
       "      <td>SCAT: Robust Self-supervised Contrastive Learn...</td>\n",
       "      <td>[arxiv.Result.Author('Junjie Wu'), arxiv.Resul...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-04 05:41:31+00:00</td>\n",
       "      <td>Despite their promising performance across var...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2307.01488v1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>http://arxiv.org/pdf/2307.06090v1</td>\n",
       "      <td>large language models llms have revolutionised...</td>\n",
       "      <td>Can Large Language Models Aid in Annotating Sp...</td>\n",
       "      <td>[arxiv.Result.Author('Siddique Latif'), arxiv....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-12 11:27:40+00:00</td>\n",
       "      <td>Despite recent advancements in speech emotion ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.SD</td>\n",
       "      <td>['cs.SD', 'eess.AS']</td>\n",
       "      <td>http://arxiv.org/abs/2307.06090v1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>http://arxiv.org/pdf/2307.07051v1</td>\n",
       "      <td>predictive power varies with clinical note typ...</td>\n",
       "      <td>Making the Most Out of the Limited Context Len...</td>\n",
       "      <td>[arxiv.Result.Author('Hongyi Zheng'), arxiv.Re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-13 20:04:05+00:00</td>\n",
       "      <td>Recent advances in large language models have ...</td>\n",
       "      <td>Association for Computational Linguistics - St...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL', 'cs.IR', 'cs.LG']</td>\n",
       "      <td>http://arxiv.org/abs/2307.07051v1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>http://arxiv.org/pdf/2307.10666v1</td>\n",
       "      <td>a dataset and strong baselines for classificat...</td>\n",
       "      <td>A Dataset and Strong Baselines for Classificat...</td>\n",
       "      <td>[arxiv.Result.Author('Hynek Kydlek'), arxiv....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-20 07:47:08+00:00</td>\n",
       "      <td>Pre-trained models for Czech Natural Language ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2307.10666v1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3569 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                PDF URL  \\\n",
       "0     http://arxiv.org/pdf/1608.04434v1   \n",
       "1     http://arxiv.org/pdf/2202.07138v2   \n",
       "2     http://arxiv.org/pdf/1906.11608v2   \n",
       "3     http://arxiv.org/pdf/2006.16212v1   \n",
       "4     http://arxiv.org/pdf/1511.07916v1   \n",
       "...                                 ...   \n",
       "3564  http://arxiv.org/pdf/2307.01211v1   \n",
       "3565  http://arxiv.org/pdf/2307.01488v1   \n",
       "3566  http://arxiv.org/pdf/2307.06090v1   \n",
       "3567  http://arxiv.org/pdf/2307.07051v1   \n",
       "3568  http://arxiv.org/pdf/2307.10666v1   \n",
       "\n",
       "                                                Summary  \\\n",
       "0     hadoop is one of the platform s that can proce...   \n",
       "1     integrating ai planning with natural language ...   \n",
       "2     the tools are machine learning based using nat...   \n",
       "3     the name tangkhul also known as hao or ihao re...   \n",
       "4     this is a lecture note for the course ds ga at...   \n",
       "...                                                 ...   \n",
       "3564  an automated method for the ontologicalreprese...   \n",
       "3565  scat modifies ran driven augmentations of the ...   \n",
       "3566  large language models llms have revolutionised...   \n",
       "3567  predictive power varies with clinical note typ...   \n",
       "3568  a dataset and strong baselines for classificat...   \n",
       "\n",
       "                                                  Title  \\\n",
       "0     Natural Language Processing using Hadoop and K...   \n",
       "1     Integrating AI Planning with Natural Language ...   \n",
       "2     Simple Natural Language Processing Tools for D...   \n",
       "3     Towards the Study of Morphological Processing ...   \n",
       "4     Natural Language Understanding with Distribute...   \n",
       "...                                                 ...   \n",
       "3564  An automated method for the ontological repres...   \n",
       "3565  SCAT: Robust Self-supervised Contrastive Learn...   \n",
       "3566  Can Large Language Models Aid in Annotating Sp...   \n",
       "3567  Making the Most Out of the Limited Context Len...   \n",
       "3568  A Dataset and Strong Baselines for Classificat...   \n",
       "\n",
       "                                                 Author  DOI  \\\n",
       "0     [arxiv.Result.Author('Emre Erturk'), arxiv.Res...  NaN   \n",
       "1     [arxiv.Result.Author('Kebing Jin'), arxiv.Resu...  NaN   \n",
       "2              [arxiv.Result.Author('Leon Derczynski')]  NaN   \n",
       "3     [arxiv.Result.Author('Mirinso Shadang'), arxiv...  NaN   \n",
       "4                [arxiv.Result.Author('Kyunghyun Cho')]  NaN   \n",
       "...                                                 ...  ...   \n",
       "3564  [arxiv.Result.Author('Giampaolo Bella'), arxiv...  NaN   \n",
       "3565  [arxiv.Result.Author('Junjie Wu'), arxiv.Resul...  NaN   \n",
       "3566  [arxiv.Result.Author('Siddique Latif'), arxiv....  NaN   \n",
       "3567  [arxiv.Result.Author('Hongyi Zheng'), arxiv.Re...  NaN   \n",
       "3568  [arxiv.Result.Author('Hynek Kydlek'), arxiv....  NaN   \n",
       "\n",
       "                 Published Date  \\\n",
       "0     2016-08-15 23:09:21+00:00   \n",
       "1     2022-02-15 02:19:09+00:00   \n",
       "2     2019-06-27 13:15:12+00:00   \n",
       "3     2020-06-29 17:24:09+00:00   \n",
       "4     2015-11-24 23:23:13+00:00   \n",
       "...                         ...   \n",
       "3564  2023-06-30 09:04:47+00:00   \n",
       "3565  2023-07-04 05:41:31+00:00   \n",
       "3566  2023-07-12 11:27:40+00:00   \n",
       "3567  2023-07-13 20:04:05+00:00   \n",
       "3568  2023-07-20 07:47:08+00:00   \n",
       "\n",
       "                                               Abstract  \\\n",
       "0     Natural language processing, as a data analyti...   \n",
       "1     Natural language processing (NLP) aims at inve...   \n",
       "2     This technical note describes a set of baselin...   \n",
       "3     There is no or little work on natural language...   \n",
       "4     This is a lecture note for the course DS-GA 30...   \n",
       "...                                                 ...   \n",
       "3564  Large documents written in juridical language ...   \n",
       "3565  Despite their promising performance across var...   \n",
       "3566  Despite recent advancements in speech emotion ...   \n",
       "3567  Recent advances in large language models have ...   \n",
       "3568  Pre-trained models for Czech Natural Language ...   \n",
       "\n",
       "                                            Journal Ref Primary Category  \\\n",
       "0                                                   NaN            cs.CL   \n",
       "1                                                   NaN            cs.AI   \n",
       "2                                                   NaN            cs.CL   \n",
       "3     In proceeding of Regional International Confer...            cs.CL   \n",
       "4                                                   NaN            cs.CL   \n",
       "...                                                 ...              ...   \n",
       "3564                                                NaN            cs.AI   \n",
       "3565                                                NaN            cs.CL   \n",
       "3566                                                NaN            cs.SD   \n",
       "3567  Association for Computational Linguistics - St...            cs.CL   \n",
       "3568                                                NaN            cs.CL   \n",
       "\n",
       "                         Category                           Entry ID _merge  \n",
       "0                       ['cs.CL']  http://arxiv.org/abs/1608.04434v1   both  \n",
       "1              ['cs.AI', 'cs.CL']  http://arxiv.org/abs/2202.07138v2   both  \n",
       "2                       ['cs.CL']  http://arxiv.org/abs/1906.11608v2   both  \n",
       "3                       ['cs.CL']  http://arxiv.org/abs/2006.16212v1   both  \n",
       "4            ['cs.CL', 'stat.ML']  http://arxiv.org/abs/1511.07916v1   both  \n",
       "...                           ...                                ...    ...  \n",
       "3564           ['cs.AI', 'cs.CL']  http://arxiv.org/abs/2307.01211v1   both  \n",
       "3565                    ['cs.CL']  http://arxiv.org/abs/2307.01488v1   both  \n",
       "3566         ['cs.SD', 'eess.AS']  http://arxiv.org/abs/2307.06090v1   both  \n",
       "3567  ['cs.CL', 'cs.IR', 'cs.LG']  http://arxiv.org/abs/2307.07051v1   both  \n",
       "3568                    ['cs.CL']  http://arxiv.org/abs/2307.10666v1   both  \n",
       "\n",
       "[3569 rows x 12 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "940cc19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'original_df' is your original dataframe and 'lda_output' is the output from LDA\n",
    "merged_df = df.merge(df_topic_sents_keywords, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7018c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF URL</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Journal Ref</th>\n",
       "      <th>Primary Category</th>\n",
       "      <th>Category</th>\n",
       "      <th>Entry ID</th>\n",
       "      <th>_merge</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Perc_Contribution</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/pdf/1608.04434v1</td>\n",
       "      <td>hadoop is one of the platform s that can proce...</td>\n",
       "      <td>Natural Language Processing using Hadoop and K...</td>\n",
       "      <td>[arxiv.Result.Author('Emre Erturk'), arxiv.Res...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-15 23:09:21+00:00</td>\n",
       "      <td>Natural language processing, as a data analyti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1608.04434v1</td>\n",
       "      <td>both</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3947</td>\n",
       "      <td>model, task, text, use, datum, base, propose, ...</td>\n",
       "      <td>[hadoop, platform, process, large, amount, dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/pdf/2202.07138v2</td>\n",
       "      <td>integrating ai planning with natural language ...</td>\n",
       "      <td>Integrating AI Planning with Natural Language ...</td>\n",
       "      <td>[arxiv.Result.Author('Kebing Jin'), arxiv.Resu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-15 02:19:09+00:00</td>\n",
       "      <td>Natural language processing (NLP) aims at inve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>['cs.AI', 'cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2202.07138v2</td>\n",
       "      <td>both</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6148</td>\n",
       "      <td>model, task, text, use, datum, base, propose, ...</td>\n",
       "      <td>[integrating, ai, plan, combination, explicit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://arxiv.org/pdf/1906.11608v2</td>\n",
       "      <td>the tools are machine learning based using nat...</td>\n",
       "      <td>Simple Natural Language Processing Tools for D...</td>\n",
       "      <td>[arxiv.Result.Author('Leon Derczynski')]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-27 13:15:12+00:00</td>\n",
       "      <td>This technical note describes a set of baselin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/1906.11608v2</td>\n",
       "      <td>both</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>system, use, process, semantic, problem, human...</td>\n",
       "      <td>[tool, machine, learning, base, use, rocesse, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://arxiv.org/pdf/2006.16212v1</td>\n",
       "      <td>the name tangkhul also known as hao or ihao re...</td>\n",
       "      <td>Towards the Study of Morphological Processing ...</td>\n",
       "      <td>[arxiv.Result.Author('Mirinso Shadang'), arxiv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-29 17:24:09+00:00</td>\n",
       "      <td>There is no or little work on natural language...</td>\n",
       "      <td>In proceeding of Regional International Confer...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>http://arxiv.org/abs/2006.16212v1</td>\n",
       "      <td>both</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4279</td>\n",
       "      <td>publish, study, paper, research, learning, spe...</td>\n",
       "      <td>[also, know, refer, ethnic, group, manipur, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://arxiv.org/pdf/1511.07916v1</td>\n",
       "      <td>this is a lecture note for the course ds ga at...</td>\n",
       "      <td>Natural Language Understanding with Distribute...</td>\n",
       "      <td>[arxiv.Result.Author('Kyunghyun Cho')]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-24 23:23:13+00:00</td>\n",
       "      <td>This is a lecture note for the course DS-GA 30...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>['cs.CL', 'stat.ML']</td>\n",
       "      <td>http://arxiv.org/abs/1511.07916v1</td>\n",
       "      <td>both</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>com, publish, network, image, visual, author, ...</td>\n",
       "      <td>[note, course, introduce, reader, neural_netwo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             PDF URL  \\\n",
       "0  http://arxiv.org/pdf/1608.04434v1   \n",
       "1  http://arxiv.org/pdf/2202.07138v2   \n",
       "2  http://arxiv.org/pdf/1906.11608v2   \n",
       "3  http://arxiv.org/pdf/2006.16212v1   \n",
       "4  http://arxiv.org/pdf/1511.07916v1   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  hadoop is one of the platform s that can proce...   \n",
       "1  integrating ai planning with natural language ...   \n",
       "2  the tools are machine learning based using nat...   \n",
       "3  the name tangkhul also known as hao or ihao re...   \n",
       "4  this is a lecture note for the course ds ga at...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Natural Language Processing using Hadoop and K...   \n",
       "1  Integrating AI Planning with Natural Language ...   \n",
       "2  Simple Natural Language Processing Tools for D...   \n",
       "3  Towards the Study of Morphological Processing ...   \n",
       "4  Natural Language Understanding with Distribute...   \n",
       "\n",
       "                                              Author  DOI  \\\n",
       "0  [arxiv.Result.Author('Emre Erturk'), arxiv.Res...  NaN   \n",
       "1  [arxiv.Result.Author('Kebing Jin'), arxiv.Resu...  NaN   \n",
       "2           [arxiv.Result.Author('Leon Derczynski')]  NaN   \n",
       "3  [arxiv.Result.Author('Mirinso Shadang'), arxiv...  NaN   \n",
       "4             [arxiv.Result.Author('Kyunghyun Cho')]  NaN   \n",
       "\n",
       "              Published Date  \\\n",
       "0  2016-08-15 23:09:21+00:00   \n",
       "1  2022-02-15 02:19:09+00:00   \n",
       "2  2019-06-27 13:15:12+00:00   \n",
       "3  2020-06-29 17:24:09+00:00   \n",
       "4  2015-11-24 23:23:13+00:00   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Natural language processing, as a data analyti...   \n",
       "1  Natural language processing (NLP) aims at inve...   \n",
       "2  This technical note describes a set of baselin...   \n",
       "3  There is no or little work on natural language...   \n",
       "4  This is a lecture note for the course DS-GA 30...   \n",
       "\n",
       "                                         Journal Ref Primary Category  \\\n",
       "0                                                NaN            cs.CL   \n",
       "1                                                NaN            cs.AI   \n",
       "2                                                NaN            cs.CL   \n",
       "3  In proceeding of Regional International Confer...            cs.CL   \n",
       "4                                                NaN            cs.CL   \n",
       "\n",
       "               Category                           Entry ID _merge  \\\n",
       "0             ['cs.CL']  http://arxiv.org/abs/1608.04434v1   both   \n",
       "1    ['cs.AI', 'cs.CL']  http://arxiv.org/abs/2202.07138v2   both   \n",
       "2             ['cs.CL']  http://arxiv.org/abs/1906.11608v2   both   \n",
       "3             ['cs.CL']  http://arxiv.org/abs/2006.16212v1   both   \n",
       "4  ['cs.CL', 'stat.ML']  http://arxiv.org/abs/1511.07916v1   both   \n",
       "\n",
       "   Dominant_Topic  Perc_Contribution  \\\n",
       "0               2             0.3947   \n",
       "1               2             0.6148   \n",
       "2               1             0.3330   \n",
       "3               3             0.4279   \n",
       "4               0             0.2970   \n",
       "\n",
       "                                      Topic_Keywords  \\\n",
       "0  model, task, text, use, datum, base, propose, ...   \n",
       "1  model, task, text, use, datum, base, propose, ...   \n",
       "2  system, use, process, semantic, problem, human...   \n",
       "3  publish, study, paper, research, learning, spe...   \n",
       "4  com, publish, network, image, visual, author, ...   \n",
       "\n",
       "                                                   0  \n",
       "0  [hadoop, platform, process, large, amount, dat...  \n",
       "1  [integrating, ai, plan, combination, explicit,...  \n",
       "2  [tool, machine, learning, base, use, rocesse, ...  \n",
       "3  [also, know, refer, ethnic, group, manipur, ba...  \n",
       "4  [note, course, introduce, reader, neural_netwo...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53de37ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('../data/Dominant_topics_of_summaries_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35a269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa810f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06bf94bd",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e682120",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=texts)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcdeb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic.to_csv('../data/Dominant_topics_of_absracts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4634e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic['Dominant_Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db13218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8870b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af1a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75152243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce302396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e2173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696279a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79536c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7a89ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
