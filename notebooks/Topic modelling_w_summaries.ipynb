{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87fc752e",
   "metadata": {},
   "source": [
    "# Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd90fd",
   "metadata": {},
   "source": [
    "## 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36bd3d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dglover\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "217c8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd49c49d",
   "metadata": {},
   "source": [
    "## 1.0 Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa4a4912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['use', 'show', 'however', 'approach', 'well', 'provide',' present', 'include', 'word', 'nlp', 'natural', 'language', 'p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb04083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Filename</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1809.09190v1.pdf</th>\n",
       "      <td>In this paper we formulate audio play hot n c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903.10625v2.pdf</th>\n",
       "      <td>Finite State Transducers FST are an efficient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904.04307v1.pdf</th>\n",
       "      <td>The quantification of semantic similarity bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809.02794v3.pdf</th>\n",
       "      <td>This paper focuses on the aim of semantic rol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805.01083v1.pdf</th>\n",
       "      <td>The mainconstructusedinextractionlanguagesand...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            Summary\n",
       "Filename                                                           \n",
       "1809.09190v1.pdf   In this paper we formulate audio play hot n c...\n",
       "1903.10625v2.pdf   Finite State Transducers FST are an efficient...\n",
       "1904.04307v1.pdf   The quantification of semantic similarity bet...\n",
       "1809.02794v3.pdf   This paper focuses on the aim of semantic rol...\n",
       "1805.01083v1.pdf   The mainconstructusedinextractionlanguagesand..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_csv('..\\\\data\\\\50_summaries.csv', index_col=0)\n",
    "#print(df.target_names.unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "796e6d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Summary    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18bd48f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d50a2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Summary'] = df['Summary'].map(lambda x: x.lower().replace('natural langauge processing', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e2fa055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data = df['Summary'].values.tolist()\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bebe6739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf715a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd9a7962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30802b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dglover\\Anaconda3\\lib\\site-packages\\spacy\\language.py:1895: UserWarning: [W123] Argument disable with value ['parser', 'ner'] is used instead of ['senter'] as specified in the config. Be aware that this might affect other components in your pipeline.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "#nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b41c0fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e832d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6284bd38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.026*\"use\" + 0.015*\"method\" + 0.013*\"model\" + 0.011*\"network\" + '\n",
      "  '0.011*\"evaluate\" + 0.009*\"task\" + 0.009*\"ground\" + 0.009*\"learn\" + '\n",
      "  '0.009*\"traditional\" + 0.009*\"word\"'),\n",
      " (1,\n",
      "  '0.024*\"language\" + 0.015*\"task\" + 0.013*\"use\" + 0.013*\"model\" + '\n",
      "  '0.010*\"text\" + 0.010*\"natural\" + 0.010*\"processing\" + 0.008*\"organize\" + '\n",
      "  '0.006*\"method\" + 0.006*\"word\"'),\n",
      " (2,\n",
      "  '0.029*\"language\" + 0.015*\"use\" + 0.015*\"work\" + 0.013*\"task\" + '\n",
      "  '0.010*\"framework\" + 0.010*\"lexical\" + 0.010*\"efficient\" + 0.008*\"semantic\" '\n",
      "  '+ 0.008*\"pretraine\" + 0.008*\"context\"'),\n",
      " (3,\n",
      "  '0.019*\"language\" + 0.012*\"system\" + 0.012*\"text\" + 0.010*\"interpretation\" + '\n",
      "  '0.010*\"arabic\" + 0.010*\"task\" + 0.010*\"sentiment\" + 0.010*\"feature\" + '\n",
      "  '0.007*\"use\" + 0.007*\"natural\"'),\n",
      " (4,\n",
      "  '0.035*\"model\" + 0.014*\"language\" + 0.012*\"project\" + 0.012*\"key\" + '\n",
      "  '0.012*\"base\" + 0.012*\"propose\" + 0.009*\"paper\" + 0.009*\"present\" + '\n",
      "  '0.009*\"system\" + 0.009*\"task\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91679646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.739581542479117\n",
      "\n",
      "Coherence Score:  0.3423974426966424\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15c032eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dglover\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el751226268908211844658022809\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el751226268908211844658022809_data = {\"mdsDat\": {\"x\": [0.13093692802847845, -0.022905988527221494, -0.01981900107786678, 0.004411111783012554, -0.09262305020640256], \"y\": [0.04663895843198042, -0.05433928344528862, -0.08158371586384201, -0.007199572647722958, 0.09648361352487322], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [25.45898834328734, 23.256845907982957, 18.635992177564507, 17.03260804201144, 15.615565529153757]}, \"tinfo\": {\"Term\": [\"model\", \"key\", \"use\", \"evaluate\", \"project\", \"language\", \"lexical\", \"arabic\", \"efficient\", \"work\", \"traditional\", \"interpretation\", \"feature\", \"sentiment\", \"classification\", \"base\", \"method\", \"text\", \"pretraine\", \"parallel\", \"context\", \"lm\", \"organize\", \"framework\", \"ground\", \"confound\", \"network\", \"propose\", \"emotion\", \"present\", \"key\", \"emotion\", \"project\", \"indian\", \"generate\", \"lithium\", \"hybrid\", \"contextual\", \"national\", \"suppose\", \"hide\", \"mix\", \"utilize\", \"tree\", \"special\", \"thesis\", \"diverse\", \"globally\", \"level\", \"rich\", \"probability\", \"counterexample\", \"path\", \"author\", \"attention\", \"develop\", \"social\", \"medium\", \"achieve\", \"write\", \"base\", \"model\", \"present\", \"propose\", \"information\", \"paper\", \"also\", \"new\", \"extraction\", \"language\", \"system\", \"problem\", \"apply\", \"task\", \"application\", \"natural\", \"large\", \"organize\", \"consist\", \"czech\", \"modification\", \"explore\", \"retrieval\", \"read\", \"worsen\", \"speech\", \"translation\", \"create\", \"constrain\", \"describe\", \"review\", \"clinical\", \"include\", \"need\", \"topic\", \"perform\", \"tag\", \"theselanguage\", \"highlyinflecte\", \"gender\", \"relatively\", \"name\", \"analogy\", \"search\", \"thecorpus\", \"outperform\", \"corpus\", \"processing\", \"speak\", \"user\", \"way\", \"play\", \"rnn\", \"understand\", \"rule\", \"language\", \"apply\", \"text\", \"task\", \"natural\", \"use\", \"model\", \"set\", \"learn\", \"word\", \"method\", \"system\", \"available\", \"embed\", \"framework\", \"new\", \"evaluate\", \"traditional\", \"mention\", \"detection\", \"imputation\", \"graph\", \"biomedical\", \"gain\", \"outofvocabulary\", \"help\", \"strategy\", \"predic\", \"agrawaletalet\", \"sophisticated\", \"progressby\", \"goal\", \"surprisingly\", \"actually\", \"refer\", \"lanophobicguage\", \"top\", \"seek\", \"rer\", \"image\", \"come\", \"denominal\", \"robustness\", \"pronominal\", \"president\", \"dedescribe\", \"ground\", \"network\", \"interaction\", \"textual\", \"embed\", \"stateoftheart\", \"method\", \"challenge\", \"community\", \"use\", \"train\", \"classification\", \"research\", \"learn\", \"word\", \"semantic\", \"property\", \"study\", \"make\", \"model\", \"work\", \"task\", \"propose\", \"natural\", \"system\", \"language\", \"sentence\", \"neural\", \"arabic\", \"confound\", \"pattern\", \"re\", \"visual\", \"distance\", \"module\", \"latent\", \"domain\", \"interpretation\", \"sentiment\", \"analysis\", \"handle\", \"regular\", \"match\", \"bind\", \"go\", \"widely\", \"certain\", \"numple\", \"simcentric\", \"leave\", \"give\", \"conceal\", \"hindienglish\", \"decipher\", \"target\", \"azouaoua\", \"houda\", \"primary\", \"feature\", \"recent\", \"free\", \"usage\", \"different\", \"classification\", \"text\", \"system\", \"high\", \"machine\", \"learning\", \"label\", \"language\", \"new\", \"novel\", \"introduce\", \"input\", \"task\", \"method\", \"natural\", \"use\", \"base\", \"paper\", \"information\", \"framework\", \"present\", \"work\", \"sentence\", \"lexical\", \"parallel\", \"lm\", \"offensive\", \"linguistic\", \"original\", \"science\", \"distribute\", \"course\", \"computer\", \"lolcode\", \"intent\", \"efficient\", \"inthisframework\", \"basedon\", \"attack\", \"incrementally\", \"shut\", \"harm\", \"developer\", \"syntactic\", \"public\", \"troll\", \"lack\", \"lead\", \"still\", \"fix\", \"behavior\", \"adversarial\", \"ofinteraction\", \"encode\", \"pretraine\", \"context\", \"work\", \"framework\", \"language\", \"semantic\", \"process\", \"use\", \"task\", \"make\", \"input\", \"application\", \"set\", \"large\", \"sentence\", \"paper\", \"model\", \"propose\"], \"Freq\": [25.0, 5.0, 20.0, 3.0, 6.0, 29.0, 3.0, 3.0, 3.0, 8.0, 3.0, 3.0, 4.0, 3.0, 4.0, 8.0, 10.0, 9.0, 3.0, 2.0, 3.0, 2.0, 3.0, 6.0, 4.0, 2.0, 6.0, 9.0, 3.0, 6.0, 5.152748274353153, 3.0066923252544555, 5.153094955982499, 2.2901407930362034, 2.288979102099731, 2.2836458933538295, 1.5749022886630208, 1.5748983490990511, 1.5745347561707128, 1.5744450109817412, 1.5743596857913702, 1.5741123580436052, 1.5740857419650771, 1.5734558921645332, 1.5735308399668864, 1.5733328048122073, 1.5729535497149156, 1.5724513994391502, 1.5721737082227396, 1.5692115404651246, 1.5690082205295104, 1.5689235679476219, 1.5679638517297985, 3.005612308205163, 3.0006232828285286, 2.2864160794331094, 2.289964953961452, 2.287449206062468, 2.281196829781554, 2.2904034946921437, 5.150244633406857, 14.449198346075015, 3.718240034709455, 5.145933789554592, 3.0056845655735853, 3.719688641207243, 2.2919151342134487, 3.0056843733997334, 2.2821561616516735, 5.8579194632187255, 3.716326367489374, 2.290018186118508, 2.2901154260877146, 3.7135836622709566, 2.2881145119387405, 3.002930137750185, 2.2867716010596557, 2.923669426908375, 2.22744451162529, 1.534302452147276, 1.5333704504691754, 1.5330644646102698, 1.5320464428111917, 1.5314618570910796, 1.5311509557966898, 1.5312575154159414, 1.5306711741831565, 1.530522131157218, 1.5293485709353112, 1.5295079714860205, 1.5294835698598657, 1.5290476760631575, 2.2311561920698333, 2.227626207186946, 2.2265593821355587, 2.228357729317789, 2.22499504479264, 0.8368624587675672, 0.836861756562498, 0.8368615810112306, 0.8368614054599633, 0.8368613176843297, 0.8368607032548941, 0.8368606154792605, 0.8368606154792605, 0.8368602643767259, 0.8368601766010922, 3.618236962676873, 1.5313798746492502, 2.227818962478443, 1.5308217971705005, 1.5347183330995118, 1.5334617371281718, 1.5307942356215343, 1.53071646641012, 9.196479949796196, 2.2264828417830156, 3.62575266353256, 5.709895202313908, 3.618366519512141, 5.045637997255054, 5.019912012339708, 2.2247615616071297, 2.226160529656251, 2.231989182833176, 2.234299788613391, 2.2264196433267873, 1.536488416527707, 1.536297065646349, 1.5357087933496236, 1.5328422167058668, 3.366958208685184, 2.718691708991774, 1.4277402676581237, 1.4277391422872778, 1.4272813976956902, 1.4272709880153651, 1.4260924433969504, 1.4238232737574605, 1.4238196163022112, 1.4237214276959025, 1.421247862576518, 0.7787484664545029, 0.7787477630977242, 0.7787475520906906, 0.7787475520906906, 0.7787474114193348, 0.778747341083657, 0.7787472004123012, 0.7787469894052675, 0.7787467783982339, 0.7787467783982339, 0.7787464970555225, 0.7787451606776429, 0.7787449496706093, 0.7787439649711191, 0.7787438946354412, 0.7787431209429846, 0.7787429802716289, 0.778742909935951, 0.7787420659078166, 2.725100414616713, 3.36981074243694, 1.426629667304533, 1.4214440991177795, 2.0671508021507345, 2.0749259893253607, 4.667641294409134, 1.4238412796909956, 1.4238370595503234, 7.892235308256327, 1.4276914546976809, 2.0674161083276656, 2.0761389984259324, 2.721881853997313, 2.7171676755236547, 2.0667366656794273, 1.4190415730330452, 1.4262803803282231, 1.429795898179596, 4.012557016788285, 2.0822145942804715, 2.7279132790461493, 2.075306646014001, 2.0767074513744896, 2.075140372471513, 2.0822724102076817, 1.4292191456210497, 1.4291192689584722, 2.6340226148514376, 2.0036335245737873, 1.3813389734364125, 1.381337559183795, 1.3811634775434272, 1.3801922717004873, 1.3796016283800656, 1.3768091223026695, 1.3764562019904019, 2.637057858105359, 2.631179709953492, 2.0066352114701487, 0.7534349821444892, 0.7534345964392299, 0.7534345964392299, 0.7534343393023905, 0.7534342750181805, 0.7534340821655509, 0.7534338893129212, 0.7534337607445014, 0.7534336964602916, 0.7534334393234521, 0.7534309322392665, 0.7534304179655874, 0.7534301608287479, 0.7534300322603281, 0.7534297108392787, 0.7534282965866612, 0.7534280394498217, 0.7534280394498217, 2.62956231923279, 1.3788032184932963, 1.379974348228978, 1.3794438749290083, 1.3776525311363583, 2.0025037938692716, 3.2565262182393577, 3.2624869073167173, 1.3788563172506612, 1.3812928173737153, 1.3791594815844779, 1.3773098962976722, 5.148394315528473, 2.0076627302809475, 1.3802701841628677, 1.3791941950578157, 1.3761945652561707, 2.6328523850946945, 2.00592589949828, 2.0095379006832874, 2.012909607491746, 1.3851433129773958, 1.3824822038250042, 1.3824590615094456, 1.3813686727413794, 1.3804258805192087, 1.3803396111095434, 1.3794892595811872, 2.5428376673270314, 1.932144296560726, 1.9313870864522618, 1.333098806942964, 1.3321920171913424, 1.3308536978308962, 1.3296514028267963, 1.3291751997075254, 1.3289288471037441, 1.3286117712644276, 1.3282687635720816, 1.327154518996223, 2.539137191899707, 0.7271291000140898, 0.7271288053339418, 0.7271283338457049, 0.7271279802295272, 0.7271277444854087, 0.7271273319332014, 0.7271271551251126, 0.7271269193809942, 0.7271268604449646, 0.7271268604449646, 0.7271264478927573, 0.7271263889567277, 0.7271260942765796, 0.7271256227883427, 0.7271256227883427, 0.7271255049162835, 0.7271252102361354, 1.3304275903367961, 1.939077177468191, 1.9387454854935304, 3.7496111024451046, 2.5477255858789936, 7.406958557763823, 1.9450489296047313, 1.3307658831467732, 3.7516304865637555, 3.168683137690594, 1.3311061797817572, 1.3380765440040558, 1.3296050791075207, 1.3389282875040192, 1.3340303498270227, 1.3337328407495377, 1.3340373042785172, 1.3532064836541786, 1.3346456419761799], \"Total\": [25.0, 5.0, 20.0, 3.0, 6.0, 29.0, 3.0, 3.0, 3.0, 8.0, 3.0, 3.0, 4.0, 3.0, 4.0, 8.0, 10.0, 9.0, 3.0, 2.0, 3.0, 2.0, 3.0, 6.0, 4.0, 2.0, 6.0, 9.0, 3.0, 6.0, 5.67029544910539, 3.5227752369058494, 6.298160898142259, 2.80679640014349, 2.806706665650908, 2.805846791445419, 2.090978005213442, 2.090977218048867, 2.090938692854571, 2.0909288323273505, 2.090911640864288, 2.0908808641626853, 2.09093083305441, 2.0908424856663994, 2.0909425722115422, 2.090831460680697, 2.0907959751153578, 2.0907484845059683, 2.090664229592326, 2.0901370430785726, 2.090198920778729, 2.0901785230076, 2.09003991932752, 4.17150215815093, 4.170813225250448, 3.4125146725715694, 3.4345550975656733, 3.4341966717415384, 3.4544442065483376, 3.5041081676982047, 8.319902121385, 25.59017057600415, 6.142641399023523, 9.52583187977422, 6.124291278348413, 8.749514643321218, 4.104920323822645, 6.800951716913663, 4.151548359507762, 29.6920246965149, 12.02144288331896, 4.829240384696738, 4.898418346495298, 17.9529276664163, 5.3655140661444545, 11.444820600865862, 5.992525342545218, 3.448221497709105, 2.7513618504932102, 2.0540661792763277, 2.053972968657353, 2.054098223089223, 2.054125404750251, 2.0539189670966387, 2.053846064807107, 2.0541176254002758, 2.0541203783660142, 2.05400661573435, 2.05352474114585, 2.0539842815691065, 2.0540940462165675, 2.054107411358003, 3.357508763039081, 3.3574598793213033, 3.3785833082502457, 3.400481755820533, 3.4673336185693544, 1.3566210391072282, 1.356620787675574, 1.356620788865929, 1.3566208090765086, 1.3566207116871125, 1.3566206501266251, 1.3566205321766585, 1.356620546017272, 1.3566204189344204, 1.356620423186464, 6.78739678380495, 2.660088086393611, 4.094391926720287, 2.681854291542598, 2.702924456383581, 2.7029319752676746, 2.7694055292999584, 2.7694871904658473, 29.6920246965149, 4.898418346495298, 9.367097184938652, 17.9529276664163, 11.444820600865862, 20.282894591245825, 25.59017057600415, 6.021714460121324, 6.580775762828639, 7.4071057005023935, 10.500033140737886, 12.02144288331896, 4.564570256624381, 4.001041078381521, 6.382564352412061, 6.800951716913663, 3.9044746053316097, 3.2556951750433307, 1.9571983995595048, 1.9571981088867652, 1.957182635333296, 1.9571815313277352, 1.957367617530251, 1.957251228391951, 1.9572549324892528, 1.9572816578486476, 1.9576814308706334, 1.3081942795258246, 1.308194113278046, 1.3081940071412024, 1.3081941575572849, 1.3081940566502435, 1.3081942071230104, 1.3081940443819522, 1.3081940016398848, 1.308193926847348, 1.308193934723128, 1.3081939601107062, 1.3081936374085046, 1.3081936851486249, 1.308193722808349, 1.3081936493351924, 1.3081935092110444, 1.3081936118989195, 1.3081936493760218, 1.3081936374177918, 4.580466447091596, 6.660851615413316, 2.585139897965851, 2.5854899392998716, 4.001041078381521, 4.01923237603833, 10.500033140737886, 2.654362000921778, 2.6546732588642703, 20.282894591245825, 2.6730336445105753, 4.490325189231369, 4.577905007556505, 6.580775762828639, 7.4071057005023935, 5.767795514408668, 3.2792127638076916, 3.3886674076614463, 3.7972982517456817, 25.59017057600415, 8.911913186556404, 17.9529276664163, 9.52583187977422, 11.444820600865862, 12.02144288331896, 29.6920246965149, 6.53562557022171, 4.783048449826781, 3.1711811037270587, 2.5427144709014917, 1.9150079934862256, 1.9150079288612947, 1.9150272825991421, 1.9151496268172146, 1.9152348813275728, 1.9148484172219755, 1.914836006166437, 3.819801736536928, 3.8869902207866307, 3.259050465595147, 1.2871008128622532, 1.2871008004553166, 1.2871008482034354, 1.2871007301956, 1.2871007993933834, 1.2871008467278808, 1.2871007389071984, 1.2871008408461233, 1.2871007659519693, 1.2871005909548128, 1.2871006874751458, 1.2871006994084286, 1.2871006765623918, 1.2871007389538964, 1.2871005913912545, 1.2871005618194178, 1.287100356887565, 1.2871006545890702, 4.600161803997416, 2.5642570459840757, 2.6123377444071925, 2.630317409452845, 2.630901695133374, 4.490325189231369, 9.367097184938652, 12.02144288331896, 3.2792316290061407, 3.3279619131440703, 3.328220000003078, 3.3465428910675774, 29.6920246965149, 6.800951716913663, 3.88583614262477, 3.8856848884011774, 4.473104035947186, 17.9529276664163, 10.500033140737886, 11.444820600865862, 20.282894591245825, 8.319902121385, 8.749514643321218, 6.124291278348413, 6.382564352412061, 6.142641399023523, 8.911913186556404, 6.53562557022171, 3.083279287756209, 2.4781895020112534, 2.4776978035165245, 1.8711640695421656, 1.8712276009176674, 1.8714948921169885, 1.871684629541089, 1.871756146126752, 1.8717927698720642, 1.8718412483265965, 1.871892656213623, 1.8715840513904431, 3.7807411823690367, 1.2651806589070933, 1.265180565927341, 1.2651805057863896, 1.2651805101695885, 1.265180548354043, 1.265180599208506, 1.2651806189803636, 1.2651805264962195, 1.2651805163448098, 1.265180558559297, 1.2651805257124726, 1.2651807082873696, 1.2651806766399307, 1.2651804245677325, 1.2651804845734727, 1.265180528790955, 1.2651804947866085, 2.4992110222643573, 3.8720146414749554, 3.8718520948551935, 8.911913186556404, 6.382564352412061, 29.6920246965149, 5.767795514408668, 3.302752540699206, 20.282894591245825, 17.9529276664163, 3.7972982517456817, 4.473104035947186, 5.3655140661444545, 6.021714460121324, 5.992525342545218, 6.53562557022171, 8.749514643321218, 25.59017057600415, 9.52583187977422], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.3832, -4.9219, -4.3831, -5.1941, -5.1946, -5.1969, -5.5685, -5.5685, -5.5687, -5.5688, -5.5688, -5.569, -5.569, -5.5694, -5.5694, -5.5695, -5.5697, -5.5701, -5.5702, -5.5721, -5.5723, -5.5723, -5.5729, -4.9222, -4.9239, -5.1957, -5.1942, -5.1953, -5.198, -5.194, -4.3837, -3.3521, -4.7094, -4.3845, -4.9222, -4.7091, -5.1933, -4.9222, -5.1976, -4.2549, -4.71, -5.1941, -5.1941, -4.7107, -5.195, -4.9231, -5.1956, -4.8594, -5.1314, -5.5042, -5.5048, -5.505, -5.5056, -5.506, -5.5062, -5.5061, -5.5065, -5.5066, -5.5074, -5.5073, -5.5073, -5.5076, -5.1297, -5.1313, -5.1318, -5.131, -5.1325, -6.1103, -6.1103, -6.1103, -6.1103, -6.1103, -6.1103, -6.1103, -6.1103, -6.1103, -6.1103, -4.6462, -5.5061, -5.1312, -5.5064, -5.5039, -5.5047, -5.5064, -5.5065, -3.7134, -5.1318, -4.6442, -4.19, -4.6462, -4.3137, -4.3188, -5.1326, -5.1319, -5.1293, -5.1283, -5.1318, -5.5027, -5.5029, -5.5032, -5.5051, -4.4967, -4.7106, -5.3546, -5.3546, -5.355, -5.355, -5.3558, -5.3574, -5.3574, -5.3574, -5.3592, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -5.9608, -4.7082, -4.4959, -5.3554, -5.359, -4.9846, -4.9808, -4.1701, -5.3574, -5.3574, -3.6448, -5.3547, -4.9844, -4.9802, -4.7094, -4.7111, -4.9848, -5.3607, -5.3557, -5.3532, -4.3213, -4.9773, -4.7072, -4.9806, -4.9799, -4.9807, -4.9773, -5.3536, -5.3537, -4.6522, -4.9258, -5.2977, -5.2977, -5.2978, -5.2985, -5.299, -5.301, -5.3012, -4.6511, -4.6533, -4.9243, -5.9039, -5.9039, -5.9039, -5.9039, -5.9039, -5.9039, -5.9039, -5.9039, -5.9039, -5.9039, -5.9039, -5.9039, -5.9039, -5.9039, -5.9039, -5.9039, -5.9039, -5.9039, -4.6539, -5.2995, -5.2987, -5.2991, -5.3004, -4.9264, -4.4401, -4.4383, -5.2995, -5.2977, -5.2993, -5.3006, -3.9821, -4.9238, -5.2985, -5.2993, -5.3014, -4.6527, -4.9247, -4.9229, -4.9212, -5.295, -5.2969, -5.2969, -5.2977, -5.2984, -5.2984, -5.299, -4.6006, -4.8753, -4.8757, -5.2464, -5.2471, -5.2481, -5.249, -5.2493, -5.2495, -5.2498, -5.25, -5.2509, -4.6021, -5.8525, -5.8525, -5.8525, -5.8525, -5.8525, -5.8526, -5.8526, -5.8526, -5.8526, -5.8526, -5.8526, -5.8526, -5.8526, -5.8526, -5.8526, -5.8526, -5.8526, -5.2484, -4.8717, -4.8719, -4.2122, -4.5987, -3.5315, -4.8686, -5.2481, -4.2117, -4.3806, -5.2479, -5.2427, -5.249, -5.242, -5.2457, -5.2459, -5.2457, -5.2314, -5.2452], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2724, 1.2097, 1.1674, 1.1647, 1.1642, 1.1622, 1.0847, 1.0847, 1.0844, 1.0844, 1.0843, 1.0842, 1.0842, 1.0838, 1.0838, 1.0837, 1.0835, 1.0832, 1.0831, 1.0814, 1.0813, 1.0812, 1.0807, 1.0403, 1.0388, 0.9676, 0.9628, 0.9618, 0.9531, 0.9429, 0.8885, 0.7965, 0.8661, 0.7523, 0.6563, 0.5127, 0.7853, 0.5515, 0.7697, -0.255, 0.1941, 0.622, 0.6078, -0.2077, 0.5158, 0.0302, 0.4047, 1.2936, 1.2473, 1.1668, 1.1663, 1.166, 1.1653, 1.165, 1.1649, 1.1648, 1.1644, 1.1644, 1.1639, 1.1637, 1.1637, 1.1634, 1.0499, 1.0483, 1.0416, 1.0359, 1.0149, 0.9755, 0.9755, 0.9755, 0.9755, 0.9755, 0.9755, 0.9755, 0.9755, 0.9755, 0.9755, 0.8295, 0.9064, 0.85, 0.8979, 0.8926, 0.8918, 0.8657, 0.8656, 0.2865, 0.6701, 0.5094, 0.313, 0.3071, 0.0673, -0.1702, 0.4628, 0.3747, 0.259, -0.0889, -0.2277, 0.3697, 0.5014, 0.034, -0.0314, 1.532, 1.4998, 1.3647, 1.3647, 1.3643, 1.3643, 1.3634, 1.3619, 1.3619, 1.3618, 1.3598, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1614, 1.1608, 0.9987, 1.0856, 1.0818, 1.0197, 1.0189, 0.8694, 1.0572, 1.0571, 0.7362, 1.0529, 0.9044, 0.8893, 0.7972, 0.6772, 0.6538, 0.8425, 0.8147, 0.7033, -0.1727, 0.2261, -0.2041, 0.1562, -0.0267, -0.0766, -0.9773, 0.1599, 0.4721, 1.5844, 1.5318, 1.4434, 1.4434, 1.4432, 1.4425, 1.442, 1.4402, 1.4399, 1.3995, 1.3798, 1.2851, 1.2345, 1.2345, 1.2345, 1.2345, 1.2345, 1.2345, 1.2345, 1.2345, 1.2345, 1.2345, 1.2345, 1.2345, 1.2345, 1.2345, 1.2345, 1.2345, 1.2345, 1.2345, 1.2108, 1.1496, 1.1319, 1.1246, 1.1231, 0.9625, 0.7135, 0.4658, 0.9037, 0.8907, 0.8891, 0.8822, 0.0178, 0.5499, 0.735, 0.7342, 0.5913, -0.1496, 0.1148, 0.0304, -0.5402, -0.0228, -0.0751, 0.2816, 0.2395, 0.2772, -0.095, 0.2145, 1.6642, 1.608, 1.6078, 1.5178, 1.5171, 1.516, 1.515, 1.5146, 1.5144, 1.5141, 1.5138, 1.5132, 1.4588, 1.303, 1.303, 1.303, 1.303, 1.303, 1.303, 1.303, 1.303, 1.303, 1.303, 1.303, 1.303, 1.303, 1.303, 1.303, 1.303, 1.303, 1.2264, 1.1653, 1.1652, 0.9912, 0.9385, 0.4684, 0.7699, 0.9479, 0.1693, 0.1225, 0.8086, 0.6501, 0.4618, 0.3534, 0.3546, 0.2676, -0.0239, -1.0828, -0.1084]}, \"token.table\": {\"Topic\": [1, 3, 3, 5, 3, 1, 3, 2, 1, 4, 1, 2, 3, 5, 1, 2, 4, 5, 1, 3, 1, 3, 2, 3, 4, 5, 4, 1, 2, 4, 5, 5, 4, 3, 4, 2, 3, 3, 4, 2, 3, 2, 3, 5, 4, 4, 2, 2, 2, 5, 1, 2, 1, 5, 2, 2, 4, 3, 3, 2, 3, 1, 5, 5, 1, 4, 4, 5, 1, 4, 2, 5, 2, 3, 1, 4, 5, 3, 2, 1, 2, 3, 1, 4, 5, 2, 3, 4, 5, 2, 4, 3, 2, 1, 4, 1, 4, 3, 3, 2, 3, 4, 4, 5, 3, 1, 1, 3, 4, 2, 4, 4, 1, 3, 3, 2, 5, 5, 1, 1, 2, 3, 4, 2, 3, 4, 5, 5, 3, 4, 3, 4, 5, 1, 3, 4, 5, 1, 1, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 4, 5, 2, 3, 4, 5, 1, 2, 4, 4, 1, 5, 5, 1, 5, 5, 1, 2, 4, 3, 4, 5, 4, 1, 4, 3, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 2, 4, 2, 1, 1, 2, 3, 4, 5, 2, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 4, 1, 3, 4, 5, 4, 5, 5, 2, 5, 3, 2, 1, 2, 3, 4, 5, 5, 1, 4, 2, 3, 2, 3, 3, 1, 3, 4, 3, 2, 5, 4, 1, 1, 2, 4, 1, 5, 1, 2, 3, 4, 3, 1, 4, 3, 1, 3, 5, 1, 2, 3, 5, 5, 4, 2, 3, 4, 3, 4, 2, 3, 1, 3, 4, 2, 2, 1, 2, 3, 3, 1, 2, 5, 2, 3, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 1, 2, 4, 5, 5, 4, 1, 4, 3, 2, 5, 1, 2, 1, 2, 3, 5, 3, 1, 3, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 3, 4, 2, 2, 1, 3, 2, 4, 3, 1, 3, 2, 1, 5, 1, 2, 1, 4, 1, 2, 3, 4, 5, 1, 2, 4, 1, 4, 2, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 1, 2], \"Freq\": [0.5789643370730221, 0.28948216853651104, 0.7644125917668763, 0.790401035459841, 0.7644125515090574, 0.48722017535715045, 0.24361008767857523, 0.7371257395401296, 0.30683783836939954, 0.6136756767387991, 0.37275086326204676, 0.18637543163102338, 0.18637543163102338, 0.18637543163102338, 0.40829505740989896, 0.40829505740989896, 0.9460197642052448, 0.7904010498315707, 0.7192841870352169, 0.23976139567840565, 0.7191653956448598, 0.2397217985482866, 0.4381573483500399, 0.21907867417501994, 0.21907867417501994, 0.21907867417501994, 0.7769400695361529, 0.6009686084104626, 0.24038744336418508, 0.12019372168209254, 0.7904010122594862, 0.7904010630839976, 0.7769399678982628, 0.510890233926405, 0.7769399626396308, 0.3767383648698749, 0.3767383648698749, 0.4454020401008752, 0.4454020401008752, 0.9736589181954065, 0.764412779670936, 0.3766941926509716, 0.3766941926509716, 0.534233338908408, 0.7769399864824994, 0.7865609854695647, 0.7269127467335782, 0.9739351856476861, 0.5165486570774599, 0.5165486570774599, 0.9564905742331522, 0.7371258628490753, 0.9568560665919386, 0.5342471752726929, 0.9737066982546979, 0.9736784628354205, 0.7769399626114423, 0.7644128295669386, 0.76441282260328, 0.9737172859337239, 0.5109344810111175, 0.5860780661472906, 0.2930390330736453, 0.7904009791154734, 0.3800978203973922, 0.3800978203973922, 0.5221524135750684, 0.5342576286282336, 0.9565734886636424, 0.522237934099658, 0.26449840170582467, 0.7934952051174741, 0.499869899063628, 0.499869899063628, 0.8516013081308539, 0.4001262762893752, 0.4001262762893752, 0.7683492155137753, 0.9736632735079909, 0.48174797131283675, 0.24087398565641838, 0.24087398565641838, 0.434767315850076, 0.652150973775114, 0.7904011005716158, 0.313353675665514, 0.156676837832757, 0.156676837832757, 0.4700305134982709, 0.38279889426278074, 0.38279889426278074, 0.5109206143258295, 0.7371256641555323, 0.7125789183730665, 0.7769399936858554, 0.9565952168907531, 0.7769399261280117, 0.7644125845981873, 0.5109388086865957, 0.21831837686202418, 0.6549551305860726, 0.21831837686202418, 0.7769399179977218, 0.7904009914676196, 0.510912671147776, 0.9565205726117105, 0.3049494860791755, 0.3049494860791755, 0.3049494860791755, 0.7371256648023167, 0.776940000273184, 0.7769401932403903, 0.9564902141550001, 0.7644128016765264, 0.5109385204767598, 0.5956797557810932, 0.2978398778905466, 0.7904010470932381, 0.712556136917432, 0.4898525990437597, 0.16328419968125324, 0.16328419968125324, 0.16328419968125324, 0.22355840417832998, 0.22355840417832998, 0.22355840417832998, 0.22355840417832998, 0.5343067543544607, 0.38682626065493103, 0.38682626065493103, 0.2617936921790633, 0.7853810765371899, 0.7904009541719003, 0.2573548881910146, 0.2573548881910146, 0.2573548881910146, 0.2573548881910146, 0.8817882674506594, 0.5976316650051905, 0.29881583250259525, 0.790401037383073, 0.2020744648209945, 0.3031116972314918, 0.0673581549403315, 0.16839538735082876, 0.23575354229116025, 0.7644126604454793, 0.3337491100455715, 0.16687455502278575, 0.16687455502278575, 0.16687455502278575, 0.16687455502278575, 0.5222345492238912, 0.7904009233223803, 0.3039155370248222, 0.4558733055372333, 0.1519577685124111, 0.1519577685124111, 0.3004609070311083, 0.3004609070311083, 0.3004609070311083, 0.7769400519489839, 0.9566337682019819, 0.9729900278294886, 0.5344085345414907, 0.71279729388564, 0.8072009416004882, 0.5342186672299646, 0.3004842080825548, 0.3004842080825548, 0.3004842080825548, 0.26334512953789796, 0.26334512953789796, 0.26334512953789796, 0.7769398966645253, 0.582377828403685, 0.2911889142018425, 0.5109344051298347, 0.095237794642782, 0.190475589285564, 0.47618897321390996, 0.190475589285564, 0.095237794642782, 0.9565346521074602, 0.5470850598052586, 0.19538752135902093, 0.15631001708721673, 0.03907750427180418, 0.03907750427180418, 0.973722648992487, 0.5221291705520921, 0.7371257060909722, 0.9565081974113643, 0.2621273067201275, 0.3495030756268367, 0.17475153781341835, 0.17475153781341835, 0.08737576890670917, 0.5956884287190028, 0.2978442143595014, 0.3002619057557097, 0.15013095287785486, 0.4503928586335646, 0.15013095287785486, 0.41814337048424216, 0.41814337048424216, 0.20907168524212108, 0.4411147328893887, 0.2940764885929258, 0.2940764885929258, 0.2573448707810229, 0.2573448707810229, 0.2573448707810229, 0.2573448707810229, 0.7769399011056609, 0.5344266792407354, 0.790401056703506, 0.8700137163442402, 0.5343322090870496, 0.510919647410566, 0.7371258651594426, 0.4571682159596506, 0.2285841079798253, 0.11429205398991266, 0.11429205398991266, 0.11429205398991266, 0.8070407845634228, 0.9569195217302401, 0.5221910317875615, 0.5881519571680225, 0.29407597858401124, 0.7399392888234585, 0.36996964441172925, 0.7644124543660791, 0.6511856610473579, 0.16279641526183947, 0.16279641526183947, 0.7644128225794223, 0.5165269724388608, 0.5165269724388608, 0.776940013537067, 0.956846728853384, 0.4141438074480101, 0.4141438074480101, 0.20707190372400505, 0.6055555102461875, 0.30277775512309374, 0.14733189053954343, 0.5893275621581737, 0.14733189053954343, 0.14733189053954343, 0.7644125256355234, 0.7938825445813599, 0.15877650891627199, 0.7644128444783044, 0.30495124044309946, 0.30495124044309946, 0.30495124044309946, 0.5248885412954096, 0.10497770825908193, 0.20995541651816385, 0.10497770825908193, 0.7904010432353686, 0.5221910494097127, 0.9737482500719797, 0.3899765047213641, 0.3899765047213641, 0.7644126167422044, 0.7769399254869909, 0.7371256531740282, 0.7644128295723654, 0.21844053084311557, 0.43688106168623114, 0.21844053084311557, 0.9736503892970294, 0.9736652533917796, 0.956875055931352, 0.739937230496501, 0.3699686152482505, 0.7644129044816067, 0.3610776765614117, 0.7221553531228234, 0.5342780424740604, 0.7371258036287633, 0.7644126410088109, 0.17337646549741162, 0.34675293099482324, 0.17337646549741162, 0.34675293099482324, 0.15300754139837858, 0.30601508279675715, 0.15300754139837858, 0.15300754139837858, 0.15300754139837858, 0.25726846305201784, 0.7718053891560536, 0.3321313245994903, 0.3321313245994903, 0.16606566229974515, 0.16606566229974515, 0.7904010232381189, 0.7769399463144419, 0.5823170521904132, 0.2911585260952066, 0.764412613527638, 0.7518548014368505, 0.37592740071842523, 0.9565064227874254, 0.9736540767037476, 0.24880372828447364, 0.24880372828447364, 0.4976074565689473, 0.7904009430935999, 0.5108083390029772, 0.5902025071797236, 0.2951012535898618, 0.9565127081699187, 0.7644124966729572, 0.7904010368934399, 0.33273876013256515, 0.16636938006628257, 0.16636938006628257, 0.24955407009942387, 0.08318469003314129, 0.2884060520292844, 0.5768121040585688, 0.7769400516855319, 0.22280488588402284, 0.3342073288260342, 0.1671036644130171, 0.1671036644130171, 0.1671036644130171, 0.21351331800163217, 0.42702663600326435, 0.10675665900081609, 0.32026997700244825, 0.38677388946668706, 0.38677388946668706, 0.7371257961084045, 0.7371255281858852, 0.9565572537103849, 0.7644126558434506, 0.5919640919068506, 0.2959820459534253, 0.9214621881669472, 0.37410677641623813, 0.37410677641623813, 0.9736527717966241, 0.9565522097962125, 0.7904010168625522, 0.36108832362040416, 0.7221766472408083, 0.3801822534444687, 0.3801822534444687, 0.09860525532993736, 0.2465131383248434, 0.39442102131974943, 0.09860525532993736, 0.19721051065987472, 0.244236511281182, 0.488473022562364, 0.244236511281182, 0.9565117929216342, 0.5221857720182268, 0.7457526705709293, 0.37287633528546466, 0.7769398975552226, 0.2700109976646274, 0.2700109976646274, 0.4050164964969411, 0.1350054988323137, 0.11220935157991632, 0.11220935157991632, 0.22441870315983264, 0.11220935157991632, 0.4488374063196653, 0.973782813751349, 0.5707586365159982, 0.2853793182579991], \"Term\": [\"achieve\", \"achieve\", \"actually\", \"adversarial\", \"agrawaletalet\", \"also\", \"also\", \"analogy\", \"analysis\", \"analysis\", \"application\", \"application\", \"application\", \"application\", \"apply\", \"apply\", \"arabic\", \"attack\", \"attention\", \"attention\", \"author\", \"author\", \"available\", \"available\", \"available\", \"available\", \"azouaoua\", \"base\", \"base\", \"base\", \"basedon\", \"behavior\", \"bind\", \"biomedical\", \"certain\", \"challenge\", \"challenge\", \"classification\", \"classification\", \"clinical\", \"come\", \"community\", \"community\", \"computer\", \"conceal\", \"confound\", \"consist\", \"constrain\", \"context\", \"context\", \"contextual\", \"corpus\", \"counterexample\", \"course\", \"create\", \"czech\", \"decipher\", \"dedescribe\", \"denominal\", \"describe\", \"detection\", \"develop\", \"develop\", \"developer\", \"different\", \"different\", \"distance\", \"distribute\", \"diverse\", \"domain\", \"efficient\", \"efficient\", \"embed\", \"embed\", \"emotion\", \"encode\", \"encode\", \"evaluate\", \"explore\", \"extraction\", \"extraction\", \"extraction\", \"feature\", \"feature\", \"fix\", \"framework\", \"framework\", \"framework\", \"framework\", \"free\", \"free\", \"gain\", \"gender\", \"generate\", \"give\", \"globally\", \"go\", \"goal\", \"graph\", \"ground\", \"ground\", \"ground\", \"handle\", \"harm\", \"help\", \"hide\", \"high\", \"high\", \"high\", \"highlyinflecte\", \"hindienglish\", \"houda\", \"hybrid\", \"image\", \"imputation\", \"include\", \"include\", \"incrementally\", \"indian\", \"information\", \"information\", \"information\", \"information\", \"input\", \"input\", \"input\", \"input\", \"intent\", \"interaction\", \"interaction\", \"interpretation\", \"interpretation\", \"inthisframework\", \"introduce\", \"introduce\", \"introduce\", \"introduce\", \"key\", \"label\", \"label\", \"lack\", \"language\", \"language\", \"language\", \"language\", \"language\", \"lanophobicguage\", \"large\", \"large\", \"large\", \"large\", \"large\", \"latent\", \"lead\", \"learn\", \"learn\", \"learn\", \"learn\", \"learning\", \"learning\", \"learning\", \"leave\", \"level\", \"lexical\", \"linguistic\", \"lithium\", \"lm\", \"lolcode\", \"machine\", \"machine\", \"machine\", \"make\", \"make\", \"make\", \"match\", \"medium\", \"medium\", \"mention\", \"method\", \"method\", \"method\", \"method\", \"method\", \"mix\", \"model\", \"model\", \"model\", \"model\", \"model\", \"modification\", \"module\", \"name\", \"national\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"need\", \"need\", \"network\", \"network\", \"network\", \"network\", \"neural\", \"neural\", \"neural\", \"new\", \"new\", \"new\", \"novel\", \"novel\", \"novel\", \"novel\", \"numple\", \"offensive\", \"ofinteraction\", \"organize\", \"original\", \"outofvocabulary\", \"outperform\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"parallel\", \"path\", \"pattern\", \"perform\", \"perform\", \"play\", \"play\", \"predic\", \"present\", \"present\", \"present\", \"president\", \"pretraine\", \"pretraine\", \"primary\", \"probability\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"processing\", \"processing\", \"processing\", \"processing\", \"progressby\", \"project\", \"project\", \"pronominal\", \"property\", \"property\", \"property\", \"propose\", \"propose\", \"propose\", \"propose\", \"public\", \"re\", \"read\", \"recent\", \"recent\", \"refer\", \"regular\", \"relatively\", \"rer\", \"research\", \"research\", \"research\", \"retrieval\", \"review\", \"rich\", \"rnn\", \"rnn\", \"robustness\", \"rule\", \"rule\", \"science\", \"search\", \"seek\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sentiment\", \"sentiment\", \"set\", \"set\", \"set\", \"set\", \"shut\", \"simcentric\", \"social\", \"social\", \"sophisticated\", \"speak\", \"speak\", \"special\", \"speech\", \"stateoftheart\", \"stateoftheart\", \"stateoftheart\", \"still\", \"strategy\", \"study\", \"study\", \"suppose\", \"surprisingly\", \"syntactic\", \"system\", \"system\", \"system\", \"system\", \"system\", \"tag\", \"tag\", \"target\", \"task\", \"task\", \"task\", \"task\", \"task\", \"text\", \"text\", \"text\", \"text\", \"textual\", \"textual\", \"thecorpus\", \"theselanguage\", \"thesis\", \"top\", \"topic\", \"topic\", \"traditional\", \"train\", \"train\", \"translation\", \"tree\", \"troll\", \"understand\", \"understand\", \"usage\", \"usage\", \"use\", \"use\", \"use\", \"use\", \"use\", \"user\", \"user\", \"user\", \"utilize\", \"visual\", \"way\", \"way\", \"widely\", \"word\", \"word\", \"word\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"worsen\", \"write\", \"write\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 2, 1, 4, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el751226268908211844658022809\", ldavis_el751226268908211844658022809_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el751226268908211844658022809\", ldavis_el751226268908211844658022809_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el751226268908211844658022809\", ldavis_el751226268908211844658022809_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "4      0.130937  0.046639       1        1  25.458988\n",
       "1     -0.022906 -0.054339       2        1  23.256846\n",
       "0     -0.019819 -0.081584       3        1  18.635992\n",
       "3      0.004411 -0.007200       4        1  17.032608\n",
       "2     -0.092623  0.096484       5        1  15.615566, topic_info=         Term       Freq      Total Category  logprob  loglift\n",
       "37      model  25.000000  25.000000  Default  30.0000  30.0000\n",
       "99        key   5.000000   5.000000  Default  29.0000  29.0000\n",
       "54        use  20.000000  20.000000  Default  28.0000  28.0000\n",
       "67   evaluate   3.000000   3.000000  Default  27.0000  27.0000\n",
       "105   project   6.000000   6.000000  Default  26.0000  26.0000\n",
       "..        ...        ...        ...      ...      ...      ...\n",
       "35      large   1.334030   5.992525   Topic5  -5.2457   0.3546\n",
       "290  sentence   1.333733   6.535626   Topic5  -5.2459   0.2676\n",
       "9       paper   1.334037   8.749515   Topic5  -5.2457  -0.0239\n",
       "37      model   1.353206  25.590171   Topic5  -5.2314  -1.0828\n",
       "191   propose   1.334646   9.525832   Topic5  -5.2452  -0.1084\n",
       "\n",
       "[296 rows x 6 columns], token_table=      Topic      Freq           Term\n",
       "term                                \n",
       "565       1  0.578964        achieve\n",
       "565       3  0.289482        achieve\n",
       "157       3  0.764413       actually\n",
       "719       5  0.790401    adversarial\n",
       "158       3  0.764413  agrawaletalet\n",
       "...     ...       ...            ...\n",
       "94        4  0.112209           work\n",
       "94        5  0.448837           work\n",
       "19        2  0.973783         worsen\n",
       "379       1  0.570759          write\n",
       "379       2  0.285379          write\n",
       "\n",
       "[379 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 2, 1, 4, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd9f82fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dglover\\AppData\\Local\\Temp\\ipykernel_7512\\3153082663.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=texts)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bcdeb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic.to_csv('../data/Dominant_topics_of_absracts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea71fbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>[uniblock, scoring, filter, information, train, good, property, block, unsupervise, supervised, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>language, use, work, task, framework, lexical, efficient, semantic, pretraine, context</td>\n",
       "      <td>[troll, public, commurum, fix, emit, offensive, language, adversarial, attack, lead, developer, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>[base, contextual, emotion, classifier, contextual, emotion, classifier, base, emotion, propose,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>use, method, model, network, evaluate, task, ground, learn, traditional, word</td>\n",
       "      <td>[program, synthesis, semantic, parsing, learn, code, idiom, author, require, highlevel, reasonin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>language, task, use, model, text, natural, processing, organize, method, word</td>\n",
       "      <td>[unilateral, contract, term, service, play, substantial, role, modern, digital, life, propose, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>use, method, model, network, evaluate, task, ground, learn, traditional, word</td>\n",
       "      <td>[outofvocabulary, embed, imputation, ground, language, graph, convolutional, network, ground, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>language, system, text, interpretation, arabic, task, sentiment, feature, use, natural</td>\n",
       "      <td>[evaluation, basic, module, isolate, spelling, error, correction, polish, text, module, combine,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>language, use, work, task, framework, lexical, efficient, semantic, pretraine, context</td>\n",
       "      <td>[pretraine, framework, language, understanding, framework, incrementally, build, pretraine, task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>[new, model, achieve, considerable, deal, special, ever, application, gradually, introly, attent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>[aim, build, neural, network, model, task, errorbase, errorcorrection, natural, language, applic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "40           40               4              0.9935   \n",
       "41           41               2              0.9908   \n",
       "42           42               4              0.9917   \n",
       "43           43               0              0.9893   \n",
       "44           44               1              0.9938   \n",
       "45           45               0              0.9946   \n",
       "46           46               3              0.9908   \n",
       "47           47               2              0.9920   \n",
       "48           48               4              0.9909   \n",
       "49           49               4              0.9943   \n",
       "\n",
       "                                                                                  Keywords  \\\n",
       "40              model, language, project, key, base, propose, paper, present, system, task   \n",
       "41  language, use, work, task, framework, lexical, efficient, semantic, pretraine, context   \n",
       "42              model, language, project, key, base, propose, paper, present, system, task   \n",
       "43           use, method, model, network, evaluate, task, ground, learn, traditional, word   \n",
       "44           language, task, use, model, text, natural, processing, organize, method, word   \n",
       "45           use, method, model, network, evaluate, task, ground, learn, traditional, word   \n",
       "46  language, system, text, interpretation, arabic, task, sentiment, feature, use, natural   \n",
       "47  language, use, work, task, framework, lexical, efficient, semantic, pretraine, context   \n",
       "48              model, language, project, key, base, propose, paper, present, system, task   \n",
       "49              model, language, project, key, base, propose, paper, present, system, task   \n",
       "\n",
       "                                                                                                   Text  \n",
       "40  [uniblock, scoring, filter, information, train, good, property, block, unsupervise, supervised, ...  \n",
       "41  [troll, public, commurum, fix, emit, offensive, language, adversarial, attack, lead, developer, ...  \n",
       "42  [base, contextual, emotion, classifier, contextual, emotion, classifier, base, emotion, propose,...  \n",
       "43  [program, synthesis, semantic, parsing, learn, code, idiom, author, require, highlevel, reasonin...  \n",
       "44  [unilateral, contract, term, service, play, substantial, role, modern, digital, life, propose, t...  \n",
       "45  [outofvocabulary, embed, imputation, ground, language, graph, convolutional, network, ground, in...  \n",
       "46  [evaluation, basic, module, isolate, spelling, error, correction, polish, text, module, combine,...  \n",
       "47  [pretraine, framework, language, understanding, framework, incrementally, build, pretraine, task...  \n",
       "48  [new, model, achieve, considerable, deal, special, ever, application, gradually, introly, attent...  \n",
       "49  [aim, build, neural, network, model, task, errorbase, errorcorrection, natural, language, applic...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4634e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    13\n",
       "1    10\n",
       "0     9\n",
       "3     9\n",
       "2     9\n",
       "Name: Dominant_Topic, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic['Dominant_Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3db13218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>use, method, model, network, evaluate, task, ground, learn, traditional, word</td>\n",
       "      <td>[quantification, semantic, similarity, word, use, evaluate, ability, system, perform, semantic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>language, task, use, model, text, natural, processing, organize, method, word</td>\n",
       "      <td>[problem, tag, natural, language, processing, find, way, tag, text, meticulous, part, speech, te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>language, use, work, task, framework, lexical, efficient, semantic, pretraine, context</td>\n",
       "      <td>[novel, teaching, parallel, distribute, computing, concept, use, memebase, programming, language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>language, system, text, interpretation, arabic, task, sentiment, feature, use, natural</td>\n",
       "      <td>[grow, body, research, arabic, language, recent, year, example, orthography, dialect, make, sent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>[automate, technique, model, check, violation, probability, reach, error, state, exceed, use, ve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0          0              0.9959   \n",
       "1          1              0.9961   \n",
       "2          2              0.9965   \n",
       "3          3              0.9959   \n",
       "4          4              0.9965   \n",
       "\n",
       "                                                                                 Keywords  \\\n",
       "0           use, method, model, network, evaluate, task, ground, learn, traditional, word   \n",
       "1           language, task, use, model, text, natural, processing, organize, method, word   \n",
       "2  language, use, work, task, framework, lexical, efficient, semantic, pretraine, context   \n",
       "3  language, system, text, interpretation, arabic, task, sentiment, feature, use, natural   \n",
       "4              model, language, project, key, base, propose, paper, present, system, task   \n",
       "\n",
       "                                                                                                  Text  \n",
       "0  [quantification, semantic, similarity, word, use, evaluate, ability, system, perform, semantic, ...  \n",
       "1  [problem, tag, natural, language, processing, find, way, tag, text, meticulous, part, speech, te...  \n",
       "2  [novel, teaching, parallel, distribute, computing, concept, use, memebase, programming, language...  \n",
       "3  [grow, body, research, arabic, language, recent, year, example, orthography, dialect, make, sent...  \n",
       "4  [automate, technique, model, check, violation, probability, reach, error, state, exceed, use, ve...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c0c711e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Representative Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>use, method, model, network, evaluate, task, ground, learn, traditional, word</td>\n",
       "      <td>[quantification, semantic, similarity, word, use, evaluate, ability, system, perform, semantic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>language, task, use, model, text, natural, processing, organize, method, word</td>\n",
       "      <td>[problem, tag, natural, language, processing, find, way, tag, text, meticulous, part, speech, te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>language, use, work, task, framework, lexical, efficient, semantic, pretraine, context</td>\n",
       "      <td>[novel, teaching, parallel, distribute, computing, concept, use, memebase, programming, language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>language, system, text, interpretation, arabic, task, sentiment, feature, use, natural</td>\n",
       "      <td>[grow, body, research, arabic, language, recent, year, example, orthography, dialect, make, sent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>[automate, technique, model, check, violation, probability, reach, error, state, exceed, use, ve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0          0              0.9959   \n",
       "1          1              0.9961   \n",
       "2          2              0.9965   \n",
       "3          3              0.9959   \n",
       "4          4              0.9965   \n",
       "\n",
       "                                                                                 Keywords  \\\n",
       "0           use, method, model, network, evaluate, task, ground, learn, traditional, word   \n",
       "1           language, task, use, model, text, natural, processing, organize, method, word   \n",
       "2  language, use, work, task, framework, lexical, efficient, semantic, pretraine, context   \n",
       "3  language, system, text, interpretation, arabic, task, sentiment, feature, use, natural   \n",
       "4              model, language, project, key, base, propose, paper, present, system, task   \n",
       "\n",
       "                                                                                   Representative Text  \n",
       "0  [quantification, semantic, similarity, word, use, evaluate, ability, system, perform, semantic, ...  \n",
       "1  [problem, tag, natural, language, processing, find, way, tag, text, meticulous, part, speech, te...  \n",
       "2  [novel, teaching, parallel, distribute, computing, concept, use, memebase, programming, language...  \n",
       "3  [grow, body, research, arabic, language, recent, year, example, orthography, dialect, make, sent...  \n",
       "4  [automate, technique, model, check, violation, probability, reach, error, state, exceed, use, ve...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0e6eaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>language, task, use, model, text, natural, processing, organize, method, word</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>language, task, use, model, text, natural, processing, organize, method, word</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>use, method, model, network, evaluate, task, ground, learn, traditional, word</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>language, system, text, interpretation, arabic, task, sentiment, feature, use, natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>language, use, work, task, framework, lexical, efficient, semantic, pretraine, context</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>use, method, model, network, evaluate, task, ground, learn, traditional, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>language, system, text, interpretation, arabic, task, sentiment, feature, use, natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>language, task, use, model, text, natural, processing, organize, method, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>language, task, use, model, text, natural, processing, organize, method, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>language, use, work, task, framework, lexical, efficient, semantic, pretraine, context</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>language, system, text, interpretation, arabic, task, sentiment, feature, use, natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>language, use, work, task, framework, lexical, efficient, semantic, pretraine, context</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>language, task, use, model, text, natural, processing, organize, method, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>language, task, use, model, text, natural, processing, organize, method, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>use, method, model, network, evaluate, task, ground, learn, traditional, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>language, use, work, task, framework, lexical, efficient, semantic, pretraine, context</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>use, method, model, network, evaluate, task, ground, learn, traditional, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>language, system, text, interpretation, arabic, task, sentiment, feature, use, natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>language, use, work, task, framework, lexical, efficient, semantic, pretraine, context</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>language, use, work, task, framework, lexical, efficient, semantic, pretraine, context</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>use, method, model, network, evaluate, task, ground, learn, traditional, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>language, system, text, interpretation, arabic, task, sentiment, feature, use, natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>language, task, use, model, text, natural, processing, organize, method, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>language, task, use, model, text, natural, processing, organize, method, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>use, method, model, network, evaluate, task, ground, learn, traditional, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>language, system, text, interpretation, arabic, task, sentiment, feature, use, natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>language, task, use, model, text, natural, processing, organize, method, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>language, system, text, interpretation, arabic, task, sentiment, feature, use, natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>use, method, model, network, evaluate, task, ground, learn, traditional, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>language, system, text, interpretation, arabic, task, sentiment, feature, use, natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>language, use, work, task, framework, lexical, efficient, semantic, pretraine, context</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>language, use, work, task, framework, lexical, efficient, semantic, pretraine, context</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>use, method, model, network, evaluate, task, ground, learn, traditional, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>language, task, use, model, text, natural, processing, organize, method, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>use, method, model, network, evaluate, task, ground, learn, traditional, word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>language, system, text, interpretation, arabic, task, sentiment, feature, use, natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>language, use, work, task, framework, lexical, efficient, semantic, pretraine, context</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4</td>\n",
       "      <td>model, language, project, key, base, propose, paper, present, system, task</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dominant_Topic  \\\n",
       "0                1   \n",
       "1                1   \n",
       "2                0   \n",
       "3                4   \n",
       "4                4   \n",
       "5                3   \n",
       "6                2   \n",
       "7                0   \n",
       "8                4   \n",
       "9                3   \n",
       "10               1   \n",
       "11               1   \n",
       "12               2   \n",
       "13               4   \n",
       "14               3   \n",
       "15               2   \n",
       "16               1   \n",
       "17               1   \n",
       "18               4   \n",
       "19               4   \n",
       "20               4   \n",
       "21               0   \n",
       "22               4   \n",
       "23               2   \n",
       "24               0   \n",
       "25               3   \n",
       "26               2   \n",
       "27               2   \n",
       "28               0   \n",
       "29               3   \n",
       "30               1   \n",
       "31               1   \n",
       "32               0   \n",
       "33               3   \n",
       "34               1   \n",
       "35               3   \n",
       "36               0   \n",
       "37               3   \n",
       "38               2   \n",
       "39               4   \n",
       "40               4   \n",
       "41               2   \n",
       "42               4   \n",
       "43               0   \n",
       "44               1   \n",
       "45               0   \n",
       "46               3   \n",
       "47               2   \n",
       "48               4   \n",
       "49               4   \n",
       "\n",
       "                                                                            Topic_Keywords  \\\n",
       "0            language, task, use, model, text, natural, processing, organize, method, word   \n",
       "1            language, task, use, model, text, natural, processing, organize, method, word   \n",
       "2            use, method, model, network, evaluate, task, ground, learn, traditional, word   \n",
       "3               model, language, project, key, base, propose, paper, present, system, task   \n",
       "4               model, language, project, key, base, propose, paper, present, system, task   \n",
       "5   language, system, text, interpretation, arabic, task, sentiment, feature, use, natural   \n",
       "6   language, use, work, task, framework, lexical, efficient, semantic, pretraine, context   \n",
       "7            use, method, model, network, evaluate, task, ground, learn, traditional, word   \n",
       "8               model, language, project, key, base, propose, paper, present, system, task   \n",
       "9   language, system, text, interpretation, arabic, task, sentiment, feature, use, natural   \n",
       "10           language, task, use, model, text, natural, processing, organize, method, word   \n",
       "11           language, task, use, model, text, natural, processing, organize, method, word   \n",
       "12  language, use, work, task, framework, lexical, efficient, semantic, pretraine, context   \n",
       "13              model, language, project, key, base, propose, paper, present, system, task   \n",
       "14  language, system, text, interpretation, arabic, task, sentiment, feature, use, natural   \n",
       "15  language, use, work, task, framework, lexical, efficient, semantic, pretraine, context   \n",
       "16           language, task, use, model, text, natural, processing, organize, method, word   \n",
       "17           language, task, use, model, text, natural, processing, organize, method, word   \n",
       "18              model, language, project, key, base, propose, paper, present, system, task   \n",
       "19              model, language, project, key, base, propose, paper, present, system, task   \n",
       "20              model, language, project, key, base, propose, paper, present, system, task   \n",
       "21           use, method, model, network, evaluate, task, ground, learn, traditional, word   \n",
       "22              model, language, project, key, base, propose, paper, present, system, task   \n",
       "23  language, use, work, task, framework, lexical, efficient, semantic, pretraine, context   \n",
       "24           use, method, model, network, evaluate, task, ground, learn, traditional, word   \n",
       "25  language, system, text, interpretation, arabic, task, sentiment, feature, use, natural   \n",
       "26  language, use, work, task, framework, lexical, efficient, semantic, pretraine, context   \n",
       "27  language, use, work, task, framework, lexical, efficient, semantic, pretraine, context   \n",
       "28           use, method, model, network, evaluate, task, ground, learn, traditional, word   \n",
       "29  language, system, text, interpretation, arabic, task, sentiment, feature, use, natural   \n",
       "30           language, task, use, model, text, natural, processing, organize, method, word   \n",
       "31           language, task, use, model, text, natural, processing, organize, method, word   \n",
       "32           use, method, model, network, evaluate, task, ground, learn, traditional, word   \n",
       "33  language, system, text, interpretation, arabic, task, sentiment, feature, use, natural   \n",
       "34           language, task, use, model, text, natural, processing, organize, method, word   \n",
       "35  language, system, text, interpretation, arabic, task, sentiment, feature, use, natural   \n",
       "36           use, method, model, network, evaluate, task, ground, learn, traditional, word   \n",
       "37  language, system, text, interpretation, arabic, task, sentiment, feature, use, natural   \n",
       "38  language, use, work, task, framework, lexical, efficient, semantic, pretraine, context   \n",
       "39              model, language, project, key, base, propose, paper, present, system, task   \n",
       "40              model, language, project, key, base, propose, paper, present, system, task   \n",
       "41  language, use, work, task, framework, lexical, efficient, semantic, pretraine, context   \n",
       "42              model, language, project, key, base, propose, paper, present, system, task   \n",
       "43           use, method, model, network, evaluate, task, ground, learn, traditional, word   \n",
       "44           language, task, use, model, text, natural, processing, organize, method, word   \n",
       "45           use, method, model, network, evaluate, task, ground, learn, traditional, word   \n",
       "46  language, system, text, interpretation, arabic, task, sentiment, feature, use, natural   \n",
       "47  language, use, work, task, framework, lexical, efficient, semantic, pretraine, context   \n",
       "48              model, language, project, key, base, propose, paper, present, system, task   \n",
       "49              model, language, project, key, base, propose, paper, present, system, task   \n",
       "\n",
       "    Num_Documents  Perc_Documents  \n",
       "0             9.0            0.18  \n",
       "1            10.0            0.20  \n",
       "2             9.0            0.18  \n",
       "3             9.0            0.18  \n",
       "4            13.0            0.26  \n",
       "5             NaN             NaN  \n",
       "6             NaN             NaN  \n",
       "7             NaN             NaN  \n",
       "8             NaN             NaN  \n",
       "9             NaN             NaN  \n",
       "10            NaN             NaN  \n",
       "11            NaN             NaN  \n",
       "12            NaN             NaN  \n",
       "13            NaN             NaN  \n",
       "14            NaN             NaN  \n",
       "15            NaN             NaN  \n",
       "16            NaN             NaN  \n",
       "17            NaN             NaN  \n",
       "18            NaN             NaN  \n",
       "19            NaN             NaN  \n",
       "20            NaN             NaN  \n",
       "21            NaN             NaN  \n",
       "22            NaN             NaN  \n",
       "23            NaN             NaN  \n",
       "24            NaN             NaN  \n",
       "25            NaN             NaN  \n",
       "26            NaN             NaN  \n",
       "27            NaN             NaN  \n",
       "28            NaN             NaN  \n",
       "29            NaN             NaN  \n",
       "30            NaN             NaN  \n",
       "31            NaN             NaN  \n",
       "32            NaN             NaN  \n",
       "33            NaN             NaN  \n",
       "34            NaN             NaN  \n",
       "35            NaN             NaN  \n",
       "36            NaN             NaN  \n",
       "37            NaN             NaN  \n",
       "38            NaN             NaN  \n",
       "39            NaN             NaN  \n",
       "40            NaN             NaN  \n",
       "41            NaN             NaN  \n",
       "42            NaN             NaN  \n",
       "43            NaN             NaN  \n",
       "44            NaN             NaN  \n",
       "45            NaN             NaN  \n",
       "46            NaN             NaN  \n",
       "47            NaN             NaN  \n",
       "48            NaN             NaN  \n",
       "49            NaN             NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8870b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af1a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75152243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce302396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e2173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696279a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79536c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7a89ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
