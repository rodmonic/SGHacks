{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\n",
      "  Obtaining dependency information for arxiv from https://files.pythonhosted.org/packages/e3/fb/ebc79ba50811878e25af80cd08dcdaae6c72edb8be17eecaaf2695e5cce7/arxiv-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading arxiv-2.0.0-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting feedparser==6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "     ---------------------------------------- 0.0/81.1 kB ? eta -:--:--\n",
      "     -------------- ----------------------- 30.7/81.1 kB 660.6 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 81.1/81.1 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting requests==2.31.0 (from arxiv)\n",
      "  Obtaining dependency information for requests==2.31.0 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sgmllib3k (from feedparser==6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hdawson\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests==2.31.0->arxiv) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hdawson\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests==2.31.0->arxiv) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hdawson\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests==2.31.0->arxiv) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hdawson\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests==2.31.0->arxiv) (2022.9.24)\n",
      "Downloading arxiv-2.0.0-py3-none-any.whl (11 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6060 sha256=c83badc9d310f56d072bce6261ddabf905bf5ec02022bb5a0b09e77cd83f312b\n",
      "  Stored in directory: c:\\users\\hdawson\\appdata\\local\\pip\\cache\\wheels\\3b\\25\\2a\\105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, requests, feedparser, arxiv\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "Successfully installed arxiv-2.0.0 feedparser-6.0.10 requests-2.31.0 sgmllib3k-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import arxiv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "search = arxiv.Search(\n",
    "  query=\"NLP\",\n",
    "  max_results=5,\n",
    "  sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    ")\n",
    "\n",
    "# Initialize an empty list to store dictionaries\n",
    "paper_list = []\n",
    "\n",
    "for result in arxiv.Client().results(search):\n",
    "    print(result.title)\n",
    "    # Create a dictionary for each paper\n",
    "    paper_info = {\n",
    "        'Title': result.title,\n",
    "        'PDF URL': result.pdf_url,\n",
    "        'Author' : result.authors,\n",
    "        'DOI' : result.doi,\n",
    "        'Published Date': result.published,\n",
    "        'Summary' : result.summary,\n",
    "        'Journal Ref' : result.journal_ref,\n",
    "        'Primary Category' : result.primary_category,\n",
    "        'Category' : result.categories,\n",
    "        'Entry ID' : result.entry_id\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    }\n",
    "    result.download_source(dirpath=pdf_folder, filename = result.title)\n",
    "    paper_list.append(paper_info)\n",
    "\n",
    "# Print the list of dictionaries\n",
    "for paper in paper_list:\n",
    "    print(paper)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(paper_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df.to_csv('..\\\\data\\\\arxiv_papers_5.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "pdf_folder = 'C:\\\\Users\\\\hdawson\\\\OneDrive - TP Group Plc\\\\Documents\\\\TP group\\\\_Internal Projects\\\\Hackathon\\\\SGHacks\\\\data\\\\PDFs'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\hdawson\\\\OneDrive - TP Group Plc\\\\Documents\\\\TP group\\\\_Internal Projects\\\\Hackathon\\\\SGHacks\\\\data\\\\PDFs'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_folder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "search = arxiv.Search(\n",
    "  query=\"NLP\",\n",
    "  max_results=5,\n",
    "  sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    ")\n",
    "\n",
    "for result in arxiv.Client().results(search):\n",
    "    title =  result.title\n",
    "    print(title)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
